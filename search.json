[{"title":"Unity-Shader-Library","date":"2025-09-11T02:33:22.000Z","url":"/2025/09/11/Unity-Shader-Library/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"前言 记录一下日常或工作中用到的Unity Shader，以便需要时检索 本篇Shader记录，格式为：序号-标题-效果-贴图资源-参数-代码-拓展内容，代码部分需要手动展开 内容1. 模拟音频 效果： 贴图资源： 参数： 代码： 点此展开 拓展： 在用于Timeline里K动画时，可以用顶点颜色的一个通道作为_Lerp参数 2. 故障效果(红蓝通道偏移+UV扰动) 效果： 参数： 代码： 点此展开 3. Hue(色相、明度、饱和度) 代码： 点此展开 4. UV流动 效果： 代码： 点此展开 5. 序列帧图片播放 参数： 代码： 点此展开 6. 扫描光效果 效果： 贴图资源： 参数： 代码： 点此展开 7. 过场黑幕 效果： 代码： 点此展开 效果： 代码： 点此展开 效果： 代码： 点此展开 8. 梦境效果 效果： 代码： 点此展开 拓展： 可调参数：圆角度、宽、高、内扩外扩程度 一般用于模拟回忆、故事滤镜 9. 按轴向显示效果 效果： 代码： 点此展开 效果： 代码： 点此展开 10. 屏幕特效 效果： 参数： 代码： 点此展开 拓展： 需要放在粒子系统上使用，需要该粒子被摄像机看到，即修改MinPerticleSize 11. 两种贴图切换 参数： 代码： 点此展开 12. 两个正多边形进行布尔运算或混合 效果： 参数： 代码： 点此展开 "},{"title":"TwilightMelody-2-2025-10-01","date":"2025-09-08T01:43:14.000Z","url":"/2025/09/08/TwilightMelody-2-2025-10-01/","tags":[["Unity","/tags/Unity/"],["TwilightMelody","/tags/TwilightMelody/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"25.09 开发日志 更新项 完善任务系统，接到新任务时展开任务栏并显示特效 新增死亡界面加鼠标显示按键提示 新增背包整理按钮 新增最高画质下开启天空盒旋转 新增手持武器时，子弹打完后再开枪的卡壳声 新增打到空气墙时的特殊粒子效果 新增魔法攻击超出释放距离时的UI提示 新增放置炸弹时发射轨迹 新增在背包中选中装备物品时显示提升或降低伤害或魔力值的UI提示，并增加颜色区分 新增狐狸每日互动给随机材料并显示收获倒计时ui，每只狐狸每日6点刷新收集物 现在存档系统能够记录和读取游玩时间 现在触发换弹时，若弹药不够，会播放一声音效 现在背包界面菜单内的返回据点按钮后会先关闭背包界面 重置出生点场景的昼夜系统，与全局游玩时间联动。现在将出生点分为5个时段，即T6、T10、T14、T18，分别代表对应数字的整点，也代表四个时段的开端，即清晨、中午、下午、夜晚。在T6、T14阶段会开始天空盒混合变换及亮度变换，在T10、T18会保持当前天空盒以及亮度。在6-18时始终会有光源旋转运动，以使物体阴影随时段变换 新增全局游玩时间系统 补全了设置中的操作说明 修复项 修复卡牌游戏中切屏后无法使用默认快捷键恢复及没按键提示的问题 修正血条、蓝条UI在特定分辨率下的毛边问题 为掉落物中的装备设置收购价上限，降低收购所得的货币获取量 修正存档保存读取界面初始化时的日期格式 修复初始装备中的手枪，及材料掉落物的描述信息格式问题 重新烘焙出生点场景，调整草地高光、环境光渲染比例及颜色，体积云颜色 恢复原预设CG 修正存档系统长时间不登录游戏读取背包InstanceID不同的问题 修正存档系统读取玩家属性错误的问题，现在存档时手中如果持枪，读取后会变成背枪状态 现在在背包菜单中点击“返回据点”触发传送后会关闭背包界面 现在当商店界面及传送菜单界面打开时，不会触发挥刀 刷怪机制增加与玩家距离的判断（场景2：5m；场景4：15m），刷新点与玩家的距离小于该距离时，取消当次刷新；场景4中地下将不再刷新新的怪物 优化背包内武器及装备属性计算UI 待完成项 增加任务中的动画表现 增加日期UI，完善跨场景的日期计算 解决掉落物捡起时卡顿问题 对话框增加箭头UI和操作提示UI 补缺CG、过场图 完善任务系统 修正教学关卡内的操作按键贴图 提升部分怪物受击增加的索敌距离 场景4可拾起物品做随机化 修正场景4捡起的枪可能无收购价 检查部分物品详细信息格式 修正收购上限失效的问题 商店界面增加多选出售功能 教学场景使用流光地面 修正狐狸与玩家的物理碰撞 增加天气系统 "},{"title":"TwilightMelody-2-2025-09-01","date":"2025-09-02T02:16:53.000Z","url":"/2025/09/02/TwilightMelody-2-2025-09-01/","tags":[["Unity","/tags/Unity/"],["TwilightMelody","/tags/TwilightMelody/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"25.08 开发日志 更新项 增加任务系统框架 待完成项 完善任务系统中的动画，制作两条主线 增加场景中的交互物体 增加狐狸按时互动给随机材料并显示收获倒计时ui 修复掉落物捡起时卡顿 补全操作说明 增加BOSS 场景3增加敌人单位 "},{"title":"浅尝ComputeShader-魔法图书馆","date":"2025-07-25T09:24:48.000Z","url":"/2025/07/25/ComputeShader-MagicLibrary/","tags":[["Unity","/tags/Unity/"],["Compute Shader","/tags/Compute-Shader/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 前言 参考效果：   参考文章：  实现效果： 其他： 初学ComputeShader，只是想到了以前用HDRP中的VFX粒子复刻过的效果，可以作为练习 效果中的旋转并非原效果中的旋转规则，可自定义 性能上还有许多优化空间还望读者见谅 本文仅作为个人学习记录和思路分享 实现思路0.场景准备 准备一个空场景 准备好用于触发效果的玩家、一个书本预制体、一个C#脚本、一个ComputeShader。 1.从生成一排&#x2F;一面书本物体开始，初始化位置和旋转 利用ComputeShader将每个书本物体的位置设置为其SV_DispatchThreadID号 线程组设为(8, 8, 1)，为了性能考虑，线程大小设为(4, 4, 1)，后续可自行调整 那么一个线程的SV_DispatchThreadID如图所示： 整个线程组的排列如图所示： 那么，数组大小为(4×8)×(4×8)&#x3D;32×32，每个单位在数组中的索引可以用id.y * 4 * 8 + id.x来表示，即第几行的第几列，如下图黄色数字所示： 而这每个单位都指代一本书所处的位置，为Vector3或float3类型，因此需要一个Vector3[]容器装这些数据，并使用Buffer与GPU进行数据传输 展开代码 ComputeShader： C#： 第一步效果图： 2.加入随机数、三角函数使物体凌乱并做漂浮运动 说到运动，自然是要增加一个核函数，并与CPU端Update联动 物体的随机旋转值使用C#里的Quaternion.EulerRotation()实现，参数为物体自身位置。读者也可以使用其他方法自行实现。 书本从书架(一个平面)飘出，实际上就是Z轴的偏移，因此只需要计算Z轴的偏移量，而不用把整个三维坐标加入计算，节约性能 展开代码 ComputeShader： C#： 第二步效果图： 3.增加书本物体的位置、旋转对玩家靠近时的响应 通过传入玩家的世界坐标，和一些函数运算，来对每个书本单位进行位置和旋转的平滑复位 此时会发现一些问题，后续会解决： 旋转是在CPU端计算的，性能不好 CPU端的SmoothStep函数与GPU端效果不同，需要自己实现 书本位置、旋转固定，不会跟随其父物体位移和旋转 展开代码 ComputeShader： C#： 第三步效果图： 4.将CPU端的旋转计算转到GPU端进行 CPU端的旋转是通过Quaternion.EulerRotation()函数中传入位置得到的 因此我的思路是再开一个线程组，记录对应物体的旋转，直接在GPU中计算旋转后，在CPU端使用 将原先的shader.Dispatch(kernelUpdateHandle, 8, 8, 1)改为(8, 8, 2) 相当于增加一张表，表中的索引从32*32-1开始，到32*32*2-1结束，原先记录Vector3信息的下标加上一半的表容量即可得到其对应的旋转值 展开代码 ComputeShader： C#： 5.解决书本不随父物体位移旋转的问题 原因是坐标系不同，ComputeShader中计算得出的位移和旋转值，在CPU中赋值给了books[i].transform.position和rotation 而不论是改为localPosition还是在Instantiate时不以一个物体为父物体，都存在不好控制、旋转后响应效果错误的问题 最终的解决方案是，以一个空物体作为父物体，控制所有的子物体书本进行位移和旋转，并统一为世界坐标系 CPU端直接将父物体的坐标和旋转传入GPU，使GPU端计算得到的值能够加入父物体的影响，成为世界坐标系 子物体的世界坐标&#x3D;父物体transform的right、up、forward三个分量分别乘上子物体x、y、z轴向上的分量 其中又可以通过两个轴的叉乘得到第三个轴的朝向向量 此时书本飘出的方向就不是Z轴了，而是父物体的transform.forawrd 需要重构部分ComputeShader代码 展开代码 ComputeShader： C#： 第五步效果图： 6.更好的效果控制 此时基本的功能都实现了，而在具体使用场景中，还需要控制物体间隔、物体的初始旋转值等参数 在这就演示这两项参数的增加 还可以加入玩家在书架背面时，不响应效果的设置，通过向量叉乘结果的正负来判断 展开代码 ComputeShader： C#： 完整效果、参数、代码展示 展开代码 ComputeShader： C#： "},{"title":"UI动效 09","date":"2025-06-23T03:47:24.000Z","url":"/2025/06/23/MyUIProject-09/","tags":[["Unity","/tags/Unity/"],["UI","/tags/UI/"],["动效","/tags/%E5%8A%A8%E6%95%88/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"Text UI动效——躲避鼠标 效果参考： 憨鸭的超级躲避鼠标 力场算法参考：  实现思路 其实很早之前做项目时已经做过3D场景中的力场效果，推广到2D鼠标交互，只要统一坐标系就好了，剩下就是按效果调参数了。 效果图 源代码 UI用： 3D物体用： "},{"title":"源码-魔法金属伤害计算","date":"2025-06-12T02:22:26.000Z","url":"/2025/06/12/SourceCode-M3/","tags":[["底层原理","/tags/%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/"],["Minecraft","/tags/Minecraft/"]],"categories":[["教程文档","/categories/%E6%95%99%E7%A8%8B%E6%96%87%E6%A1%A3/"]],"content":" 总览位置- project.studio.manametalmod&nbsp;&nbsp;&nbsp;&nbsp;- event&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- EventFx.class&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;- void combatAttack(LivingHurtEvent event) 源码 点此展开 前言 叠个甲先 本人已有四年独立游戏开发经验，正式从事游戏开发行业已有一年半时间。 然而对MC的开发仅处于脚本层面，对源码更是知之甚少。 源码中会有许多隐式的方法名，只能凭游戏理解猜测，如func_76346_g()。 本着对魔金的热爱和对游戏开发的学习动机，才有了这么一篇文章。 翻译如果有误请多包涵。 解读概念 player&#x2F;rootPlayer : 玩家自身实体 event.ammount : 伤害 event.source : 伤害来源 ItemStack item &#x3D; player.func_71045_bC(); : 武器&#x2F;手持的物品 event.getEntityLiving : 获取被伤害的生物实体 event.setCanceled(true); : 设置伤害无效 field_76373_n : 外来伤害类型 参考 :  1.0E8F : 为1后面8个0，即100000000，F代表浮点类型 func_110143_aJ() : 当前血量 func_110138_aP() : 血量上限 mana.getMagicMax() : 魔力上限 attack : 造成的伤害 penetration_base : 穿透 critDamage : 暴击伤害 crit : 暴击率 avoid : 回避率 final_attack : 最终伤害 max_attack_base : 最大伤害 attack_base_physical : 物理攻击力 attack_base_magic : 魔法攻击力 hp_blood : 吸血 xp : 职业经验获取量 attack_base : 基础攻击力 百科上译为：物理&#x2F;魔法攻击力 mana.magicReliefTemp : 魔力减免 no_tack_damage : 附加伤害 player.field_70170_p.field_73012_v.nextInt(10) &#x3D;&#x3D; 0 : 10%概率 field_70170_p.field_72995_K : 为true时对象是客户端线程上的，反之在服务器线程上 参考 :  field_70128_L : 单位是否死亡 参考 ：  func_70606_j : 设置目标单位当前生命值 参考ItemToolOp.class Produce : m3生产系统 addAllPower(AttackEffect data, int type, boolean isAttack) : 全能力提升，分伤害计算和受到伤害减免两部分，由第三参数isAttack区别，套装效果中攻击时伤害计算部分生效，受击时伤害减免部分生效，type取值范围[0, 10] player.field_71071_by.func_146026_a(Items.field_151043_k) : 消耗物品(金锭) func_70015_d() : setFire() 给予燃烧状态 参考： func_70027_ad() : isBurning() 处于燃烧状态 func_70115_ae() : 处于骑乘状态 func_70690_d(new PotionEffect()) : 为对象添加原版药水效果 new PotionEffect(Potion.getPotionById(), 100, 0) : 原版药水效果，参数：药水id；持续时间，每20tick为1s，所以100代表5s；层数，如0为一层，2为三层。 参考 :  field_70122_E() : onGround() 处于落地状态 func_70090_H : isInWater() 处于水下状态 逐步解释 仅解释含event.ammount的部分： 代码自上而下顺序执行，后面可能会覆盖前面效果 空手时，伤害为 1，后续代码不执行。 若玩家单位或攻击单位为空，后续代码不执行。 玩家攻击到自己时伤害无效，伤害为 0。 手持ManaMetalAPI中指定的ItemDamageBlackList里的物品时，伤害为该物品的整数伤害数值。 ManaMetalAPI.ItemDamageBlackList中的物品包含： Items.field_151110_aK : 鸡蛋 Items.field_151079_bi : 末影珍珠 Items.field_151126_ay : 雪球 Decoration.baserock : 石块 Items.field_151112_aM : 原版鱼竿 依据 若攻击的对象实体含IJobAdvEntity接口，触发玩家职业是否已二转的判断，若不是二转职业，伤害为 1，后续代码不执行。 含该接口的对象有： 阿斯翠德 (BossAstrid) 赤血恶龙 (BossBloodDragon) 末日黑龙 (BossDoomsDragon) 镜中梦魇 (BossMirror) 艾莉西亚 (BossTime) 神王禁卫·艾莉西亚 (BossTimeHard) 即二转BOSS。 依据 若无法使用武器，后续代码不执行。 伤害来源为荆棘附魔时，荆棘伤害上限为100倍职业等级。 双方距离大于4格时，取消伤害，伤害为 0，后续代码不执行。 若手中武器为创造者之剑： 伤害设为1.0E8F。 若受击方不是玩家单位，触发addDamageFX()。 若受击方是BOSS单位，将玩家添加到“可获取BOSS掉落物”列表中，并计算掉宝率。 若受击方含IDungeonBoss接口(地下城怪)，再判断是否为BOSS，将玩家添加到“可获取BOSS掉落物”列表中，并计算掉宝率。 后续代码不执行。 这部分代码有点冗余，判断BOSS单位何不直接调用MMM.isEntityBoss()，估计是迭代过，懒得改原先能跑通的代码。 addDamageFX()方法： 猜测为发送造成伤害通知。 伤害为0或有无敌药水效果等情况，会取消伤害。 其他情况下发送64格范围全体通知，应用伤害字型时装，产生伤害特效。 掉宝率计算方式： i &#x3D; 职业掉宝率+临时掉宝率 i加上从M3药水效果中得到的临时掉宝率 若i大于对方掉宝率，对方掉宝率变为i 目前该掉宝率作用未知 依据 伤害类型标签bypassMagic、bypassArmor 参考 参考 若手中武器为匠魂的武器，伤害 × 12。 若手中武器属于ManaMetalAPI.ItemAttackBalance列表中的物品，伤害加上武器attack属性的值。 ManaMetalAPI.ItemAttackBalance中的物品包含 Botania manaGun terraSword thunderSword crystalBow starSword elementiumSword livingwoodBow enderDagger thornChakram kingKey missileRod aether notch_hammer lightning_knife phoenix_bow dart_shooter zanite_sword gravitite_sword flaming_sword lightning_sword holy_sword valkyrie_lance vampire_blade aoa HauntersStaff thaumcraft itemSwordElemental itemSwordVoid itemSwordCrimson itemBowBone itemWandCasting ChocolateQuest musket revolver staffPhysic staffMagic staffBlast staffFire staffLight ironSwordAndShield diamondSwordAndShield spiderSpear bullAxe ironBigsword diamondBigsword bigSwordBull monkingSword ironDagger diamondDagger tricksterDagger ninjaDagger monkingDagger ironSpear diamondSpear spearGun fireSpear ImmersiveEngineering itemRailgun itemRevolver itemChemthrower Metallurgy GameRegistry.findItem(“Metallurgy”, item.toLowerCase() + “.sword”) Techguns (GenericGun)item ThaumBasic herobrinesScythe revolver ThaumicTinkerer sword sword2 Aether(天境)Mod伤害计算 记录玩家最后攻击的对象 magicReliefTemp值归零，暂不明确用途 若玩家已二转，将最大伤害设为M3配置文件中的GlobalMaxDamage2 若伤害类型是一种EntityDamageSourceElement，获取其type等属性。 参考 应用盔甲效果 判断是否装备全套套装。 判断全套盔甲是否都为装备类型。 判断通过后返回盔甲材质，根据材质应用不同套装效果。 套装效果详解 注：伤害计算的套装效果计算时不包含百科中“受到伤害时”、“额外消耗魔力”等词条，在EventFx.entityHurtsFX()方法中计算受到伤害效果。 若盔甲是ItemToolArmorSpecial，即可升级的盔甲，也即那些毕业套。 获取套装中最低的等级，若不是全套ItemToolArmorSpecial或套装类别不统一，则返回-1。 当最低等级大于-1，获取盔甲路线和材质进行应用效果。 盔甲路线对应：0——基础 1——深渊路线 2——超越路线 DefendGuard_1(保卫使者)： 深渊路线-深渊守门人套装： 强化等级 &gt;&#x3D; 5阶：防御力+75后防御力+5%。 强化等级 &gt;&#x3D; 15阶：防御力+15%、伤害减免+10%。 强化等级 &gt;&#x3D; 30阶：攻击时获得7s最大5层每次叠加1层的药水效果“深渊护卫的意志”，冷却时间2秒。 注：百科上原文为“持续5秒”。 强化等级 &gt;&#x3D; 35阶：防御力+20%、伤害减免+15%。 强化等级 &gt;&#x3D; 40阶：防御力-400，之后剩余的所有防御力若大于0，乘以0.4加到攻击力上，用于转换的防御力不会损失。 基础与超越路线-神圣守护者套装： 强化等级 &gt;&#x3D; 5阶：防御力+50、伤害减免+5%。 强化等级 &gt;&#x3D; 15阶：防御力+10%、伤害减免+10%。 强化等级 &gt;&#x3D; 30阶：攻击时获得7s最大5层每次叠加1层的药水效果“巨人守卫的意志”，冷却时间2秒。 强化等级 &gt;&#x3D; 35阶：防御力+20%。 WraithReaper_1(亡魂死神)： 套装效果：攻击生命值低于50%的目标时，造成的伤害提高30%、穿透值提高4点。 深渊路线-残暴梦魇套装： 强化等级 &gt;&#x3D; 5阶：造伤+10%、爆伤+5%。 强化等级 &gt;&#x3D; 10阶：攻击时获得10s最大100层每次叠加1层的药水效果“无尽梦魇”，无冷却时间。 强化等级 &gt;&#x3D; 15阶：造伤+15%、爆伤+10%。 强化等级 &gt;&#x3D; 20阶：造伤+7%、爆伤+5%，攻击时获得5s最大5层每次叠加1层的药水效果“残暴屠宰”，冷却时间2秒。 强化等级 &gt;&#x3D; 25阶：造伤+20%、爆伤+15%。 强化等级 &gt;&#x3D; 30阶：攻击时，所有以玩家为中心，11格半径内的单位(是EntityMob或含net.minecraft.entity.monster.IMob接口)获得5秒0级的药水效果“噩梦领域”，冷却时间5秒。 强化等级 &gt;&#x3D; 35阶：攻击拥有状态“噩梦领域”的单位额外造成50%暴击伤害。 强化等级 &gt;&#x3D; 40阶：最终伤害+25%、造伤+25%、暴伤+50%。 强化等级 &gt;&#x3D; 45阶：攻击时，根据6格半径内拥有“噩梦领域”状态的目标数量，每个增加5%造伤、3%暴伤。 基础与超越路线-审判之眼套装： 强化等级 &gt;&#x3D; 5阶：基础攻击力+18。 强化等级 &gt;&#x3D; 10阶：对BOSS单位造伤+10%。 强化等级 &gt;&#x3D; 15阶：基础攻击力+36。 强化等级 &gt;&#x3D; 20阶：攻击时10%概率获得16s最大10层每次叠加1层的药水效果“灵魂虹吸”，无冷却时间。状态&gt;&#x3D;10层时，触发叠加时对BOSS单位造伤+20%。 强化等级 &gt;&#x3D; 25阶：攻击生命值低于50%的BOSS单位时，造伤+30%（该BOSS单位在服务器线程上）。 强化等级 &gt;&#x3D; 30阶：攻击生命值低于50%的BOSS单位时，造伤+20%，爆伤+10%，同时目标获得7秒0级的药水效果“死神印记”，无冷却时间。 强化等级 &gt;&#x3D; 35阶：攻击BOSS单位时，造伤+75%；攻击非BOSS单位时，造伤-50%。 强化等级 &gt;&#x3D; 40阶：若目标单位有“死神印记”效果，使自身获得7秒0级的药水效果“审判者之眼”，无冷却时间。 强化等级 &gt;&#x3D; 45阶：若目标单位有“死神印记”效果，，使目标获得6s最大10层每次叠加1层的药水效果“审判终曲”，无冷却时间。若自身拥有“审判者之眼”状态，且目标拥有“审判终曲”状态，终伤+10%。 强化等级 &gt;&#x3D; 50阶：若目标单位未死亡、拥有“审判终曲”状态、没有无敌药水状态、血量低于生命上限的1%，玩家(服务端)将该目标当前生命值设置为1点。注：百科上原文为“立即杀死”。 SecretMagic_1(秘法魔力)： 套装效果：魔力值高于90%时，造伤+30%、穿透+4。 深渊路线-禁忌秘术套装： 强化等级 &gt;&#x3D; 5阶：造伤+12%，魔力减免+1%。 强化等级 &gt;&#x3D; 10阶：造伤+20%。 强化等级 &gt;&#x3D; 15阶：造伤+16%，魔力减免+2%。 强化等级 &gt;&#x3D; 25阶：造伤+24%，魔力减免+4%。 强化等级 &gt;&#x3D; 30阶：增加等同于32%魔力上限的附加伤害。 强化等级 &gt;&#x3D; 35阶：当自身“超能负荷”状态&gt;&#x3D;5层时，终伤+10%，爆伤+15%。 强化等级 &gt;&#x3D; 40阶：攻击时获得15s最大(玩家魔力上限的30%)层每次叠加(基本伤害 * 0.03F + 1.0F)层的药水效果“魔力护盾”，无冷却时间。 强化等级 &gt;&#x3D; 45阶：若玩家拥有“魔力护盾”状态，造伤+35%，暴击率+30，爆伤+10%，攻击时增加3%基本伤害的魔力值。 基础与超越路线-符纹魔导套装： 强化等级 &gt;&#x3D; 5阶：攻击时增加0.1%基本伤害的魔力值，魔力减免+1%。 强化等级 &gt;&#x3D; 10阶：攻击时获得45秒(玩家魔力上限的15%)层的药水效果“魔力护盾”，冷却时间45秒。 强化等级 &gt;&#x3D; 15阶：攻击时增加0.1%基本伤害的魔力值，魔力减免+2%。 强化等级 &gt;&#x3D; 25阶：攻击时增加0.2%基本伤害的魔力值，魔力减免+4%。 强化等级 &gt;&#x3D; 30阶：增加等同32%最大魔力值的附加伤害。 强化等级 &gt;&#x3D; 35阶：若自身拥有“魔力护盾”状态，造伤+20%，爆伤+15%，暴击率+15，回避率+15。 强化等级 &gt;&#x3D; 50阶：攻击时若自身未持有“魔导爆发”状态，则获得7s最大20层每次叠加1层的药水效果“魔导充能”，无冷却时间。 EternalSpirit_1(永生之灵) 深渊路线-无尽贪欲套装： 强化等级 &gt;&#x3D; 5阶：吸血+2%。 强化等级 &gt;&#x3D; 10阶：攻击时获得10s最大10层每次叠加1层的药水效果“血刃切割”，冷却时间2秒。触发叠加效果时，若“血刃切割”层数&gt;&#x3D;10，吸血+5%，附加伤害+目标血量上限的1%(BOSS单位为0.1%)。 强化等级 &gt;&#x3D; 15阶：吸血+4%。 强化等级 &gt;&#x3D; 20阶：攻击时获得20秒0级的药水效果“血色愉悦”，无冷却时间。同时造伤+35%，爆伤+10%。 强化等级 &gt;&#x3D; 25阶：攻击时获得20s最大5层每次叠加1层的药水效果“嗜血本能”，冷却时间3秒。 强化等级 &gt;&#x3D; 30阶：攻击时若自身血量大于最大生命的90%，终伤+10%，爆伤+20%。 强化等级 &gt;&#x3D; 40阶：攻击时若自身血量小于最大生命的70%，吸血+4%。 强化等级 &gt;&#x3D; 45阶：攻击时获得5s最大10层每次叠加1层的药水效果“鲜血渴望”，无冷却时间。每层增加4%造伤。状态&gt;&#x3D;10层时，终伤+10%。 基础与超越路线-永恒神灵套装： 强化等级 &gt;&#x3D; 20阶：攻击时附加等同自身最大生命值16%的附加伤害。 强化等级 &gt;&#x3D; 25阶：未拥有任何创伤时，攻击附加等同自身最大生命值32%的附加伤害。 强化等级 &gt;&#x3D; 30阶：若自身血量大于最大生命的50%，造伤+30%，获得20秒0级的药水效果“生命之源-力量”，无冷却时间；反之，获得20秒0级的药水效果“生命之源-抵御”，无冷却时间。 强化等级 &gt;&#x3D; 50阶：攻击时获得7s最大5层每次叠加1层的药水效果“神灵祝福”，冷却时间2秒。状态&gt;&#x3D;5层时，增加最大生命值64%的附加伤害。 返回ArmorEffect.class的void doEffectAttack，应用其他套装效果。 HighlycrystalArmor_1(致命晶套装) 造伤+40%，攻击目标不为空时，移除服务端玩家的“剧毒”药水效果 Adamantine_1(精金套装) 全能力巨量提升(type&#x3D;3)：造伤+30%，暴击率+10，穿透+4，终伤+4%。 造伤+70%，吸血+5%。 Mithril_1(秘银套装) 全能力巨量提升(type&#x3D;3)：造伤+30%，暴击率+10，穿透+4，终伤+4%。 造伤+60%，吸血+5%。 SoulSteel_1(魂钢套装) 全能力巨量提升(type&#x3D;3)：造伤+30%，暴击率+10，穿透+4，终伤+4%。 造伤+50%，吸血+5%。 MysteriousIron_1(玄铁套装) 全能力巨量提升(type&#x3D;3)：造伤+30%，暴击率+10，穿透+4，终伤+4%。 造伤+40%，吸血+5%。 HolyCopper_1(圣铜套装) 全能力巨量提升(type&#x3D;3)：造伤+30%，暴击率+10，穿透+4，终伤+4%。 造伤+30%，吸血+5%。 BloodDragonArmor_1(恶咒套装) 血量大于最大生命的90%时，造伤+60%，全能力巨量提升(type&#x3D;5)：造伤+40%，暴击率+14，穿透+6，终伤+6%。 注：百科上原文为“生命值高于90%时，全能力极大提升，造成的伤害增加45% ”。 LapudaCore.MeteoriteArmor.ArmorMaterials[0](初-远古套装) 全能力中幅提升(type&#x3D;1)：造伤+20%，暴击率+6，穿透+2，终伤+2%。 血量大于最大生命的90%时，造伤+20%。 LapudaCore.MeteoriteArmor.ArmorMaterials[1](极-远古套装) 全能力大幅提升(type&#x3D;2)：造伤+25%，暴击率+8，穿透+3，终伤+3%。 血量大于最大生命的90%时，造伤+20%。 LapudaCore.MeteoriteArmor.ArmorMaterials[2](灭-远古套装) 全能力巨量提升(type&#x3D;3)：造伤+30%，暴击率+10，穿透+4，终伤+4%。 血量大于最大生命的90%时，造伤+20%。 LapudaCore.MeteoriteArmor.ArmorMaterials[3](真-远古套装) 全能力海量提升(type&#x3D;4)：造伤+35%，暴击率+12，穿透+5，终伤+5%。 血量大于最大生命的90%时，造伤+20%。 oceanArmor_1(海洋套装) 全能力小幅提升(type&#x3D;0)：造伤+15%，暴击率+4，穿透+1，终伤+1%。 每级垂钓等级增加4%造伤。 farmArmor_1(丰饶套装) 全能力小幅提升(type&#x3D;0)：造伤+15%，暴击率+4，穿透+1，终伤+1%。 每级农耕等级增加4%造伤。 BossStartDragonArmor_1(星辰龙套装) 全能力巨量提升(type&#x3D;3)：造伤+30%，暴击率+10，穿透+4，终伤+4%。 造伤+40%。 TempleArmor_1(失落套装) 全能力中幅提升(type&#x3D;1)：造伤+20%，暴击率+6，穿透+2，终伤+2%。 攻击BOSS时，造伤+40%。 StrongholdArmor_1(红光战神套装) 血量小于最大生命的50%时，造伤+80%，全能力海量提升(type&#x3D;4)：造伤+35%，暴击率+12，穿透+5，终伤+5%。 ShadowSecretGold_1(暗影秘金套装) 全能力小幅提升(type&#x3D;0)：造伤+15%，暴击率+4，穿透+1，终伤+1%。 每级采矿等级增加4%造伤。 FeatherSnakeArmor_1(白羽套装) 全能力大幅提升(type&#x3D;2)：造伤+25%，暴击率+8，穿透+3，终伤+3%。 攻击时服务端玩家获得10s最大0层的药水效果“羽蛇守护”，无冷却时间 DungeonGolden_1(神庙金套装) 全能力大幅提升(type&#x3D;2)：造伤+25%，暴击率+8，穿透+3，终伤+3%。 攻击时消耗金锭，造伤+60%，穿透+4。 WeaponCore.bedrock_level_1.ArmorMaterials[1](基岩魔力-全能套装) 全能力中幅提升(type&#x3D;1)：造伤+20%，暴击率+6，穿透+2，终伤+2%。 WeaponCore.bedrock_level_1.ArmorMaterials[2](基岩魔力-攻击套装) 造伤+25%，暴击率+8。 WeaponCore.bedrock_level_1.ArmorMaterials[3](基岩魔力-防御套装) 吸血+5%。 WeaponCore.bedrock_level_2.ArmorMaterials[1](基岩勇士-全能套装) 全能力巨量提升(type&#x3D;3)：造伤+30%，暴击率+10，穿透+4，终伤+4%。 WeaponCore.bedrock_level_2.ArmorMaterials[2](基岩勇士-攻击套装) 造伤+35%，暴击率+8。 注：百科原文为”暴击率提高12点”。 WeaponCore.bedrock_level_2.ArmorMaterials[3](基岩勇士-防御套装) 吸血+10%。 LegendaryWeaponCore.Bear(野熊套装) 职业经验获取量+10%。 LegendaryWeaponCore.Falcon(老鹰套装) 暴击率+15，职业经验获取量+10%。 LegendaryWeaponCore.Fox(狡狐套装) 穿透+5，职业经验获取量+10%。 LegendaryWeaponCore.Wolf(野狼套装) 造伤+15%，职业经验获取量+10%。 UndeadGraveCore.ArmorM1(勇士套装) 造伤+10%，吸血+5%。 UndeadGraveCore.ArmorM2(游侠套装) 造伤+20%，暴击率+7。 UndeadGraveCore.ArmorM2(法师套装) 造伤+10%，暴击率+5。 攻击时，服务端玩家恢复15点魔力值。 WeaponCore.legend_ore.ArmorMaterials[0](地狱使者套装) 全能力小幅提升(type&#x3D;0)：造伤+15%，暴击率+4，穿透+1，终伤+1%。 WeaponCore.legend_ore.ArmorMaterials[1](充能地狱使者套装) 全能力中幅提升(type&#x3D;1)：造伤+20%，暴击率+6，穿透+2，终伤+2%。 WeaponCore.legend_ore.ArmorMaterials[2](觉醒地狱使者套装) 全能力大幅提升(type&#x3D;2)：造伤+25%，暴击率+8，穿透+3，终伤+3%。 WeaponCore.legend_ore.ArmorMaterials[3](真。地狱使者套装) 全能力巨量提升(type&#x3D;3)：造伤+30%，暴击率+10，穿透+4，终伤+4%。 WeaponCore.epic_ore.ArmorMaterials[0](传说勇士套装) 造伤+10%，暴击率+3。 WeaponCore.epic_ore.ArmorMaterials[1](充能传说勇士套装) 造伤+15%，暴击率+5。 WeaponCore.epic_ore.ArmorMaterials[2](觉醒传说勇士套装) 造伤+20%，暴击率+7。 WeaponCore.epic_ore.ArmorMaterials[3](真。传说勇士套装) 造伤+25%，暴击率+9。 ItemArmor.ArmorMaterial.GOLD(金套装) 造伤+30%。 ItemArmor.ArmorMaterial.CHAIN(锁链套装) 造伤+15%，穿透+3。 ManaMetalMod.ArmorKnight(骑士套装) 暴击率+5，穿透+2。 ItemArmor.ArmorMaterial.DIAMOND(钻石套装) 造伤+10%。 服务端玩家攻击时对目标赋予10s最大0层的“破甲”药水效果，无冷却时间。 WeaponCore.BloodMetal.armorMaterial(暗红钢套装) 吸血+10%。 WeaponCore.Dark.armorMaterial(黑暗钢套装) 血量小于最大生命的30%时，造伤+35%。 WeaponCore.AncientThulium.armorMaterial(远古铥套装) 攻击的目标为上一次攻击的目标时，造伤+20%。 WeaponCore.ManaS.armorMaterial(魔法钢套装) 服务端玩家恢复20魔力值。 WeaponCore.UniverseEnergy.armorMaterial(宇宙能量套装) 造伤+20%，暴击率+5。 WeaponCore.NeutronEnergy.armorMaterial(奥哈立尔钢套装) 造伤+10%。 WeaponCore.Endless.armorMaterial(无限钢套装) 魔力值高于50%时，造伤+25%。 WeaponCore.Crimson.armorMaterial(红莲金属套装) 生命大于等于血量上限时，造伤+35%。 WeaponCore.Cobalt.armorMaterial(钴蓝套装) 造伤+15%。 WeaponCore.Palladium.armorMaterial(钯金套装) 吸血+5%。 WeaponCore.RuneSteel.armorMaterial(符纹钢套装) 全能力小幅提升(type&#x3D;0)：造伤+15%，暴击率+4，穿透+1，终伤+1%。 WeaponCore.TrueAncientThulium.armorMaterial(觉醒远古铥战斗套装) 造伤+20%，吸血+5%。 armor_Titanium_1(钛金套装) 全能力中幅提升(type&#x3D;1)：造伤+20%，暴击率+6，穿透+2，终伤+2%。 armor_Lead_1(重铅套装) 造伤+10%，爆伤+10%。 goldSteeleafIngotArmor_1(黄金钢叶套装) 全能力中幅提升(type&#x3D;1)：造伤+20%，暴击率+6，穿透+2，终伤+2%。 攻击Boss单位时，造伤+20%。 powerIronwoodIngotArmor_1(强化铁木套装) 全能力中幅提升(type&#x3D;1)：造伤+20%，暴击率+6，穿透+2，终伤+2%。 吸血+5%。 FIERY(炽铁套装) 攻击正在燃烧的目标时，造伤+35%。 KNIGHTMETAL(骑士套装) 骑乘时，造伤+50%。 KNIGHTPHANTOM(幻影骑士套装) 全能力大幅提升(type&#x3D;2)：造伤+25%，暴击率+8，穿透+3，终伤+3%。 吸血+10%。 YETI(雪怪套装) 全能力大幅提升(type&#x3D;2)：造伤+25%，暴击率+8，穿透+3，终伤+3%。 服务端玩家攻击目标时，目标获得10秒2级的冰缓效果，无冷却时间。 ARCTIC(极地套装) 全能力中幅提升(type&#x3D;1)：造伤+20%，暴击率+6，穿透+2，终伤+2%。 CompressionSteelArmor_1(压缩钢套装) 造伤+20%，吸血+10%。 MMM.isThaumcraft 神秘： MisriruArmorMaterial(米斯里鲁套装) 造伤+35%。 MisriruArmorMaterialTrue(觉醒米斯里鲁套装) 造伤+50%，吸血+15%。 SPECIAL(揭示护目镜) 造伤+20%，穿透+2。 VOID(虚空套) 造伤+20%，穿透+4，吸血+10%。 FORTRESS(神秘要塞套装) 造伤+30%，吸血+10%。 MMM.isBotania 植物魔法： MANASTEEL(魔钢套装) 魔力大于50%时，造伤+20%，穿透+5。 TERRASTEEL(泰拉钢套) 造伤+30%，吸血+10%。 B_ELEMENTIUM(源质钢套装) 魔力低于80%时，造伤+30%，穿透+5。 MANAWEAVE(魔源套装) 造伤+10%，穿透+2 攻击时恢复50魔力。 MMM.isMoCreatures 更多生物： crocARMOR() 造伤+25%。 服务端玩家攻击目标时，使目标获得5秒2级的冰缓效果，无冷却时间。 furARMOR(毛皮套装) 造伤+20%。 hideARMOR(兽皮套装) 造伤+20%，穿透+4。 MMM.isAether 天境： Armor_Zanite(紫晶套装) 造伤+10%，穿透+2。 Armor_Gravitite(重力晶套装) 玩家处于落地状态时，造伤+60%。 Armor_Neptune(海神套装) 玩家处于水下状态时，造伤+65%，穿透+8。 Armor_Phoenix(凤凰套装) 服务端玩家攻击目标时，使目标燃烧10s。若目标处于燃烧状态，造伤+90%。 Armor_Obsidian(黑曜套装) 穿透+11，吸血+10%。 Armor_Valkyrie(武神套装) 造伤+30%，穿透+5，吸血+10%。 MMM.isChocolateQuest 寻找巧克力： CQ_dragon(龙之头盔) 造伤+60%，穿透+9。 CQ_king(国王盔甲) 造伤+30%，吸血+10%。 TURTLE(乌龟套装) 吸血+10%。 服务端玩家获得200秒0级的药水效果PotionM3.potionbrewing3和PotionM3.potionResistance2，无冷却时间。 MONSTER_FUR(未找到翻译，可能为蜘蛛套装) 造伤+30%。 服务端玩家攻击目标时，使目标获得5秒2级的冰缓效果，无冷却时间。 CQ_bull(公牛套装) 增加等同于防御值的基础攻击力。 CQ_slime(史莱姆套装) 服务端玩家攻击时消耗粘液球，造伤+70%。 服务端玩家攻击时有20%概率获得一个粘液球。 CQ_mage(法师套装) 造伤+10%。 服务端玩家攻击时恢复60魔力值。 MMM.isMetallurgy 冶金： metallurgy.tartarite(熔火石套装) 造伤+50%，穿透+4，吸血+5%。 metallurgy.adamantine(幽冥剧毒套装) 造伤+40%。 服务端玩家攻击目标时，使目标获得5秒3级的冰缓效果，无冷却时间。 metallurgy.atlarus() 依据 依据-毕业套效果 未完待续……"},{"title":"TwilightMelody-2-2025-05-01","date":"2025-05-19T06:41:00.000Z","url":"/2025/05/19/TwilightMelody-2-2025-05-01/","tags":[["Unity","/tags/Unity/"],["TwilightMelody","/tags/TwilightMelody/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"25.04 开发日志 更新项 增加狐狸、幽灵的碰触对话。 新增HUD显隐切换快捷键O，鼠标锁定状态切换快捷键P。 修复项 修复主界面不读取本地配置，导致进入游戏场景可能改变分辨率的问题。 修复传送时也会受到伤害的问题。 修复背后枪械材质与手中不一致问题。 对话框内文字颜色调整。 待完成项 密道楼梯后空间布置。 梳理任务系统结构。 "},{"title":"GPU粒子实现原理与ComputeShader GPU Instance的基础应用","date":"2025-03-17T02:12:08.000Z","url":"/2025/03/17/ComputeShaderLearning-1/","tags":[["Unity","/tags/Unity/"],["Compute Shader","/tags/Compute-Shader/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; Unity粒子系统 Unity有两套粒子系统 CPU粒子的ParticleSystem，能支撑粒子的数量级是几千个 GPU粒子的Visual Effect Graph(VFX Graph)，能支撑粒子的数量级是几百万个 粒子是什么 粒子系统是由大量运动颗粒构成的 从编程角度来看 分为三部分 数据 逻辑 表现 数据： 结构体，必须有一个Vector3的Position属性 其他属性，可以有Color、Scale 假设有一个例子系统，由10万个这样的粒子构成那一个Particle结构体的数组，长度为10万，就构成了粒子系统的全部数据 逻辑： 根据某种规律，每一帧，计算position属性，让这些数据“运动”起来 表现： 如何结合图像API把刚才10万个粒子的数据展示出来，比如把每个例子渲染成点图元、面片等 CPU粒子和GPU粒子的实现有很大区别CPU粒子 工作流程： 第一步：在内存里初始化10万个粒子对象 第二步：每一帧里更新十万个粒子的位置 第三步：每一帧要把变换的数据提交给GPU，让GPU做渲染 开销影响： 由于第二步的计算每一帧都要计算，而CPU无法进行并行计算，所以粒子数量多时，计算开销非常大 第三步数据计算之后，需要从CPU把计算的结果提交给GPU做显示，这样的显示每一帧都要做，都涉及到跨CPU和GPU的通信 GPU粒子 工作流程： 第一步：虽然也需要声明10w万个粒子的数据，但是会在初始化的时候，一次性的把这些数据从内存拷贝到GPU显存侧的ComputeBuffer里 第二步：计算每一个粒子下一帧所应该在的位置，计算后的结果依然存储在GPU的显存的ComputeBuffer里面 第三步：渲染的时候直接从显存的ComputeBuffer里面拿数据，直接渲染 开销影响： 第二步由于发生在GPU侧，可以充分利用GPU里面的ComputeShader并行计算能力 第三步减少了CPU到GPU的数据拷贝 借助ComputeShader和ComputeBuffer实现GPU粒子的细节 还是从数据、逻辑、表现三块来看 数据 需要一个结构体particle，里面至少要包含一个Position属性 初始化数据，初始化ComputeBuffer，填充数据 把结构体数据填充到内存里，并拷贝到ComputeBuffer里 new ComputeBuffer() 第一个参数是要缓存多少个这样的粒子，ComputeBuffer的长度要和粒子的长度一样 第二个参数是Particle结构体的大小 new完后只是说显存里有这个Buffer了，还要把数据真正拷贝过去 为了能在ComputeShader计算的时候能使用上刚才ComputeBuffer里的数据，需要新建一个ComputeShader，也写上一个同样的struct 写一个RWStructure的Buffer，把Particle当做泛型传进来，相当于准备好一个Particle List去容纳CPU传过来的数据 在C#里准备好了ComputeBuffer、在ComputeShader里准备好了StructureBuffer之后，需要把二者关联起来 逻辑 如何每帧更新粒子位置 在CPU大概会写成这个样子 变成GPU粒子后，Update函数有比较大的变化 不会在Update里面做for循环了，只需要给ComputeShader设置deltaTime，然后调用Dispatch，传一个ComputeShader的函数名，这样ComputeShader就会去工作，自动去算每个粒子的位置了 实践 第一步-准备粒子数据 第二步-建立CPU、GPU联系，传递Buffer 第三步-在CS中写Update逻辑 第四步-编写UnityShader显示粒子 "},{"title":"数学可视化(15)——相机的控制与运动","date":"2025-02-21T07:41:57.000Z","url":"/2025/02/21/Mathematical-Visualization-15/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 在世界空间下构造相机的世界矩阵定义相机运动需要的几个参数 相机位置x, y, z 相机三个轴上的旋转角度，也就是欧拉角，一般把沿x轴旋转的角度叫做Pitch俯仰角，沿着y轴旋转的角度叫Yaw偏航角，以及沿着z轴的旋转角度叫Roll横滚角 这样定义的摄像机更适合做自由摄像机 而在做相机的目标追踪时，使用起来并不方便 对于追踪摄像机，需要的是相机的位置X, Y, Z 目标追踪点的位置X’, Y’, Z’ 由于目标点投影到视口平面后只是一个二维坐标，它只能影响相机沿X轴与Y轴的渲染角度，因此还需要一个变量来控制相机的横滚角度 一般情况下相机的横滚角默认为0，也就是相机一般不沿Z轴发生旋转，也就是Y轴朝上 不过为了完整性，还是可以通过定义Z旋转轴的Eular角来控制 实现 将追踪相机的两个矢量参数，一个欧拉角参数设置成函数形式 根据这三个参数构建相机的世界矩阵 构建相机的世界矩阵的函数中有四个中间变量 cw为摄像机的朝向方向，也就是相机矩阵的Z轴正向，是由目标点位置减去相机点位置归一化后得到的 cp为世界空间的Y轴正向，这里是由三角函数生成的，为的是方便应用欧拉角参数，默认的欧拉角设置为0，这样实际为float3(0, 1, 0)，也就是世界空间的Y轴正向了 有了两个矢量就可以确定平面了，并可以通过两个矢量的叉乘来求垂直这个平面的向量 cu和cv分别代表摄像机矩阵的X轴正向和Y轴正向，也就是屏幕空间下的U方向和V方向。注意叉乘顺序，Unity下是左手坐标系，摊开手掌四指指向的方向代表叉乘的第一个参数，这里也就是世界空间的Y轴正向，握拳四指卷向的方向为第二个参数，也就是Z轴正向，这时大拇指指向的方向就是要求的X轴正向了 有了相机的世界矩阵，需要将矩阵与Ray marching射线步进方向进行组成，这样，3D空间下的成像与摄像机位置、目标点位置以及横滚角联系起来了 让摄像机看向(0, 1, 0)点，并做半径为6的圆周运动 "},{"title":"数学可视化(14)——屏幕空间环境光遮蔽SSAO","date":"2025-02-21T06:44:57.000Z","url":"/2025/02/21/Mathematical-Visualization-14/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 屏幕空间环境光遮蔽(SSAO)算法 影响SSAO系数的因素 场景深度 表面点法向量 法向量半球的半径 采样点个数 采样点分布 场景深度不连续 由于场景深度不连续以及采样点是预设的，并不能完全展现真实积分后的结果 还可能带来一些错误的结果 采样点的离散分布还会带来噪点的问题，所以一般会和降噪、模糊等算法配合使用 Shader实现原版算法实现 根据uv随机采样得到颜色向量 将随机得到的颜色向量通过乘2减1的变换转到[-1, 1]区间，这是用来做整个球体内的随机法线 将变换后的随机向量与表面法向量点乘，小于0代表夹角大于90°了，已经不是法线半球内的向量了，可以将随机法线向量乘以-1，也就变换到法线半球内了，不会浪费本次的随机 之后将随机向量乘以法向量半球的半径，确保在法向量半球内随机一个点，并投影到近平面上 通过getPosition函数获得表面点屏幕对应uv，加上随机点投影到屏幕上的位移，来获取世界坐标系下随机采样点在世界深度外壳上的点 这里由于是GPU Sample，是一遍Pass的程序，利用了已有的有向距离场信息，重新计算Ray marching找到采样点在世界深度外壳上的点；而如果是显式模型渲染情况下，一般是通过两边Pass，第一遍拿到场景深度信息或场景深度与场景法线信息，第二遍Pass根据场景深度信息或场景深度与场景法线信息重构三维空间来找到这个随机采样点在世界深度外壳上的点 然后根据这个点与表面点，也就是半球球心点来构建向量，通过这个向量与法向量点乘夹角的cos值判断遮蔽情况，夹角越大，对应的遮蔽影响也越大 后面除以两点间距离+1 &#x2F;(length(diff) + 1.0) ，是为了做遮蔽值影响的衰减，距离越大，影响越小 另外，采样点个数也是预定义的，采样点越少，AO的噪点就会越明显，可以通过模糊算法来处理 "},{"title":"数学可视化(13)——距离场环境光遮蔽SDF AO","date":"2025-02-21T06:08:45.000Z","url":"/2025/02/21/Mathematical-Visualization-13/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 环境光遮蔽(Ambient Occlusion) 用来描述绘制物体和物体相交或靠近时候遮挡周围漫反射光线的效果 AO的表现可以突出阴影暗部的细节 除了可以增强画面的层次感和真实感，还可以修补一些漏光、Shadow map阴影接触不实等问题 是实时渲染里，在经验光照模型下，模拟GI表现比较常用的一种光影技术 AO表现的实现有多种方法，如预计算的AO、顶点AO、各种在屏幕空间下实时计算的AO等等 利用距离场计算AO的一种简便方式 在已经有距离场数据的条件下，对于着色点p，在其法向量方向上，以固定的步长步进几个绿色的点，用该点对距离场进行采样 将距离场采样的结果，与到p点的实际距离差值比较 如图，若洋红色的线条与黄色线条长度几乎相等，其累计的差值也很小，代表该p点的环境光几乎不被遮蔽；或洋红色线条与黄色线条的差值较大，其累计差值也相对更大，这代表该p点环境光被遮挡更多 总之，累计的差值越大，代表环境光被遮挡越多 由于环境光遮蔽的衰减是呈指数级下降的，因此更远的表面比更近的表面遮挡得更少 任意点的AO值为 1 - 洋红色线条长度与黄色线条长度差值的累加值，这里的公式默认步进了5次，1&#x2F;2的i次幂是衰减的指数，k为我们为衰减值添加的系数，通过k可以调整遮挡阴影的深浅 进一步对公式展开，洋红色线条长度可以为步进次数乘以△步进长度，黄色线条长度可以可以替换为步进的几个绿色点在距离场上的采样 Shader实现上述公式 传入着色点p的位置与p点的法线方向 occ是为计算累计距离差值定义的变量 scale是衰减系数 衰减系数k默认为3.0 步进的默认距离为0.03 这些数值都可以通过调整来改变AO的效果 接下来是5次循环计算洋红色线条长度(distDelta)，与黄色线条长度(distField)，并将二者的差值乘以衰减系数累加到遮挡值中 最后用1减去遮挡值，并将结果截断到[0, 1]间返回 并乘到经验光照模型的环境光分量上 在有SDF数据时，该算法即简单又高效 当没有SDF数据时，也可以通过屏幕空间来模拟计算AO，比如SSAO等 补充 按公式来看，1&#x2F;2的i次幂完整的写法应该再加上scale * 0.5; 但如果这样改，出来的AO效果衰减得太快，所以需要同时调整遮挡系数k与默认步进距离step 由于衰减过快，可能后几次的增加值非常小，所以可以在遮蔽值达到一定值后直接跳出循环，放弃后面的增量值occ的计算 当把衰减系数和步进距离调成一个更夸张的值来看时，只使用1&#x2F;2系数时效果是不对的，使用1&#x2F;2的幂次更符合AO的分布表现 "},{"title":"数学可视化(12)——距离场阴影SDF Shadow","date":"2025-02-21T02:38:45.000Z","url":"/2025/02/21/Mathematical-Visualization-12/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 本影与半影 本影即硬阴影范围，半影即软阴影范围 SDF Shadow算法 当步进距离h小于预定距离EPSILON时，表示光线与物体相交的距离非常小，可以认为发生了碰撞，这时返回0，代表光线发射点的位置在全影中 否则，继续进行光线步进 当步进距离超过最大距离设定时，表示光线没有与物体发生碰撞，返回1 调用的地方，传入光源发射点位置p，是计算场景sdf光线步进后，得到的隐式几何体上的点；第二个参数传入光源的方向矢量 将计算结果乘以场景深度场 由于每个像素计算的结果都是非0即1，其中0代表阴影，1代表非阴影，这样就能得到硬阴影了 计算软阴影时，将半影区域返回[0, 1]之间的插值过渡就可以了 本影部分逻辑不变 通过一个参数k，将原来的非阴影区域根据步进的次数的倒数与k的乘积来表示 当k越大时，返回值越接近1，k越小，返回值越接近步进次数的倒数，形成一个过渡区的半影 不过这种靠步进次数的插值，中间可能会由于精度产生条带效应，比如步进次数迭代很少的情况下，一些顶点尖角的位置 一个改进算法是，通过步进光线到物体表面距离来完成 绿点为当前迭代的位置，红点为上次迭代的位置；绿圈与红圈表示当次与上次步进sdf边界相切的球体 可以估计最近的几何表面，将位于两个球相交处的点，即两个橙色的点，将这两个点连接起来，就有了橙色线条与光线的交点 假设y为绿点到橙点的距离，d为橙色线条的一半，红色与绿色圆圈的半径为r1与r2，可推出y与d的表达式 将其引入到软阴影改进算法中 这里 d&#x2F;(w*max(0.0, t-y))就是步进方向与橙点到光源点连线的夹角tan的值 而w可以理解为原始软阴影算法中参数k的倒数，这样可以让w的值与软阴影的范围成正比了 小光源与面积光源阴影的差异 SDF Shadow的内容只适配于光源较小的情况 如果光源较大的话可能会出现伪全影的内部半影情况 "},{"title":"UI动效 08","date":"2024-12-31T06:51:37.000Z","url":"/2024/12/31/MyUIProject-08/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["UI","/tags/UI/"],["动效","/tags/%E5%8A%A8%E6%95%88/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"按钮UI动效——昼夜切换 效果参考：  SDF参考：  按钮Mask贴图： 实现思路 绘制按钮外形 思路：采样Mask贴图，最后输出颜色时乘上Mask的a通道即可。 代码(若展不开请等待加载完成) 绘制Handle及高光、内阴影 思路：利用Circle()函数画主体的圆，再画两个圆进行计算高光和阴影。同时开放SunPos参数控制Handle的左右移动范围。 代码 背景制作 思路：这时考虑到背景元素，先做三个变色的圆环，写在Handle前面 代码 加入云层背景 思路：通过画圆的叠加制作，注意要使用saturate函数防止画出的云不超过1，否则在叠加的时候会显示错误；先画背景层较淡的云再画上一层云防止遮盖。 代码 制作背景昼夜颜色插值效果 思路：定义昼夜背景色，使用Handle的x轴位置Remap到[0, 1]做插值。 代码 Handle主体颜色同理。 制作云随Handle移动的下移插值效果 思路：使用Handle的X轴位置Remap到[0, 1]做云Y轴位置的[0, -2]插值。 代码 绘制”月球坑”与显隐控制 思路：继续使用Circle函数在Handle后面继续绘制，有黑色描边则需要绘制两次，显隐则使用Handle的X轴位置Remap到[0, 1]做颜色插值，为了不在移动Handle的一开始就出现月球坑，使用clamp函数进行一些偏移。 代码 绘制”星星”与显隐控制 思路：使用SDF绘制单个星星，再加入位置、缩放、闪烁进度、边缘凹陷度等变量，并分别存入四维变量中，即一个四维变量控制4个星星。 代码 绘制内阴影 思路：使用圆角矩形SDF直接做效果，通过位置、大小微调来实现偏左上角的阴影。 代码 其他： 目前效果差不多了，星星的上下移动插值就不做了，原理和云层的位移一样。 另外遮罩图形也可以用SDF做，可以做到完全不用材质，因为项目里已经有贴图了所以直接用了。 完整代码与Inspector参数： 代码 C#代码 参数 "},{"title":"TwilightMelody_2_2024_12_01","date":"2024-11-08T01:40:05.000Z","url":"/2024/11/08/TwilightMelody-2-2024-12-01/","tags":[["Unity","/tags/Unity/"],["TwilightMelody","/tags/TwilightMelody/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"24.11 开发日志 更新项 新增道具名称和描述 新增场景名设定： 教程场景：梦境 场景一：水晶之地 场景二：毒瘴之森 场景三：孤岛遗迹 场景四：幽魂旷场 新增进入场景动画 新增饰品9、10、11、12、13、14；帽子5、6、7、8、9；鞋子12 新增受伤、中毒屏幕效果 修复项 调整部分贴图大小为2次幂 调整部分枪械材质 调整场景二毒气机制为部分区域 修正回血&#x2F;魔速度与帧率相关的问题 待完成项近期： 修改掉落物粒子效果 "},{"title":"TwilightMelody_2_2024_11_01","date":"2024-11-01T01:54:42.000Z","url":"/2024/11/01/TwilightMelody-2-2024-11-01/","tags":[["Unity","/tags/Unity/"],["TwilightMelody","/tags/TwilightMelody/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"24.10 开发日志 更新项 新增生物：狐狸、幽灵 新增场景2的毒雾机制 新增冲刺消耗魔法值机制 新增与环境的交互剧情 新增据点场景中的彩蛋 新增枪械打完子弹后再射击时，无需通过换弹按键也能触发换弹的机制 新增据点场景中的草地多生物交互逻辑 新增返回据点的菜单选项 新增部分UI界面的分辨率适配 为场景二取名为”毒瘴之森”，为场景四取名为”幽魂旷场” 修复项 修复进入新场景时子弹数不能正确加载的问题 修复使用能量弹的枪射击报错和子弹计算问题和部分枪械可连续拔枪问题 修复据点场景中的部分石头没有碰撞体积的问题 修复场景四中的部分树没有碰撞体积的问题 修复玩家在工作台上悬浮的问题 修复场景四中部分有描边的物体不可拾取的问题 调整恶魔的攻击技能 调整所有怪物的攻击数值 调整冲刺按键为Z和V都能够触发 缩小据点场景中的空气墙范围 待完成项近期： 为每个道具添加名称和描述 为怪物增加音效 增加场景中的可交互物体 增加进入场景动画 未来可能做的： 补全CG 优化包体(贴图) 存档可跨版本继承 成就系统 增加近战武器和动作 任务系统 其他 碎碎念 感觉是时候写点什么来记录了，无论是游戏项目还是生活，总有一些时候需要回头看，或是用于总结和激励自己。也许因为路太遥远，没有归宿，因此只能一直前往。 回看发现太尴尬于是只留下了第一段…… "},{"title":"UI动效 07","date":"2024-08-02T07:27:12.000Z","url":"/2024/08/02/MyUIProject-07/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["UI","/tags/UI/"],["动效","/tags/%E5%8A%A8%E6%95%88/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"按钮UI动效——Hover动效 UI动效06为测试demo，因此跳过，可能以后会补 效果图： 源代码： Shader： C#： "},{"title":"game101 L13 To L22","date":"2024-07-31T02:09:49.000Z","url":"/2024/07/31/game101-L13ToL22/","tags":[["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"前言 由于内容过多，做笔记太费时间，对于Games101后半段只做简单记录 &nbsp; Lecture 13 Ray Tracing 1&nbsp; 光线追踪 Why Ray Tracing? 光栅化最大的问题，就是不能很好地表示全局的效果(软阴影、光线多次反射等) 光栅化很快，但质量较低 光线追踪真实，但是很慢 ~10K CPU core hours to render one frame in production 光栅化：实时渲染，光线追踪：离线渲染 基本原理 定义光线 三个想法(假设)： 光沿直线传播 光线和光线间不会发生碰撞 光线肯定是从光源发出，打到场景中，并在场景中不断发生反射、折射等一系列操作后，进入人的眼睛 光线追踪利用光线的一个性质，光线的可逆性(reversal-reciprocity)，可以理解成，人的眼睛可以发出可以感知的光线，打到物体上，最后打到光源上 Ray Casting 光线投射：怎样去生成不同的光线 从眼睛(摄像机)开始，做光线的投射 假设我们向虚拟的世界中看，面前放了一个成像平面，成像平面被划分成不同的像素格子，对每一个格子，可以从摄像机连条直线穿过这个像素，打出一根光线，这根光线一定会打到场景中的某一位置，如果光线和某一物体相交(交点p)，表明摄像机沿着这条光线看到哪 在把交点(点p)和光源做一个连线，判定这个点是不是对光源也可见，是不是在阴影里，如果不在，则形成一条有效的光路(光源-点p-摄像机) 每个像素投射出一根光线，从眼睛开始，和场景相交，求对应交点，找到交点后和光源连线，判定是否可见，然后算着色，最后写回像素中 Recursice(Whitted-Style) Ray Tracing Whitted风格光线追踪本质是递归 考虑光线弹射很多次 在任意一个点可以继续传播这条光线，只需要正确地算出反射方向、折射方向 着色发生一点点变化，在每一个弹射点都会去计算着色的值 如果光源可以照亮任何一个弹射的点，就把这些点算出的着色值都加到像素里面去 将光线进行分类，eye ray(camera ray)归为primary ray；一次以后的弹射称为secondary ray；往光源连接，判断可见性的称为shadow ray 技术细节 如何求交点 定义光线，数学上就是一条射线，有一个起点(点光源 o)，有一个方向(单位向量 d) 光线上任何一个点都可以用公式表达： &nbsp; 定义球，隐函数表示：球上任意一点到圆形的距离都等于半径 &nbsp; 要求光线和球的交点，即这个点又在光线上，又在球上，满足表达式： 即表示沿光线传播多久(t)会落在球上 将式子展开成二次形式，很容易求得a、b、c的量，同时t得具有物理实际意义，不能为虚数，是正数，根据光线所在射线与球的距离关系，可以解出不同的t&nbsp; 推广到光线和一般性的隐式表面的求交 解出时间t，交点为o + td&nbsp; 对于显式表面求交，即光线和三角形求交 在纸上画任何一个封闭的图像，在这个形状内部点一个点，往任意方向做射线，判断光线和物体有多少个交点，会发现，如果点在形状内，得到的交点数一定是奇数；偶数个交点，一定是在物体外。推广到3D一样可行&nbsp; 怎样做光线和三角形求交 三角形肯定在一个平面内，将问题分解成：光线和平面求交，找到交点后再判断交点是否在三角形内 定义平面，一个方向和一个点 当定义了一个方向(法线 N)后，再定义一个点(p’)就能确定这个平面 平面上任何一点p满足： &nbsp; 求交点： &nbsp; 人们在想，有没有一下解出光线和三角形的交点的方法 O + tD 是光线上的点，如果这个点在三角形内，则一定可以写成用重心坐标描述的位置，其中(1-b1-b2)、b1、b2相加为1 只需解出t、b1、b2 解出后看解是否合理 沿着光线方向：t为正 点在三角形内，对于重心坐标表示的三角形，1-b1-b2、b1、b2都得是非负的 光线和表面求交点，怎么加速 如果用最原始的方法，光线在场景中弹射多次，每次弹射计算一次新的光线和整个场景求交，速度很慢&nbsp; 方法一：Bounding Volumes(包围盒) 用一个相对简单的形状把物体包围起来，保证物体一定在这个简单形状之内 如果光线连包围盒都碰不到，那就更不可能碰到包围盒里的物体 将box理解为三个不同的对面形成的交集 求交点： 对于x0、x1两个面，光线在tmin、tmax时间会和两个面有交点 对于y0、y1两个面，光线在tmin、tmax时间会和两个面有交点 而光线实际在盒子里的时间，是上面两个线段的交集 在三维情况下，有三个不同的对面 进入所有的三个对面时认为光线进入包围盒，tenter &#x3D; max{tmin} 只要光线离开任何一个对面，认为光线离开了包围盒，texit &#x3D; min{tmax} 当tenter &lt; texit，表示光线在盒子里了一段时间，有交点；反之则没交点 如果texit &lt; 0 ，说明盒子在光线背后，没有交点 如果texit &gt;&#x3D; 0 同时tenter &lt; 0 ，说明光线起点在盒子内，有交点 总之，当且仅当tenter &lt; texit &amp;&amp; texit &gt;&#x3D; 0 时，有交点 &nbsp; Lecture 14 Ray Tracing 2&nbsp; AABB如何帮助加速光线追踪1.均匀的格子 先考虑和包围盒求交，再考虑和物体相交 在做任何光线追踪前，对场景进行预处理： 找到包围盒 将包围盒分成一堆格子 判定哪些格子和物体表面相交 做光线追踪 假设光线和盒子求交非常快，和实际物体求交非常慢 当光线经过的格子内有物体，则该格子内，光线和物体有可能有交点，这时再做光线和物体求交点 通过光线的传播方向，判定接下来需要求交的格子是哪几个。如向右上打的光线，只需判断其上方和右方的格子 划分的格子不能太密也不能太疏，得有一个平衡 #cells &#x3D; C * #objs C ≈ 27 in 3D 2.空间划分 均匀的格子有许多不足之处，如在稀疏的地方不需要那么多格子 八叉树 一个节点有八个子节点 通过一定规则来规定停止切分的标准 人们不喜欢用八叉树：在二维下是四叉树，三维下是八叉树，若维度再高点，就变成2的幂次树，显然并不好 KD-Tree 能让空间得到划分，并且和维度没关系 每一次找到一个格子，总是将它沿着某一个轴进行展开，只切一刀 每个轴交替切分，基本保证均匀地划分 BSP-Tree 每次将空间进行二分，但不是横平竖直的，类似KD树，但计算上跟复杂 维度高时，计算会越来越复杂 KD-Tree 同样是做光线追踪前的预处理 如果设计一种数据结构来存储KD-Tree 对于任何一个节点 当前沿着哪个轴划分 划分在哪 对于中间节点来说一定有两个子节点 实际的物体(三角形)只存在叶子节点上 实际做法： 如果光线和某一格子没有交点，什么都不用做 如果光线和某一格子有交点，就能知道，光线和它的两个子节点可能都有交点，所以都看一下，直到光线打到叶子结点，如果还没有交点，什么都不用动，如果和叶子节点包围盒有交点，则光线和包围盒里所以物体进行求交 但是，如何判定场景中的物体(三角形)和包围盒相交，是个复杂的问题；一个物体可能出现在多个包围盒里，并不直观 因此，人们渐渐地不使用KD-Tree了 于是有了另外一种办法，同样可以做划分，不是从空间做起，而且从物体做起，形成的加速结构，就叫做BVH Object Partitions &amp; Bounding Volume Hierarchy (BVH) 一开始找一个盒子把全部物体包起来 将所有三角形分成两部分，把这两部分的三角形重新求它们的包围盒 可以明确的是，一种物体只可能出现在一个格子里，省去了三角形和盒子求交点，避免了KD-Tree的问题 实际做法： 找到一个包围盒 递归地把任何一个包围盒拆成两个部分 把这两部分重新计算包围盒 正常情况下，当叶子节点有足够少的三角形时，停止划分 如何划分节点有不同的做法： 沿着最长的轴：保证划分的空间较均匀 取中间的物体：两部分的三角形数量差不多，划分成的树较为平衡(深度差不多) 如果光线和整个BVH节点都不想交，什么也不发生 如果相交，是叶子结点，则光线和节点内所有物体求交，返回最近的那个 如果相交，不是叶子结点，则光线可能和两个节点都有交点，分别求出它们两个的交点，再求最近的一个(递归) Basic radiometry(辐射度量学) 学习辐射度量学的动机 Blinn-Phong模型中提到，Light intensity I &#x3D; 10，这个10是什么呢，肯定得有个物理意义 辐射度量学告诉我们如何去定义光照，定义了一系列方法和单位，可以给光各种各样不同的(空间中的)属性 认为光还是沿直线传播，不会波动 New terms：Radiant flux， intensity， intensity， irradiance， radiance 所有这些量都有明确的物理概念 Radiant Energy and Flux(Power) Radiant Energy，是一种能量，用焦耳单位表示 Radiant Flux，人们通常叫它Power，单位时间内产生的能量，类似功率，单位为瓦特 可以理解为光的亮度 另一种理解：有一个感光的平面，单位时间通过它的光子的数量，就是它的flux 一个灯泡看上去更亮，说明单位时间内辐射出更多的光子 Radiant Intensity &amp; Irradiance &amp; Radiance Radiant Intensity： 定义：单位立体角上的Power 立体角： 表示空间中的角有多大 可由二维的弧度表示角有多大来延伸 单位立体角 &#x3D; 单位面积 &#x2F; r2 如果把球的所有方向对应的立体角积分起来，得到的是4π 在辐射度量学中，用 ω 表示三维空间中的方向，可以用 θ 和 Φ 的方式定义它的位置，通过sinθdθdΦ算出单位立体角(微分立体角)是多少 回到Intensity的定义，其实就是光源在任何一个方向上的亮度(Flux或Power) &#x2F; 对应单位立体角 既然Intensity &#x3D; dΦ &#x2F; dω ，反过来积分，把所有方向上的Intensity积分起来，一定能得到Power 如果一个点光源往各个方向均匀地辐射出光，那么任何一个方向上对应的Intensity &#x3D; Power &#x2F; 4π 实际例子：60瓦指看上去像60W的白炽灯，实际是11W，规格815流明 如果认为这个灯向四面八方辐射出的能量是一样的，则可以算任意方向的Intensity是多少 总结 光源总在不断辐射出能量，这个能量在图形学里很少用这个概念，比如太阳能板，接收光照时间越长，吸收能量越多 为了分析问题，一般考虑的是单位时间的能量，因此引入Radiant flux(power)，对应灯泡的功率 intensity就是在单位立体角上的能量 球体表面积的计算公式为 S &#x3D; 4πr2 &nbsp; Lecture 15 Ray Tracing 3&nbsp; Irradiance 定义：Power per unit area unit area：面必须和光线垂直，如果不是垂直，通过投影变成垂直 之前说到Blinn-Phong点光源辐射出的能量到达着色点，和着色点本身的吸收，都有能量损失，而到达着色点有个r2的衰减，可以用Irradiance正确地解读 定义点光源power(功率)为Φ，认为往各个方向均等地辐射出能量 可以看出，变的是Irradiance，而不是Intensity(单位立体角上的能量) Radiance 为了描述光线传播过程中的属性 定义：power在单位立体角，并且在单位面积上有多少 联系： Incident Radiance： 入射进来的能量 Irradiance为dA收到的能量，Irradiance per solid angle是说这个能量要往某一个方向去辐射，能量本身会往各个方向辐射，但这个能量往这个方向去辐射，会辐射出多大的强度来 反过来理解，从一个方向，打到这个小的面上来，到达这个面的时候，应该会有一些能量，这个能量就是Irradiance。本身如果考虑来自四面八方的能量，可以得到dA总共收到多少能量，但只考虑从某个方向进来的能量被dA收到了多少，这个概念就是Radiance 所以Irradiance和Radiance的区别在于是否有方向性，考虑从一个方向进来，并且被dA收到的能量为Incident Radiance Exiting Radiance： 一个面发出去的能量 这个很小的面会往各个方向发出能量，dA往某一确定的方向(dω立体角)上去有多少的Intensity 对于Radiance，要考虑成两个部分，一部分是一个很小的面dA，一部分是一个很小的范围(无论是进来还是离开) Irradiance vs. Radiance Irradiance：dA(在某一小范围)收到的所有能量 Radiance：还是看某一很小的范围，只考虑从某一方向进来，能让dA收到的能量 Radiance无非是在Irradiance上加了一个方向性 dA这么一个小的范围可以写成Irradiance形式(E(x))，某一方向Radiance是L，考虑朝向乘以cosθ，然后考虑立体角dω 从dω立体角来的所有能量，可以通过这种方式把Irradiance和Radiance联系起来 整理式子，两边分别积分，p点收到的所有能量，就是从每个方向过来的能量积分起来(积分就是求和) Bidirectional Reflectance Distribution Function(BRDF 双向反射分布函数) 一个描述 光线打到漫反射物体后向四面八方反射 性质的函数：有多少能量，如果从某个方向进来，它会往不同的方向去，怎么样去分散，不同的反射方向上会分布多少能量 有两种理解反射的方式： 光进来后打到一个物体，改变一下方向，被弹走了 光线打到了某一物体表面，被吸收了，再从这个物体表面把这部分能量发出去，经过了一个中间过程 如果按后者理解，就可以用Irradiance和Radiance来解释反射 从 ωi 来的Radiance，会打到dA上，dA吸收了多少，然后再发出去 相当于入射的Radiance，会在dA处转化成power，这个power优惠辐射到另外一个方向去 所以通过这个能量，可以把入射和出射联系起来 考虑微小面积dA，从某一微小立体角 dωi ，接收到的Irradiance，会如何被分配到各个不同的立体角上去，这个分配比例，就是对于任何一个出射方向的radiance除以dA这么一小块接收到的Irradiance，就是BRDF的定义 对于每一个入射方向，都会有对应入射方向——着色点——出射方向的BRDF，BRDF会告诉我们从某个方向进来的光反射到出射方向有多强，那就把每一个方向的入射光强度(radiance)乘以BRDF乘以cosθ，把每个方向对出射方向的贡献都加起来，就可以得到这个点在所有可能的入射光下，最后反射到出射方向上看过去是什么样的 反射方程和渲染方程 所有的光线传播都可以用这条公式(渲染方程)来总结 反射方程告诉我们，要从某个点观察某一个着色点，要考虑能够到达着色点的所有光线，这些光线不只是光源能够到达，如果有其他物体在，也会被照亮，也会反射出光 如果物体自己会发光，只要把自发光加上就可以 渲染方程跟Blinn-Phong着色模型一样，还是假设所有光线都朝外(明明是光线打进来，这里的ωi表示为朝向外的向量) (n·ωi)法线点乘入射方向，就是cosθ dωi指考虑所有可能的入射方向，指从球心向各个方向去 Ω+指半球，因为只考虑半球的话，法线朝上，如果光线从半球下打过来，认为对反射的贡献为0 一个点光源下的反射方程 多个点光源，就把每个点光源的贡献加起来 如果有面光源，把面光源理解为一堆点光源的集合，以前可以把所有点光源加起来，那么也可以把面光源上任意点光源积分起来，积分这个面光源所占据的立体角，考虑所有覆盖的方向，从这个方向来的Radiance经过BRDF反射过去应该是什么样的Radiance出去 如果有其他物体反射来的Radiance，就考虑这些物体反射出去，并且正好回照亮x点的Radiance是多少，相当于把物体当成是光源 在数学上有简单的表达方式 两个不同的位置，用u、v表示 l为辐射出去的Radiance e(u)为着色点自身发出去的能量 加上从其他的物体表面，通过BRDF，把从其他物体表面来的Radiance反射到当前着色点位置上，会有多大的能量反射到观察方向上 可以进一步简写，把BRDF连着积分的东西都写成某种操作符 所有物体辐射出的所有能量 &#x3D; 光源辐射出的能量 + 辐射出的能量被反射后的能量 目的是为了解渲染方程 最后可以经过泰勒展开得到不同弹射次数的分解 从另一个角度来理解 光栅化可以把物体投影到屏幕上，已知屏幕上任何一着色点的位置和光源位置可以做着色，着色做的就是直接光照，光源自己可以直接投射到屏幕上来(可见的话) 光栅化做的就是0次和一次光线弹射的部分，后面的部分比较难做，这就是光线追踪要做的部分，就是间接光照 概率论回顾 随机变量、概率分布 随机变量会以不同的概率取不同的值 满足：所有概率都是非负的、所有的概率相加为1 期望：不断地去取随机变量，求它们的平均 在连续的情况下描述概率和它的分布 概率密度函数(PDF)：在某一点x取它周围的微点dx，向上连线，与曲线和坐标轴围成的近似梯形区域的面积为该点x对应的概率，这条曲线叫做概率密度函数 求期望就是把值乘以概率密度并且积起来 &nbsp; Lecture 16 Ray Tracing 4&nbsp; Monte Carlo Integration(蒙特卡洛积分) 是一个求定积分的方法，最后得到的是一个数(围成的面积) 回顾黎曼积分的做法，是把ab之间均匀地拆成多份，每一份取中间位置，找到对应的y，认为每一份都是一个微小的长方形，把整个曲线下方的面积分解成各个不同的小正方形的面积之和 蒙特卡洛积分，是一种随机采样的方法，在ab间重复采样多次，每次采样到xi，找到对应的f(x)，得到对应长方形的面积，采样多次，将得到的面积平均起来 已知任何一个采样点的函数值，已知概率密度 只需要在积分域上，以一定的PDF进行采样，对每个样本，算f(X)&#x2F;p(X)，最后平均起来 采样点越多，误差越小 不用考虑积分域，已经在PDF里体现了 要求只能用积分域上的点做蒙特卡洛的积分近似(在x上积分只能用x，其他变量不成立) Path Tracing(路径追踪) 为了解决Whitted-style ray tracing中非基于物理的、不正确的问题 Whitted-style ray tracing的做法： 不断地弹射光线，在任何一个位置都和光源连一条线 当光线打到光滑的物体上，会沿着镜面方向反射、折射方向折射；当打到漫反射物体，就不再弹射 Whitted-style ray tracing的问题： 如果对于Glossy的材质，还沿镜面方向反射，是不对的 打到漫反射物体后就停了 既然Whitted-style ray tracing是错误的，而渲染方程是正确的，那么就要正确地解出渲染方程，要考虑两个问题： 它本身是积分，对半球内四面八方来的光线 本身也是递归的定义，解这个点的渲染方程，同时要解从其他地方来的光线的渲染方程 第一个问题用蒙特卡洛积分 只考虑直接光照 对着色点p，出射方向ωo，要算四面八方的光源对这个点的直接光照贡献，可以写成这个算法 从这个着色点，往半球上发出N个不同的方向采样，按照某种PDF 初始化结果为0 对任何一个选中的方向，从p点往这个方向连出一条方向 如果这根光线打到了光源，就把求和式子写出来，自然能知道光源的辐射(Radiance)L_i，BRDF f_r也知道，cos也知道，pdf(wi)是均匀采样的PDF 引入间接光照 从Q点到P点的Radiance，可以看成Q点也是个光源 可以类比P点是摄像机，从P点去观察Q点，算Q点的直接光照一样 把Q点的直接光照的结果，作为Q点过来的光照 此时仍有几个问题： 光线的数量会爆炸 #rays &#x3D; N#bounces；递归没有停止条件 只有N &#x3D; 1的情况下，才不会爆炸 修改：随机往一个方向采样 N &#x3D; 1时，这种方法称做路径追踪；N !&#x3D; 1时，称做分布式光线追踪 当只考虑一条光线时，噪声非常大 最后要的是像素的Radiance，而穿过这个像素会有很多不同的路径，最后像素是多少，由所有路径求平均，只要有足够的的路径就可以了 每个像素，发出一系列光线，在任何一个打到的点上，把着色的结果求平均算出来 在像素内均匀地取某一位置 对任一选取的位置，从视点连一条光线到样本的位置，如果这根光线打到场景中某个位置，就算这一点的着色 为了解决第二个问题，不能设置递归条件为光线弹射几次，因为总会损失能量，而引入俄罗斯轮盘赌的方法来决定以一定的概率来停止继续往下追踪 积分的结果需要算出来等于Lo 以一定的概率(提前定好)P，往某一方向打一条光线，得到一定的结果后，除以P作为返回值 以另外的一部分概率 1 - P内，不打光线，得到结果为0 最后的期望仍然是Lo 代码上修改极少 定义某一概率P_RR，每次选取[0, 1]间的数ksi PDF如果均匀地往四面八方采样，可能会有很多光线浪费，于是考虑直接在光源上采样 如果想采样光源，将光源理解为二维的框，在这个平面上均匀采样，所用的PDF是 1 &#x2F; A 而渲染方程不是定义在光源上的，它是定义在立体角上的积分，定义在半球上的 蒙特卡洛要求在x上积分就要从x上采样，从光源上采样，就得把渲染方程写成对光源上微表面的面积进行积分，只需要知道dω和dA的关系 dω是dA投影到单位球上的立体角，立体角是空间面积除以距离平方 按照立体角的定义，先把面朝向着色点，再除以距离平方 重写渲染方程： 现在，将光线传播拆成两部分： 光源直接对着色点的贡献 所有其他非光源的贡献 最后考虑光线传播过程中是否有遮挡 &nbsp; Lecture 17 Material and Appearances&nbsp; Material 在渲染方程中，BRDF是决定材质的，材质是BRDF的一个参数 反射 漫反射系数定义： 首先，材质是漫反射材质 任何的光线进来，都会被均匀地反射出去 认为从空间中任何一个进来的光线的Radiance都是一样的 利用能量守恒，如果这一点不发光，也不吸收光，也就意味着所有的能量进来多少，就反射多少 观察到入射光是均匀的uniform的，入射和出射的Irradiance相同，则入射光的Radiance和出射光的Radiance也得是一样的 在渲染方程中，没有自发光项，认为入射光ωi从任一方向来，通过漫反射BRDF，会被反射到ωo上去 可以简化一下，因为入射Radiance和BRDF的diffuse是常数，可以拿出去，剩下的是半球上一个对cos函数的积分 半球上直接对立体角积分得到的是2π，而 Li &#x3D; Lo ，可以得到 BRDF &#x3D; 1 &#x2F; π 如果BRDF &#x3D; 1 &#x2F; π ，这个时候，就是完全不吸收能量的BRDF 这时可以定义一个反射率albedo，可以是单通道的一个数，也可以是三个数rgb，也可以是光图，albeddo在[0, 1]之间，可以引入不同颜色的BRDF，这个BRDF的值就是albedo &#x2F; π 反射公式有两种不同的理解方式： 方法一：平行四边形法则，给定入射光和法线算出出射光 方法二：把这些角度投影到一个局部坐标系上 认为任何一个方向和法线的夹角(仰角)，如θ &#x3D; 0为沿着法线方向 定义一个Φ角，规定在某一个平面上，比如ion，认为Φ &#x3D; 0，如果这个平面绕着n转动，引起的角度Φ 折射 当入射的介质反射率&gt;出射的介质反射率时，可能出现没有折射的现象，这个现象称为全反射现象 红线是菲涅尔项，告诉我们如果一根光几乎和物体表面完全平行，就会完全被反射；如果是垂直的，更多能量会直接穿过去发生折射，反射的能量非常少 另外两条表示极化性质，和光线的波动性有关，光线其实是沿着各个不同方向振动的，极化值只沿着S和P方向振动，正常情况下认为S和P方向都有振动，基本是两个方向上的平均，目前也没有什么渲染器在考虑极化的光的情况 这是反应了对绝缘体的菲涅尔项，对于导体又是另外一种现象 对于金属(导体)来说，它的菲涅尔项在任何情况下反射率都挺高的 菲涅尔项的计算可以简化，认为某一条曲线从某一地方开始，，0°的时候是某一个值，涨到90°的时候涨到1，拟合出一条曲线。它的基准反射率(在0°时的反射率，垂直入射的反射率)是和它们两个折射率是有关系的 不管对绝缘体还是导体，都可以近似地表达 Microfacet Material(微表面材质&#x2F;模型) 真正的基于物理的材质 微表面模型：当离得足够远看向一个物体的时候，很多微小的东西看不到，看到的是它们最终形成的，光对表面的作用 微表面模型认为：从远处看，看到的是材质&#x2F;外观，从近处看，是几何 每一个微表面认为是一个微小的镜面，每一个微表面都有自己的朝向(法线) 可以研究这些微表面本身法线形成的分布 可以把表面的粗糙程度用微表面的法线分布来表示，集中就是glossy，分散就是diffuse 考虑菲涅尔项F、法线分布D、几何项G D：表示在任何方向上分布的值是多少，只有当法线方向和half vector完全一致的时候，微表面能够把入射方向的光反射到出射方向。微表面被认为是完全的镜子。查询在所有的分布里，有多少微表面的法线方向是沿着half vector方向去的 G：修正微表面互相遮挡的情况，光线方向或观察方向只要接近Grazing Angle(接近水平)，会发生遮挡 Isotropic &#x2F; Anisotropic Materials 各项同性材质&#x2F;各项异性材质 各项同性：认为微表面并不存在一定的方向性 各项异性：如果在BRDF上不满足在方位角上旋转，得到的还是相同的BRDF，就把它叫做各向异性的材质 其他各项异性材质例子： BRDF的性质 非负性 线性性 可以拆成很多块，最后加起来算结果 可逆性 交互入射方向和出射方向得到的结果相同 能量守恒性 各向同性的话意味着BRDF的值只和相对的方位角有关，原本四维的BRDF可以变为三维的 根据可逆性，所有的BRDF，方位角不用考虑正负 测量BRDF &nbsp; Lecture 18 Advanced Topics in Rendering&nbsp; Advanced Light Transport&nbsp; 有偏&#x2F;无偏的光线追踪 做光线追踪很多的都是在用蒙特卡洛估计 无偏的蒙特卡洛：估计出的结果的期望永远都是对的 有偏的蒙特卡洛：所有其他情况。但如果用的样本足够多，在极限的情况下，期望值会收敛到正确值，这时还是有偏的，也是一致的(consistent) 双向路径追踪(BDPT) 思想：生成两个不同的半路径(子路径)，把半路径的端点连起来，形成整个路径 BDPT在某些情况下，效果会更好 BDPT实现难度高，运行速度也慢很多 Metropolis(人名) 光线传播(MLT) 思想：用统计学上的一个采样工具，Markov Chain(马尔科夫链) 相当于当前有一个样本，马尔科夫链可以根据当前样本生成一个跟它靠近的下一个样本 好处：它可以做到，给定足够的时间，马尔科夫链的蒙特卡洛方法(MCMC)可以生成一系列以任意函数的形状为PDF的样本。当采样的PDF和要积分的函数形状一致的时候，得到的效果是最好的，而任何未知的函数用马尔科夫链的办法能让生成的样本分布和被积函数形状一致 特别适合做复杂的场景 但不能估计什么时候收敛 所有操作都是局部的，有些像素收敛快，有些慢，使得图像看上去很脏，所以也不能用于做动画，前后两帧收敛不同，会强烈抖动 Photon Mapping(光子映射) 非常适合渲染caustics(国内翻译成”焦散”)，caustics指由于光线的聚焦产生非常强的图案 光子映射的实现方法有很多 其中一种做法有两步 第一步：从光源出发，打出很多光子，该反射的反射、该折射的折射，直到打到漫反射物体停止(把所有光子记录到Diffuse物体上) 第二步：从摄像机出发，往各个方向打，会反射和折射，直到打到漫反射物体停止(也停在Diffuse物体上) 将两个步骤结合，计算局部的密度估计 光子越集中的部分越来 对任何一个着色点，取它周围最近的N个光子，找这N个光子所占的面积，接着算这些光子的密度 如果N取太小，噪声会很大；N取太大，画面会模糊 这就是为什么光子映射是有偏的方法 密度应该是当前一个点密度是多少，当前点周围取微小面积dA(dN &#x2F; dA)；而光子映射做的是给一定光子数，算它的面积(△N &#x2F; △A) 对密度的估计是一个不正确的估计，而当有足够多的光子的情况下(极限情况)，△A会接近dA 但只要不是无限个光子，这种方法一定会有点糊，所以叫做有偏的方法，但是一致的 在渲染中很好理解有偏和无偏 得到的结果有任何一点的模糊，就是有偏 一致的：虽然是有模糊的，但只要样本足够多，最后会让它收敛到不模糊的结果 Vertex Connection and Merging(VCM) 将双向路径追踪和光子映射结合起来 生成两个sub-path连起来，如果有的path满足两个端点非常接近，就不用连一条path，而是用光子映射结合起来 Instant Radiosity (IR 实时辐射度) 思想：已经被照亮的面都认为是光源，用它们再去照亮别人 从光源打出很多光线，停在某些地方，认为那些停住的地方形成了新的光源(VPL 虚拟光源) 当看到某一点时，用所有新的光源去照亮这一点，实际上是考虑光线弹射了两次 问题：在窄的接缝处会发光，因为之前把对立体角的采样改成了对面积的采样，面积 x cos &#x2F; 两点间距离，两点间距离足够小时，得到结果非常大 &nbsp; 外观建模&nbsp; 非表面模型 散射介质 如云、雾 当光在行进过程中如果穿进了散射介质，会有若干事情方式 云中间有光源，先不考虑 云里面有小的冰晶，会把光线随机地打到不同方向去 光线传播过程中也可能接收到其他光线 在传播过程中逐渐消失，如乌云 总之，光线在传播过程中，可能被吸收，可能被散射 而如何散射的，由相位函数(Phase Function)来定义 光线能传播多远，取决于介质(如乌云、薄雾) 光线停下后，考虑光线应该往哪个方向重新走，这就是散射 相当于光在物体表面做各种各样的弹射，只不过中间任何一个点都有可能发生方向的改变，最终都能找到一条连接光源的path，找到path后和各个弹射点相连，计算整个路径的贡献 Hair Appearance 考虑光线和一根线的作用 有无色的高光和有色的高光，如何形成的呢 光线打到圆柱(头发)上，往四面八方散射，对头发来说，会散射出一个圆锥，同时一些光线会被散射到四面八方去 这种模型显然不好 这种模型考虑光线打到圆柱的时候，肯定有一部分被直接反射掉(R)；也有一部分会穿进去，发生折射(TT)；还有一种是光线进入头发里面，在内壁上发生一次反射又往回走(TRT) 描述材质就是要描述如何跟光线作用 把头发当成玻璃的圆柱，局部是直的，它有两层结构，外层是cuticle(角质层)，内层是cortex(皮质) 认为头发内部有色素，如果头发是黑的，色素多，吸收多 考虑三种光线和圆柱的作用： 综合考虑后，可以得到一个非常好的模型 而用人的头发模型不能用来描述动物的毛发 从生物结构来看，毛发有三层，而动物毛发的髓质比人的头发髓质要大很多，光线进去更容易发生散射 而事实上，髓质的影响确实很大，于是提出了双层圆柱模型 Granular Material 颗粒材质 一粒一粒的模型，一堆小东西形成的模型 Surface Models 半透明材质 为了描述光线的这种反射方式，定义为次表面反射(Subsurface Scattering) 次表面反射可以理解为BRDF的延伸 人们发现，半透明介质好像就是光打到物体上，这个物体底下出现一个光源，从底下照亮着色点周围的一片 为了真实，人们觉得一个光源不够，上方还得有一个光源，用这两个光源去照亮着色点周围的一块，很像次表面散射得出的结果，这个方法叫做Dipole Approximation Cloth 布料是一系列缠绕的纤维构成的 它的缠绕有不同的层级 纤维(fiber)是最原始的概念，一根一根的，如一根羊毛就是一根纤维 纤维经过第一次缠绕可以缠绕成不同的股(Ply) 不同的股再经过缠绕会形成线(Yarn) 再被织成布(包含机器织的布和手工织的毛衣等) 这种材质的渲染肯定和织的形状有关系 有的布本身真的在一个平面上，可以用BRDF，而像天鹅绒这种不是一个平面，就不能用BRDF来描述 一个办法是认为是空间中分布的体积，划分成一个个非常细小的格子，每个格子里面知道纤维的朝向分布、复杂程度等，就可以把这些性质转换成光线的吸收、散射，好像是在渲染云一样 能得到相对准确的结果，但计算量大 把每一根纤维都渲染出来 同样是计算量大 Detailed Appearance 渲染出的结果往往非常完美 而真实世界中的物体会存在各种细节，比如划痕 微表面模型提到，最重要的是微表面的法线分布 大家描述这种分布，一般用的都是简单的模型，比如正态分布、高斯，用这种方式去描述，得到的自然是看上去没什么细节的结果，因为法线分布并没有体现各种各样的变化和细节 实际上我们要的是基本符合统计规律，又有自己带的细节的模型 细节的渲染十分困难 问题就在于我们认为每个微表面是一个镜面，摄像机打出的光线很难打到光源，反之亦然 解决办法是考虑一个像素会覆盖很多的微表面，而如果能把这块微表面的分布算出来，替代原来光滑的分布，并且用在微表面模型里 如果考虑一个像素覆盖了多大的范围，会得到各种各样的法线分布NDF 如果一个像素覆盖了很多的微表面，这些微表面的法线分布自然而然的显示出圆形的统计学规律 如果覆盖的范围小，就会显示出很独特的性质 而且不同类型的法线贴图会引起不同的分布 在物理上，当物体非常小的时候，小到和波长相当的时候，就不能假设光是沿直线传播了，必须假设这个光是一个波 在一个小黑屋里，用一个点光源照亮金属，可以发现不是一个颜色 用白光来照射物体，就应该反射出白的，如果不是白的，就一定有波动光学发生 波动光学得出的BRDF跟几何光学得出的BRDF挺像的，但是又有不连续的特点，这是因为光的干涉，使得某些地方强某些地方弱 Procedural Appearance 程序化生成的材质 用一定的方式去指导材质的生成，不需要真正的生成它，而是动态地查询它 如果定义一张三维的纹理，存储量太大 不存纹理，定义一个空间中的函数f(x,y,z)，什么时候需要用，就去查，这种函数就叫做噪声函数 &nbsp; Lecture 19 Cameras, Lenses and Light Fields&nbsp; 注：以下所描述的”棱镜”都为Lenses，应该被称做”透镜” Imaging &#x3D; Synthesis(合成:光栅化成像、光线追踪成像) + Capture(捕捉:如相机拍照) Camera 控制光在1&#x2F;n内进入相机 记录光的Irradiance Field of View (FOV 视场) 即能看到多大的范围 人们通常定义FOV的时候，认为是以35mm格式的胶片为基础，通过定义焦距的方式来定义FOV FOV越窄，可以看到的东西越远 如果能改变传感器的大小，小的传感器就对应小一点的视场 缩短焦距让小的手机也能达到相同的FOV 平常一般会固定传感器的大小，只用焦距来衡量 对于渲染器来说，传感器(Sensor)负责记录最后每个像素收到的Irradiance有多大，胶片(film)决定最后成什么样的图片格式 对于目前来说，可以把这两个概念混淆着使用 Exposure 曝光 相机能够影响照片亮度的因素 f-stop(f数)：调节光圈的大小，仿照人的瞳孔，在暗的环境下瞳孔会放大，单位时间可以接收更多的光，反之相反 快门速度：快门开放的时间越短，意味着更少的光会进来 ISO gain：可以理解成后期处理，简单理解为最后接收到多少能量，乘以一个数 f数越小，光圈越大 1&#x2F;1000指开放1&#x2F;1000秒，ISO的增长可以认为是简单的线性增长 ISO能提高亮度，同时也会提高噪声 快门时间越久，让光进来的时间越久，在这段时间里如果物体在做运动，则运动的距离越长，得到的运动模糊越严重 反之，快门时间不变，物体运动的越快，运动模糊越严重 为了减少运动模糊，要求拍照不要手抖 或减少曝光时间，而减少曝光时间必然会减少收到的光线使得画面变暗，此时需要调节ISO，上表为一系列相同曝光度的对应参数 而大光圈会引起前景深的问题，快门时间会影响运动模糊，这两种情况是需要权衡的 运动模糊不一定是坏的，如体现赛车的速度 由于快门的打开需要一个过程，在这个过程中拍摄的高速物体，会产生Rolling shutter问题，产生不同位置的图像有可能记录的是不同的时间的结果，造成扭曲的现象 高速摄影 人们不希望有严重的噪声，因此使用大光圈，而不直接提高ISO 延时摄影 用小光圈慢慢拍 Thin Lens Approximation 真正的棱镜非常复杂 有些棱镜并不是把光聚到一个点上 我们研究的是一种理想化的薄的棱镜，棱镜本身厚度忽略不计 平行光打进来，都会经过一个点，叫做焦点，焦点到棱镜中心的距离叫做焦距 光路有可逆性，如果光线穿过焦点，被棱镜折射后会变成平行的一束光 假设这个薄的棱镜，可以任意改变它的焦距。而实际上棱镜生产出来后，是不能改的，这正是相机中使用棱镜组的好处，使用棱镜组就类似一个可以调焦距的棱镜 棱镜会满足基本的物理规律，定义物距、相距和焦距 用相似三角形来推导 反应了相距、物距、焦距三者的关系 通过薄棱镜，可以解释好多问题 1.景深 CoC：一个点成像过来，反应到Sensor上变成了一个圈 CoC跟光圈大小成正比 N(f数) &#x3D; f(焦距) &#x2F; A(光圈直径) CoC和N有反比关系 所以拍清楚的照片通常用小光圈 Ray Tracing Ideal Thin Lenses 模拟薄棱镜做光线追踪 一种设定方案： 确定成像平面大小，定义棱镜属性(焦距和光圈大小) 定义这个棱镜离场景中某个平面有多远(物距zo) 计算相距 渲染： 在成像平面上选一点x’ 在透镜上选一点x’’ 将这两点连一条线 可以得到x’’’ Depth of Field 大光圈得到大的CoC，一个点会得到大的圆，但总归有部分是不模糊的(Focal Plane) 用大小光圈会影响模糊的范围 景深就是指在场景中有一段深度，这段深度经过透镜后会在成像平面的附近形成一段区域，这段区域内认为CoC都是足够小的 景深就是指成像清晰的一段范围 &nbsp; Lecture 20 Color and Perception&nbsp; Light Field &#x2F; Lumigraph (光场) 人们看到的是从各个方向进来的光线，而看不见光线从多远进来，从什么地方进来 可以用全光函数(The Plenoptic Function)来描述人可以看到什么东西 假设人站在场景里位置固定，往四面八方去看，可以用极坐标表示任何一个方向 改进函数，引入波长(表示不同颜色) 再扩展一个时间t 再考虑空间中任何一个位置 最后把这个函数理解为：在任何一个位置、往任何一个方向看，并且在任何时间，看到不同的颜色 就拿这个七维的函数当做全光函数 紫色点并不是离散的，可以放在任意位置，能从任意方向知道过来的光是多少，方向也应该是连续的 光场是全光函数的一小部分 光线 起点是(VX, VY, VZ)，方向是θ 可以用不同的方式定义光线 比如取任意两点，假如方向已知 表面 对于定义任何一个物体的表面 可以把任何一个物体放在一个包围盒里 看向物体，无非是从任何位置、任何方向 根据光路的可逆性反过来理解，要想描述这个物体能被看到的所有情况，就要描述这个物体在它的包围盒上，它在任何一个位置往任何一个方向过去的光线，就可以得到从任何一个位置看向这个物体是长什么样的 光场 相当于是包围盒上有一个点，观察位置一个点，两点确定一条光线。知道包围盒上的位置，知道方向，就可以去查询记录的函数 这个函数记录了不同的点(物体表面不同的位置)，往各个不同的方向的发光情况，把这个情况记录下来，就是光场 总结：光场就是在任何一个位置，往任何一个方向去的光的强度 光场是全光函数的一小部分，只是二维的位置和二维的方向 位置：三维物体的表面其实在一个二维空间中，可以理解为纹理映射，用u、v就能表示任何一个位置 方向：任何一个空间中的位置，都可以用θ、Φ表示 光场的一种参数化方式：取两个平行的面(uv、st)，各取一个点连线，考虑所有的可能性 从某个角度看向整个世界，拍一张图，把所有这些图组织在一块，这就是整个光场 光场的另一种理解方式 把原本记录在一个像素上的光分别记录在不同位置 光场摄像机：支持后期的重新聚焦 原理就是把原本的像素换成微透镜，这些微透镜会把来自各个方向的光给分散到不同的方向上去，将感光元件往后挪一点点 原本记录一个像素，现在记录一块像素 为了得到最后的图片，每个像素都选取同一方向的一条光线，记录在一个像素的结果上 相当于有了这个光场以后，我们可以虚拟地移动摄像机的位置 光场相机的问题： 分辨率不足：原本一个像素记录一个像素的信息，现在用一百个像素记录一个像素的信息。胶片的分辨率变成空间上的分辨率乘以方向上的分辨率 高成本：高精度胶片、透镜 Physical Basis of Color 牛顿通过实验发现，颜色其实是很多基本颜色混合出来的结果 不同的波长对应不同的折射率，而任何一种光一定对应某一种光谱 光谱就是光线的能量在不同的波长上的分布 光谱是一个很长的范围，而图形学中关心的是可见光的光谱，分布在大概波长400nm ~ 700nm之间 谱功率密度(SPD)：光线在不同的波长的强度是多少 通过SPD，可以描述光在各个波长上的分布 SPD有线性的性质 What is Color？ 颜色是人的感知，并不是物理上的一些东西 人眼就是一个摄像机 瞳孔可以调节大小，相当于光圈 晶状体相当于透镜，晶状体调节焦距，是通过肌肉来拽它 人眼感知的地方在视网膜上，也是最终光线到达的地方 视网膜上有感光细胞 一种是棒状细胞：感知光的强度，但不感知颜色，用它可以得到灰度的图 一种是锥形细胞：比棒状细胞少很多，用来感知颜色 锥形细胞内部，又分成三种不同的锥形细胞(S、M、L类型的细胞)，对三种类型的波长的响应各不相同 但是不同的人眼睛里这三种细胞的分布非常不一样 再次印证了颜色是人感知的结果 把光线的强度和相应的感知曲线的感应强度乘起来，再把每一个不同的波长都考虑进去，就是最终的结果 三种不同的感知细胞，会感应出三种颜色结果，这三个数才是真正看到的颜色，而不是光线本身的SPD Metamerism(同色异谱) 不同的信号积分后得到相同的结果，是有可能发生的现象，称为同色异谱 Color Reproduction &#x2F; Matching颜色应该如何混合 加色系统 允许线性组合基本颜色来匹配任何给定的颜色 表示用多强的第一、二、三种颜色可以混合出左边的颜色 对任意的颜色都可以通过类似的方式解决 但是有一些情况不同，左边的颜色右边怎么混合都出不来 可以把左边需要混合的颜色往上加一个颜色，相当于对应右边减掉一个颜色，这就是线性的性质 通过几种颜色混合出一种颜色，系数是负的是没有关系的 CIE(一个组织)定义了RGB系统，它要做颜色匹配 给定任何一个颜色，是单波长的一个颜色激光，光线的SPD就是一个单一的函数 混合各种不同的单色光，得到任何一个波长上的给定的光线颜色 叫做匹配函数(CIE RGB Color Matching Functions) 如果给定任何一个实际的SPD分布，需要考虑每一个波长用多上的红色、绿色、蓝色混合才能得到它，自然是一个积分的结果 Color Space 标准RGB系统是广泛使用的一个标准系统 但是它所形成的色域是有限的 CIE XYZ系统是在科学上更加广泛应用的一个系统 同样要定义颜色匹配函数 它不是实验测出来的，是人造的颜色匹配函数 绿色的曲线覆盖波长非常均匀，分布是对称的，正常来说用x、y、z三个匹配函数匹配出不同的颜色得到的Y(类似于RGB的G)一定程度上就可以表示亮度 把XYZ系统，能够表示的所有的颜色都显示出来 而XYZ是三维的，不好可视化 只想显示其中的两维 对任何的XYZ先做一个归一化，得到三个归一化的值xyz，由于知道xyz相加等于一，所以只需要表示xy就行 为了显示x和y，它其实表示的颜色还是由XYZ来定的，其实还是三个变量 既然知道Y表示亮度，可以把亮度固定成某一个数，让X和Z发生变化，这样x和y都是X、Z的函数 这块区域就叫做色域，也就是所有一个颜色空间可以显示的颜色 对于一个色域来说，中心呈白色，是由各种颜色混合而来，说白色是最不纯的颜色，而纯的颜色都在边界上 不同的颜色空间，表示的颜色范围是不一样的 Perceptually Organized Color SpaceHSV颜色空间 允许选择不同的色调(Hue)、饱和度(Saturation)、亮度(Brightness&#x2F;Value) 色调：不同类型的颜色 饱和度：更接近白色(不纯)还是颜色本身的纯色，越饱和越接近单一的颜色 CIE LAB Space 也是跟感知有关 L轴是亮度 a、b轴相互垂直，a轴表示红和绿，b轴表示蓝和黄 它认为任何一个轴上表示的颜色，它的极限(两端)都是互补色 比如能想到深绿、黄绿、蓝绿，但不会想象一种偏红的绿 人的大脑对互补色有一个定义，人脑会自动把互补色补上 颜色本身是感知，有些事情是相对的 减色系统 各种颜色混合后会得到黑色 为什么需要K？ –考虑印刷成本，因为黑色墨水便宜，彩色墨水贵，需要黑色的时候直接用黑色墨水而不用混合 XYZ有非常好的理论性质，非常大的色域 RGB好用，很直观 HSV比较好调颜色 &nbsp; Lecture 21 Animation&nbsp; 对动画的不同理解 让物体”活”起来 用于交流的工具，给别人展示各种动起来的东西 早期的动画人们并不关心画的对不对，是否符合物理，只要看起来差不多对，那就差不多 也可以理解成建模、几何的拓展 动画无非是在不同的时间(帧)有不同的几何形状，动画就是为了得到这些不同的形状要怎么去计算 动画的形成是把很多的图按顺序、按一定的速度去播放，就可以了 不同的应用对动画的要求是不一样的 关键帧 工作量大 关键帧动画本质是插值的技术 希望有种东西可以控制插值效果，这时虚线&#x2F;样条是非常重要的 动画和几何是关联的 Physical Simulation (物理模拟&#x2F;仿真) 物理模拟说的就是推导、实现、利用不同的物理公式，来计算出一个物体应该有什么形状&#x2F;位置上的变化 Mass Spring System (质点弹簧系统) ||b - a||表示方向 问题：永远弹下去 解决：加个摩擦力(damping force) 在模拟仿真中，用x一点表示一阶导数(速度)，两点表示二阶导数(加速度) 会引起所有的运动都停下来 Particle System 本质上是定义个体与群体之间的关系 Forward Kinematics 在图形学中通常把运动学区分成正向的和反向的 定义一些简单的关节模型，形成一个复杂的模型 本身又能把整个结构形成加速结构&#x2F;树形结构 运动学定义的东西都非常物理，而艺术家喜欢直接拿着骨骼到处拽，不用通过调整角度来控制骨骼，引入了逆运动学 Inverse Kinematics 计算复杂、解不唯一或无解都有可能发生 Rigging 蒙皮、插值 Motion Capture(动作捕捉) &nbsp; Lecture 22 Animation Cont.&nbsp; 显式&#x2F;前向 欧拉 非常不稳定 误差可以通过减小步长缩小 Combating Instability 中点法 自适应思路，试着把时间分成两半，如果跑出来结果接近就不往下分，反之往下分 隐式欧拉方法 Runge-Kutta方法，简称RK4 龙格库塔方法是一系列方法 Position-Based &#x2F; Verlet Integration 通过调整位置，使得最终能能够满足某些限制 刚体 位置、朝向、速度、角速度 "},{"title":"games202","date":"2024-07-30T07:09:55.000Z","url":"/2024/07/30/games202/","tags":[["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"前言 由于内容过多，做笔记太费时间，对Games202只做简单记录 Lecture 1 “怨虎龙都没打过你还来听什么网课，本末倒置” -by 闫令琪 Lecture 2 Recap of CG BasicsBasic GPU hardware pipeline 渲染的过程：开始是3D模型，最后是一张图 中间过程：渲染管线(渲染流水线) 物体在空间中被表示成点和它的连接关系 任何的点都会经过顶点的处理和变换(MVP)，最后成为屏幕上的点 经过一系列的变换后，它们的连接关系并没有发生改变，仍然会表示那么些三角形，只不过这些三角形被投影到屏幕上去了 三角形被投影到屏幕上去了，下一步做光栅化(“光栅化”最早的词就是”画”)，就是把原本连续表示的三角形给连起来，把它离散化成屏幕空间上的一堆像素(fragments) 在打散成像素的过程中，会涉及到一些遮挡的处理 确定了可见的fragment后，就可以对它们进行着色，就是去计算它们应该长什么样(Bling-Phong) 先判断片段的顺序，考虑遮挡，还是先做着色，有不同的处理方法，有细微的差别，影响不大 OpenGL OpenGL是什么 是一系列的API，在CPU端执行的，它负责调动GPU 因此，用什么语言都没有关系，我们更关心GPU怎么执行，而不是CPU怎么让GPU执行 特点：跨平台 确定：版本碎小；C风格的代码，没有面向对象一说，对编程人员来说不方便；若干年前不好Debug 怎么用OpenGL 类比：把整个的渲染过程理解成画一幅油画的过程 a.把物体放好 b.把画架放好 c.放置画布 d.在画布上画东西 e.(放上另一个画布继续画) f.(用以前的画做参考) A.放置物体&#x2F;模型 什么物体 怎样摆放 Vertex buffer object(VBO) User specifies an object’s vertices, normals, texture coords and send then to GPU as a Vertex buffer object(VBO) VBO就是GPU中的一块区域，这块区域用来存储我们的模型 Very similar to .obj files Use OpenGL functions to obtain matrices e.g., glTranslate, glMultMatrix, etc. No need to write anything on your own B.放置画架 视图变换 Create&#x2F;use a framebuffer (类比OpenGL里的画架) Set camera by simply calling, e.g., void gluPerspective(GLdouble fovy, GLdouble aspect, GLdouble zNear, GLdouble zFar) OpenGL让一切都得到简化，只需要规定相机的一些属性(e.g.,可视角度fovy、长宽比aspect、近平面zNear、远平面zFar) C.固定画布 对场景渲染一次，相当于坐在画架前画，但是可以画很多幅不同的画 即用一个framebuffer，可以指定这个framebuffer它可以输出很多不同的纹理(shading, depth, etc.) 渲染一次(one pass)场景，可以得到很多不同的东西，由fragment shader告诉你最后要写到哪一个纹理上去 E.可以用同一个画架画多幅画，只需要换一块画布 只要指定一个framebuffer，可以一下渲染出很多不同的纹理 D.在画布上画画 顶点&#x2F;片元着色器 对每一个顶点进行操作 写顶点着色器着色 MVP映射、插值后，送给片元着色器 OpenGL把一个三角形打成一堆像素 对每一个片元进行操作 写片段着色器着色 F.Multiple passes Use your own previous paintings for reference 总结 我们更需要关心的是写顶点&#x2F;片元着色器，其他更多的都是可封装的 OpenGL做什么事情：就是告诉GPU该做什么，而且可以告诉GPU去做多次不同的任务 OpenGL在渲染之前，一定要先告诉清楚信息给GPU 为了让场景能够渲染，要做的事情(in each pass): 定义要渲染的物体、场景，定义物体、场景的MVP矩阵，相机关系等 要选什么framebuffer(画架)，framebuffer的输出是几个纹理 告诉GPU怎么渲染(顶点&#x2F;片元着色器) 当所有东西都告诉GPU后，再拿去渲染 其他 垂直同步、双重缓冲、三重缓冲：先把渲染的结果存到一个纹理或一个缓冲区里去，当渲染好后，确保没问题，再拿到屏幕上显示 OpenGL Shading Language(GLSL)The Rendering Equation 一套正确的用来描述光线传播的方法&#x2F;等式 你看到的任何一个点p，观测方向O，是它本身发出来的radiance，加上所有其他打到这一点的radiance乘以BRDF乘以cos角度，把这些光收集起来 在实时渲染(RTR)中，说的BRDF有可能指BRDF，也有可能指cosine-weighted BRDF 人们会考虑当前这个shading point，它是否能看到四面八方的光照，会不会引入visibility的概念 Calculus 放在下节 Lecture 3 Real-Time Shadows 1Shadow Mapping A 2-Pass Algorithm 第一遍(Pass)渲染场景，会认为从light看向场景，并输出一个该light所能看到的最近的深度 有了这张ShadowMap之后，可以拿到后面去用。也就是第二遍Pass，从相机出发，真正地渲染场景，配合SM，可以去检测相机所看到的任何一点是否在阴影里 An image-space algorithm 好处：SM生成了就可以作为场景中的几何表示，为了得到阴影只需要SM，不需要实际的场景的几何 坏处：会出现自遮挡、走样现象 Well known shadow rendering technique 家喻户晓的算法 最早的时候在离线渲染也是非常有用的生成阴影的方法 由于数值精度造成的地板纹路 ShadowMap有精度，每个像素要记录它所看到的最浅深度，也就是说一个像素内是一个常数，一个像素对应的地板上的一块区域在ShadowMap看来是与成像平面平行的，所以会出现自遮挡现象 只有光线垂直照射平面的时候，不会出现自遮挡现象 可以加上一小段bias去降低自遮挡情况，光源与地板垂直时bias小，夹角越大bias越大 bias过大可能会造成丢失阴影的问题 一个解决思路 实际上没人使用，要求物体是个水密性物体 实时渲染不相信复杂度 The math behind shadow mapping 从微积分开始，有很多不等式 在RTR中，我们关心的是”近似相等”，更希望把这些不等式拿来当约等式用，特别是建立在一系列条件下 一条贯穿RTR不同子领域的约等式 想把两个函数乘积积分起来，可以拆出来 分母表示归一化常数 积分域(support)越小越准确、g(x)足够光滑越准确 人们更愿意把visibility项单独拆出来写 用刚才的公式可以立刻推导出，把V单独拿出来，右边没有visibility，就是shading 对于点光源&#x2F;方向光源来说，这么拆分是准的 Percentage closer soft shadows (PCSS) ShadowMapping产生的是硬阴影，而生活中更多会遇到软阴影 Percentage Closer Filtering (PCF)是一个工具，最早研发出来用于做抗锯齿，后来人们发现还能被用于做软阴影 PCF做的是，把任何一个点连向光源看是否在阴影里，是的话标注成0，不是标注成1，对这一系列结果做一个Filtering，实际上是求平均 它的Filtering不是指在最后的图上做，不是对ShadowMap进行filter，而是在做阴影判断的时候 它平均的是任意一个ShadowPoint做了很多次阴影的比较的结果 filter区域的大小会决定阴影的软硬 所以PCF可以用来做软阴影效果 但是要给它多大的filter size呢，是不是各个不同的位置上都要给它相同大小的filter呢。答案是：不是 人们发现离阴影投射物(遮挡物)近的地方，比较硬，反之较软 因此定义一个距离叫做blocker distance 准确的说，叫做：相对的、平均的、投射的遮挡物的深度 该filter多大，就取决于light的size和blocker的距离 对于面光源，无法生成ShadowMap，一般认为它是一个位于面光源中心的点光源 而第一步的Blocker search又要取多大的范围呢，一般认为有两种方法 取某一固定大小的区域 另一个更好的方法，对于shading point，想要去找Shadow Map里面的某一块区域在第一步用来做Blocker search，要去红色区域里去估计能挡住shading point的点的平均深度，红色区域取多大，我们认为把light当点光源，放在Light中心，看向物体，认为ShadowMap是在某一位置，比如近平面，就看shading point连向light来看覆盖了ShadowMap多大区域 总结： 在任何一个Shading Point，通过上述方式，可以找到在Shadow Map上某一片区域，应该去找哪些像素可能遮挡这个点，这样的像素就被视为Blocker，把它们深度平均起来，如果遇到像素不能遮挡它，就不管它，因为它不是Blocker，记录下Blocker的平均深度后，用公式得到对应阴影应该去fliter多大的信息，之后问题转化成PCF 开销是很恐怖的，在做Block search时，要对范围里的纹理进行访问，完成后在PCF里面还得做PCF对该范围的纹理进行访问。工业界给出了一些方法，在下节中说明 用PCF去做软阴影，叫做PCSS Lecture 4 Real-Time Shadows 2 实际上做的是，对任意一个像素p，都取周围的一圈领域，邻域中取点q，所有的点q都考虑进来，把所有的点q根据和点p的距离做一个加权，最后重新写回点p fliter实际上就是加权平均，convolution(卷积) 在PCSS里，做的是点x在Shadow Map上对应点p，附近的任意一个点q是否能遮挡住点x 在公式中，只有两项，左边是权；右边是值，阴影比较的结果，点q如果挡到的话visibility是0，挡不到是1。Χ是个符号函数，在微积分里就是个阶梯函数，当它的变量大于0时，Χ的函数值就是1，变量小于0，函数值为0，这正是阴影比较的结果 从公式可以看出，它并不是在filter Shadow Map，对SM进行模糊后，最后得到的值还是非0即1 也不是在图像上做filter，在一个有锯齿的硬阴影上做模糊，试图去解决抗锯齿的问题，这种做法是在图像空间上来做 在第一步和第三步中，都要做在某一区域内，里面所有的纹素和某个深度相比 Variance Soft Shadow Mapping 针对PCSS中的第一步和第三步慢的问题 从第三步PCF中考虑，在Shadow Map上记录的一块区域内，把里面深度都拿到，看有百分之多少的纹素的深度要比Shading Point要浅 而我们不想把每个纹素都看一遍，为了避免这个过程，使用VSSM解决 近似的认为是正态分布，只需均值和方差 切比雪夫不等式，不需要知道是什么分布，只需均值和方差，就能得到近似面积 有个限制，t必须在均值的右边 用VSSM提升PCSS第三步PCF的fliter质量，需要再生成Depth map的同时，还要生成它平方的map MIPMAP and Summed-Area Variance Shadow Maps 如何对一张图上的任何一块区域快速获取平均值，并且保证这块区域一定是一张矩形 最简单的办法是Mipmap，快速的、近似的、方形的范围查询，但不准 一个100%准确的方法，引入Summed-Area Table数据结构，跟算法中的前缀和概念紧密结合 范围内求平均和范围内求和是同一个概念 二维的情况下 Moment shadow mapping VSSM的问题体现在它做的假设不正确 所以引发一个能不能解决VSSM对分布描述不准的问题 做法是使用更高阶的矩(moments)，去描述分布 VSSM用的是前两阶的矩(深度和深度平方)，而用更高阶的矩，确实可以获得更接近的分布估计 结论：如果保留前m阶的矩，它可以表示一个函数，一个由一系列阶跃函数堆起来的一个函数，并且它能表示m &#x2F; 2个台阶 问题更多的在于对于一个四阶矩，怎么得到有两个台阶的函数，是很复杂的 Lecture 5 Real-Time Environment MappingDistance Field Soft Shadow 很好的软阴影效果 SDF的背后和一个理论关系密切，叫做最优传输(Optimal Transport) 应用1：光线追踪(ray-marching) 应用2：生成软阴影 不准，但符合观察 将SDF得出的安全距离转化成安全角度，这个角度越小，遮挡越大 关心的是如何得到安全角度 对每一个安全角度取最小 避免复杂的计算，用第二个公式进行近似 k用于控制阴影的软硬程度。k越大，很小的比值也会得到1，也就是阴影的过渡越小 Shading from environment lighting 环境光照：用一张图记录在场景中往任何一个方向看，可以看到的光照 认为光照是来自无限远的 放一个物体在场景中，在不考虑遮挡&#x2F;阴影的情况下，如何算出Shading 这种操作被称作Image-Based Lighting(IBL) 通用的解法就是用蒙特卡罗积分，但对任何一个fragment做会非常慢 在shader中使用采样的方法，都不能用于实时渲染(以前这么认为，现在或许有解决办法，也应该避免) 在IBL的情况下，任何一点的Shading不通过采样来得到 基本思路从观察开始 在rendering equation里面，不考虑visibility，是两个函数相乘再积分，一个是Lighting，一个是BRDF项 观察是这样的：如果BRDF是一个glossy的BRDF，渲染一幅图，从视角Incident，它覆盖的球面是很小的；如果是diffuse的BRDF，从入射方向看过来会向四面八方反射，在球面上会覆盖整个半球的区域，虽然区域非常大，但是非常smooth，它的值变化不大 如果BRDF是glossy的情况，它support就小；如果BRDF是diffuse，它就smooth 之前(Lecture 3)的近似方案 这里显示的把support写出来 在g(x)support比较小，或者g的值比较smooth的情况下，这个近似较为准确，对于BRDF来说，非常满足这个性质 所以可以做一个拆分，把除了BRDF(类比于g(x))以外的另外一项f(x)拆出来，对应这里的光照 光照在BRDF范围内的积分，去除以BRDF范围内的空的积分，做归一化 区分于做阴影时，把光照和BRDF留在里面，把visibility项拆出来，这个公式是可以根据需要来选用的 正是因为light和BRDF综合考虑挺难的，把light拆出来，发现就是在light所表示的球上，BRDF的lobe所覆盖的区域，把这个区域的light积分起来并且normalize 所说的事就是把IBL表示的图给模糊了 做拆分能够让lighting做一个pre-filter 做pre-filter能干什么： 左边不用做采样的部分拆出来后，还需要计算右边剩下的部分，是一个BRDF的积分 可以做一个预结算，这里的预计算比较麻烦，因为要把所有的参数考虑进去 如果想预计算一个积分的值，它的参数空间非常高维，需要想办法降维 人们法线菲涅尔项用Schlick这种近似方式可以写成一种形式 把R0提出来，也就是消除了对基础反射率的依赖，剩下来只有两个变量，BRDF的Roughness和入射角θi 这时想做预计算只需对两个变量打一个表 通过以上两部分的处理，可以做到不需要采样，还可以在环境光下渲染不同的物体，得到一个非常好的结果 把一个积分或求和拆开，对两边再分别进行filter或查表，分别求和，这种方式本身有个名字，叫做split sum split sum就是UE引擎PBR做到那么好的基础 Lecture 6 Real-Time Environment Mapping Shadow from Environment Lighting 不幸的是，非常难做 两个思路： As a many-light problem： 把环境光理解成多个光源，每个光源需要生成一张Shadow Map，消耗线性于光源数量 As a sampling problem： 当成采样问题，每个Shading Point去解Rendering Equation，其中Visibility项是最复杂的问题；如果做Visibility项的拆分，要求support越小越准确、g(x)越光滑越准确，而Glossy的BRDF是高频的，环境光L这项的support是整个半球，所以不太容易做 工业界在用的方法： 在环境光中取一个最具代表性的光源，比如太阳，从这个最亮的光源生成一张阴影 Backgroung knowledge 傅里叶级数变换 任何一个函数都写成一堆sin和cos的线性组合，并且这些函数都有各自对应的频率，这些函数称为基函数，这些基函数前面乘上系数再加起来，就能得到原始函数 一般讲频率的高频还是低频，就是指变化得快还是慢，不是时间层面的变化，而是在空间上，颜色变化得剧烈不剧烈 滤波(Filtering)是指去掉一系列对应频率上的内容 低通滤波器，留的是比它低频的频率 对于一张图，只保留低频的部分，还是基本能看清的 实域做卷积，相当于在频域做乘积 认为两个函数乘积再积分起来就是一个卷积&#x2F;滤波操作 可以理解成实域上的两个信号卷积，等于频域上两个信号相乘 频域上两个信号各自的频谱，其中有一个是低频的，它们在频域上相乘的结果就是低频的，再积分的结果也是低频的 只要满足上述式子的性质，叫做product integral，认为存在一定的滤波意义 Real-time environment lighting 先不考虑Shadow，在都是diffuse物体的情况下做Shading Spherical Harmonics 球面谐波函数 它是一系列二维的基函数，并且都是定义在球面上的 非常像一维的傅里叶级数 不同频率的函数个数也不同 每阶(l)的SH有2l + 1个不同的基函数，并且它们有固定的编号 前n阶有n^2个基函数 阶越高，对应的频率越高，基函数的数量也越多 每一个基函数利用勒让德多项式来写 任何一个二维的球面函数，如果展开成用SH的线性组合来描述，对于任意一个SH，Bi(x)，前面的系数ci，可以用这条性质来得到 对应位置逐点相乘再积分 用基函数来描述的时候，求任何一个基函数的系数ci的过程称做投影，任何一个函数f(ω)，都可以求出它在任何一个基函数上的投影 如果想用基函数来恢复出原来的函数，人们并不想用太多阶去表示，如果只用前四阶来表述，已经可以得到不错的结果，恢复出的函数只保留了最高阶的频率 Recall: Prefiltering 如果有一个环境光，沿着镜面反射方向去查它的某一个值，会感觉在看一个镜子 如果先把环境光做一个filtering，也就是模糊，同样去沿着镜面反射方向查它的某一个值，看上去就是diffuse 所以Prefiltering过的环境光加上一次查询，就好像不做任何的滤波，在任何一个点去查任何一个方向的环境光它的值是多少，这两个基本等价 Diffuse Shading in Render Equation Diffuse BRDF之所以简单，因为Diffuse是Smooth的 在Rendering Equation里，我们要解决的是Lighting乘以BRDF，只考虑Shading，没有Visibility项 Lighting是整个Environment map过来的一个球面函数，整个BRDF是定义在半球上面的很光滑的函数，它们两个做逐点的相乘然后积分起来，正是product integral的操作 环境光可能很复杂，有高频有低频，而BRDF在Diffuse时有个很好的性质，好像是一个低通滤波器 所以，是否可以用很少的SH基函数来描述Diffuse的BRDF，实际上用三阶就可以很好地描述 可以理解为，要把Diffuse BRDF投影到SH，只有前面几阶有值，意味着它根本就没有后面几阶描述的高频信息 由于两个函数做product integral时，两个函数乘出来的结果的频率肯定由较低频率的函数决定。因此环境光不管有多高频，只要用它照亮一个Diffuse物体，基本看不到什么高频信息 显而易见的是，diffuse球上不会反射出多复杂的光照 既然BRDF可以用非常低频的前三阶SH来描述，那为什么Lighting要用那么高的频率呢 结论：对于任何的光照条件，只要材质是Diffuse的，都可以用前三阶的SH来描述光照，用它照亮Diffuse的物体 剩下的问题： 没有阴影 其他材质 PRT PRT的思想认为，整个场景其他东西都不变，只有光照可以发生变化 把Rendering Equation里面看成两部分 把Lighting表述成一系列基函数乘系数再相加 Diffuse下计算Shadow + Shading 代价是场景中的物体都不能动 对于预计算的光源，如果把它投影到SH上，如果光源发生了旋转，可以立刻得到旋转之后SH前面的系数如何变换 SH有一些很好的性质 正交性：SH是一组正交基。把一个基函数投影到任意的另外一个基函数上去，会得到0(投影到自己是1) 非常支持旋转，任何一个旋转后的基函数，都可以被同阶的基函数的线性组合得到 Lecture 7 Real-Time Global Illumination (in 3D) Diffuse Case 对于lighting和light transport如何做预计算 上节中从Rendering Equation出发，先把lighting写成一个加数的描述方法，剩下的部分就好像把light transport投影到basic function上。这是一种理解 另外一种理解是不考虑先后顺序，两部分分别做 变成一个双重求和的问题 由于基函数的正交性，只有p和q是相同的基函数时，右边的结果才是1，否则为0 Glossy Case Glossy与Diffuse区别在于BRDF，Diffuse的BRDF是一个常数，而Glossy的不是，是四维的函数(两维输入，两维输出，用phi和theta定义一个角) Glossy的物体是和视角有关的，给一个不同的视角就会有不同的结果 既然已经将四维的light transport投影到一个二维的东西上去了，剩下来系数Ti虽然是o的函数，但也只是o的函数了 既然是二维的o的函数，可以在o的方向上投影到SH上去，就能得到light transport这里不再是一个向量了，而是一个矩阵 为什么说可以把多次反射当成light transport的一部分 一些更高阶的算法中，可以对不同的路径分类，可以用一系列的表达式来描述一系列的路径都是什么类型 比如光线从发出就直接被看到，可以写成LE(Light Eye) 正常情况下区分材质，特别是在实时渲染里面，一般分为三种：Diffuse、Specular、Glossy 对于任意复杂的light transport都可以认为等于是给定了一个光照，整个光照就是SH的基函数，用它渲染出来的结果 总结之前最早的这篇PRT 提出了用SH的基函数来描述lighting和light transport两部分 对于Diffuse的情况下，可以在实际的渲染过程中每个顶点做一个点乘的操作 对于Glossy的情况下，每个顶点做一个向量乘以矩阵的操作 它有它的问题 SH基本上只适合用于描述低频的函数 由于是预计算，要求场景是静态的、材质是静态的(BRDF是预计算的，不能改变) Wavelet 小波函数 定义在图像块上 压缩方式： 对于任何一个2D的函数，可以投影到任何一个小波的基函数上去，会发现大量的时候是这种情况，很多基函数对应的系数是接近0的 压缩思路就是取对应系数最大的几个，接近0的都不要了 这种保留非0或取最大的几个来近似地描述或恢复原始函数，和SH相比，有个最大的好处是支持全频率的表示 怎么样把任何一个函数投影到小波上去，如何用它描述球面上的函数 用CubeMap 每张图单独做小波变换，把每一张图投影成小波的系数 对于任何一张图，它都把高频信息留在右上、右下、左下三个小块里面，稍微低频的东西集中在左上 左上还可以继续做小波变换，可以发现绝大部分地方是0 不断去做小波变换，可以得到不错的结果 JPEG的格式用了类似于小波变换的变化：离散余弦变换(DCT Discrete cosine transform)。 通过先投影，再取非0的投影出来的系数，得到非常强烈的压缩 小波不支持快速旋转 Real-Time Global Illumination (in 3D) 全局光照 &#x3D; 直接光照 + 间接光照 实际上人们解决的就是比直接光照多一次bounce的间接光照，人们希望实现起来简单、快速 想要得到p点间接光照的结果(用次级光照得到的Shading)需要什么? 1.哪些是次级光源&#x2F;哪些点会被直接光照照到 &#x3D;&gt; Shadow Map 2.它们各自的贡献是多少 如果需要用次级光源(Shadow Map上的每个像素)去照亮点p，观察方向相当于从点p去观察这些次级光源，所以出射方向是未知的，无法计算Shading 因此，为了不依赖出射方向，假设所有的反射物(Reflector)都是Diffuse，不需要假设接收物(点p)也是Diffuse的 回顾辐射度量学 Flex&#x2F;Power : 表示能量是多少 Radiant Intensity : 一个单位立体角上对应的能量是多少 Irradiance : 单位面积对应的能量 Radiance : 单位面积、单位立体角上对应的能量 先考虑一个patch，最后把所有的加起来 避免浪费，在light上采样 用变量替换的方式把立体角描述成对Area的积分 对于一个Diffuse的reflective patch，BRDF是一个常数 出射的Radiance如何跟BRDF联系起来 BRDF定义：出射的Radiance除以入射的Irradiance Irradiance定等于Flex除以这块面积 当把Li如此描述后代入，会发现Area都被消掉了 距离如果离得非常远，它的贡献非常少，，所以对于一个Shading Point，只需要找离它足够近的次级光源就行了 这个观察引出了一个猜想：在世界坐标下两个点比较接近，不好找，那么就把Shading Point投影到Shadow Map上，在Shadow Map上周围的一圈找深度比较近的点 特别适用于手电筒 优点：非常好写，其实就是Shadow Map的流程 缺点： Shadow Map本身的问题，有多少个直接光源就得做多少个Shadow Map 计算过程中不去算Shading Point到反射物之间的可见性，会造成不真实的情况 做了很多假设，都会对质量造成影响 采样越多越好，tradeoff Lecture 8 Real-Time Global Illumination (screen space) Light Propagation Volumes (LPV) 要解决的核心问题：为了做全局光照(间接光照)，其实需要的是在任何一个Shading Point，如果可以立刻得到间接光照到达该Shading Point时，来自所有方向的Radiance是多少 认为Radiance在沿直线传播过程中是一个不变的量 LPV做法： 首先将3D的场景分成网格，这些格子用来传播Radiance 要知道哪些点作为次级光源 要把这些接收到直接光照的点，放进(注入 injection)划分的格子里 在三维的网格中传播Radiance 渲染 具体一点： 第一步：生成。用RSM找到场景中直接光照照亮的表面，有多少光源就得做多少RSM。可以降低当做次级光源的表面数量。完成后得到虚拟的光源 第二步：注入。工业界一般用一个三维的纹理来定义划分的格子。看任何一个格子内部是否包含了前一步得到的虚拟光源，把所有的格子内部的虚拟光源往各个不同方向的Radiance都算出来再相加，拿SH去压缩它，工业界一般用前两阶来描述这种大概的Radiance分布 第三步：传播。一个格子会传播到周围的六个格子上去，对每一个格子都会扩散到周围的六个格子上去，直到最后所有网格稳定下来(迭代四五次，每次迭代是每个格子向周围扩散) 第四部：渲染。对于任何一个Shading Point，都知道它在哪个格子里，知道格子后把这格之前接收到的incident Radiance都加起来 问题： LPV的假设中不考虑Visibility，当物体粒度比格子还小的时候，会出现Light leaking问题 Voxel Global Illumination (VXGI) 是一个两趟(two-pass)算法 与RSM的主要区别 在RSM里次级光源都是每个像素所表示的微小表面，在VXGI里场景是完全离散成微小的格子。像素-&gt;体素 ray tracing -&gt; cone tracing Real-Time Global Illumination(screen space) 屏幕空间方法：相当于做图像的后处理，认为起点是只有直接光照 Screen Space Ambient Occulusion (SSAO) 常数阴影让物体的相对位置感更强，提升视觉效果 AO是非常容易实现的 AO是全局光照的近似 在屏幕空间 假设： 不知道间接光是什么，假设间接光是一个常数 考虑Visibility AO这种渲染方式在建模软件中叫做 天光 从Rendering Equation理解AO是环境光的近似 实际上AO是一个非常简单的事，只要假设间接光照、物体的BRDF都是Diffuse也是个常数，直接从Rendering Equation拿出来，剩下对Visibility cos的积分 加权平均的Visibility在Screen Space怎么做 Ray tracing一般会考虑在一定距离范围内有无遮挡物 但是会造成超过这个范围的却真正会遮挡的物体被忽略 Screen Space AO并没有这么做 它假设任何一个Shading Point，都往周围一个半径r的球里面去采样很多的点，判断这个球的体积内随机撒的点能不能被看到 结合从摄像机获取的深度图，来判断物体能否被看到 考虑Visibility都是法线所在的半球 在AO那个时代，还不能假设Camera Ray渲染出来的场景又有深度又有Normal，可以认为有深度，得不到法线方向。 不知道法线方向就不知道哪个半球该去考虑，因此考虑整个球。而正常情况下一个平面必然有一半看不到，所以对任何一个几何做这么一个假设：在打在全球里面的点只有看不着的点(红点)个数过半的情况下，才开始考虑AO问题 采样点越多效果越好，但为了速度，不能有太多的Sample，做法是用少量的Sample先得到一张Noise的AO结果，再对它DeNoise把它模糊掉 在现在有法线的情况下，不需要SSAO做那么近似的假设，并且可以对各个方向做加权，得到更准的值 HBAO比SSAO要好一些，就是因为它真正考虑了一定范围r的半球 Lecture 9 Real-Time Global Illumination (screen space cont.)Screen Space Directional Occlision (SSDO) Screen Space Reflection (SSR) 实际上是在屏幕空间做光线追踪 动态决定步长 Lecture 10 Real-Time Physically-Based Materials (surface models) Microfacet BRDF Disney principled BRDF PBR概况： Microfacet BRDF Fresnel项告诉我们有多少百分率的能量会被反射 有多少能量被反射取决于入射光的角度 入射方向与法线几乎垂直，这时反射是最多的 根据入射角不同，有多少能量会被反射 对于绝缘体，从正上方看，很少能量被反射，基本上能透过去，如水面、镜子；从掠射角度看，能看到更多的反射 对金属来说，基本上符合这个曲线，整体反射能量会高很多 在物理上会考虑光线的S极化和P极化，以及两种极化的综合效果 但是又不太对，因为要考虑空气到物体表面各自的介质折射率，又要考虑入射角 有一个简单的估计，基础反射率R0，加上某种曲线，一开始是R0，拉到掠射角1 重要的是微表面各自的法线分布(NDF) 二维的法线分布函数模型 法线方向h的函数 高斯函数是正态函数更通用的解释，也就是中间值大，往两边衰减的形状 α一定程度上描述不同材质表面的粗糙程度，越小表示越不粗糙 tan2θ：因为BeckmannNDF是定义在坡度空间上，θ可以无限接近90°但不会超过90°，也就是不会出现面朝下的微表面 分母一系列计算是为了做归一化，为了在单位球投影变成单位圆后，在这个域上积分成1，这个单位圆的覆盖是x[-1, 1]y[-1, 1] “长尾”性质：能量衰减到一定程度后，衰减速度会放缓，带来一种自然的效果 对比Beckmann，高光的周围，高光不会消失，形成光晕的效果 希望”尾巴”更长 又叫”Geometry项”，G 解决微表面自遮挡问题 避免在Grazing angle的情况下得到非常亮的结果，是不符合事实的 越粗糙的表面，光线多次弹射的占比越大，损失的能量越多 想办法把丢失的能量补回去 基本思路：被遮挡意味着必然会继续弹射，直到被弹射出去 因此有了近似方法Kulla-Conty，通过一种经验形的方式去补全多次弹射丢失的能量 Lecture 11 Real-Time Physically-Based Materials (surface models cont.) Shading Microfacet Models using Linearly Transformed Cosines(LTC 线性变换余弦) 把任意的BRDF lobe在任意的多边形Shading转换成了在一个固定的Cosine下对任意的多边形光源进行积分的问题，这个积分是有解析解的 Disney’s Principled BRDF Why is it needed? 微表面模型并不擅长表示真实的材质 微表面模型不好用，PBR模型参数多半是物理量相关，对于艺术家不友好 High level design goal artist friendly 不保证物理完全正确 认为基本上Disney’s Principled BRDF还是PBR模型 “principled”设计原则 不使用物理量 不希望有很多参数 参数最好是0到1范围 必要时允许超过范围调整参数 某些参数的组合情况不会导致程序崩溃或效果难看 How does it work? subsurface 次表面反射 光线能够进入物体，并且从另外一个地方打出去 在BRDF上给人一种比Diffuse还要平的效果 metallic 金属度 specular 相当于Blinn-Phong模型里的ks，相当于控制有多少镜面反射的内容 specularTint 颜色是更偏白(0)，还是更偏底下材质的颜色(1) roughness 粗糙程度 anisotropic 各向异性程度 sheen 在Grazing Angle下看物体表面，有一种雾化效果 sheenTint 希望长出的”绒毛”更偏白还是偏材质颜色 clearcoat 透明的层，镀膜 类似木头上刷清漆的效果，包裹了一层糖衣 clearcoatGloss 光滑程度 Pros and Cons 易用 功能强大 实现复杂 并不是基于物理的，牺牲了物理的准确性，但不是重要问题 10维的参数空间，参数空间越大，越容易冗余 Non-Photorealistic Rendering(NPR 非真实感渲染) 等同于风格化 在实时渲染中意味着快速、可靠的风格化 NPR研究思路 从真实渲染出发 把真实渲染变成非真实 分析真实效果，转换成渲染操作 What are Styles? 轮廓渲染 渲染上 用角度阈值规定描边区域 粗细不一样 几何上 把背面的面扩一圈 图像后处理上 锐化做的就是找到图像上的边界加回到原图上，起到强调的效果 色块 做一个阈值化 可以不是二值化，可以多值化 可以在不同的部分做不同的阈值化 分析不同点应该用什么样的密度 保证不同点之间密度变化过程中，笔触的连续，所以需要设计不同密度的纹理 防止距离变远时uv缩小、密度变大、图像变暗，做一个MipMap Some Notes NPR is art driven need the ability to “translate” artists’ needs into rendering insights Communication is important Sometimes, per character, even per part Photorealistic models are super important in NPR Lecture 12 Real-Time Ray-Tracing 1 RTRT is Happening 实时光线追踪(RTRT)和Path Tracing基本上只有算法上的简化，并没有需要新的算法，本身的突破是因为硬件的能力增加 RTRT最大的问题是需要降噪 针对RTRT的降噪是非常少的 工业界的做法 Temporal 即时间上的滤波 关键点： 用递归的思维来考虑 考虑当前帧，认为当前帧的前一帧是已经滤波好了的 假设当前场景的运动是连续的 用Motion vector找到之前的对应 The G-Buffers Geometry buffer 几何缓冲区 屏幕空间的信息 在渲染场景的过程中，认为可以免费得到一些额外的信息 Back Projection 求这一帧某个点的像素对应上一帧在哪个点的方法 通过Back Projection方法做出motion vector后，只需做一个线性的blending就好 Temporal Failure screen space的问题，存的信息都在屏幕空间上 强行用上一帧信息：拖尾、拖影 Lecture 13 Real-Time Ray-Tracing 2 屏幕空间的低通滤波 滤波就是做一种模糊操作 低通滤波隐藏着两个问题 高频中也有信号，如果把高频的噪声去掉，会造成高频信息的丢失 噪声也有低频的 高斯滤波，j应该贡献多少到i上去 对任何一个像素，定义两个变量 一个叫所有权值的和，一个叫所有的加权了的贡献和 对于任何一个像素，都要考虑周围或小或大的一圈像素j，应该如何贡献到i上 归一化 用更多的feature指导滤波过程 解大的滤波 第一种解法 因为二维的高斯函数在数学上就是可拆分的 滤波就是在做卷积 但是理论上复杂的滤波拆分不出来 第二种解法 用一个逐步增大的filter做多趟的path 例子：a-trous wavelet (一个filter名) 每一趟的间隔变大，但考虑的像素还是5个 为什么要用越来越大的filter 用大的filter意味着要去除低的频率 为什么可以跳过样本 采样在频域上是在做搬移频谱，搬移的距离正好是2倍的上一趟最高频率，不会出现混叠(aliasing) Outlier Removal (and Clamping) 超级量的点在filter后会变成更大的量点 处理： 对每个像素取周围7x7 每个像素都得到7x7范围内的均值和方差 认为像素的颜色都应该集中在均值±若干个方差范围内，超出这个范围的值都认为是outlier，都claimp到这个范围 把上一帧的结果clamp到当前帧统计学的范围附近，上一帧的结果不愿意多相信它，把它clamp向当前帧 Lecture 14 A Glimpse of industrial Solution SVGF RAE 残影、overblur Temporal Anti-Aliasing (TAA) 走样是因为样本不足 TAA是从复用上一帧的一些sample，当前帧仍然使用1个SPB，思路跟RTRT使用temporal信息一模一样 有意义的数值不能反走样，图像可以反走样 Deferred Shading 延迟渲染 基本解决思路： 把场景渲染(光栅化)两次 第一次光栅化不做shading，任何的fragment只用来做对深度缓存的更新 第二次做shading，只有深度等于深度缓存的地方，才能通过测试 问题：做不了AA，但能用TAA或图像空间AA解决 Tiled Shading 把屏幕分成小块，每个小块单独做shading 通过这种方法，可以节省每个小块需要考虑的光源数量 把每块光源的数量降低到平均的光源数量 Clustered Shading 不止把屏幕空间分成若干块，还要在深度上切片，避免没有意义的Shading Level of Detail Solutions Global Illumunation Solutions "},{"title":"Unity Shader入门精要 第十八章——第二十章","date":"2024-06-20T01:30:53.000Z","url":"/2024/06/20/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-17/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"18 基于物理的渲染 18.0 之前学的光照模型都有一些缺点，它们都是经验模型。如果需要渲染更高质量的画面，这些经验模型就显得不再能满足我们的需求了 近年来，基于物理的渲染技术(Physically Based Shading, PBS)被逐渐应用于实时渲染中 Unity5引入的基于物理的渲染不需要我们过多地了解PBS是如何实现的，就能利用各种内置工具来实现一个不错的渲染效果 我们很难通过短短几万文字来非常详细地说清这些渲染到底是如何实现的，因为这其中需要牵扯许多复杂的光照模型，如果要完全理解每一种模型的话，大概还要讲很多论文和其他参考文献 18.1 PBS的理论和数学基础18.1.1 光是什么 在物理学中，光是一种电磁波。首先，光由太阳或其他光源中被发射出来，然后与场景中的对象相交，一些光线被吸收(absorption) ，而另一些则被散射(scattering) ，最后光线被一个感应器(例如我们的眼睛)吸收成像 材质和光线相交会发生两种物理现象:散射和吸收(其实还有自发光现象) 在光的传播过程中，影响光的一个重要的特性是材质的折射率(refractiveindex) 光在不同介质的边界会被分割成两个方向:反射方向和折射方向 金属材质具有很高的吸收系数，因此，所有被折射的光往往会被立刻吸收，被金属内部的自由电子转化成其他形式的能量。而非金属材质则会同时表现出吸收和散射两种现象，这些被散射出去的光又被称为次表面散射光(subsurface-scattered light) 18.1.2 双向反射分布函数(BRDF) 我们可以用辐射率(radiance)来量化光 而这个过程就可以用BRDF(Bidirectional Reflectance Distribution Function)来定量分析 BRDF有两种理解方式 第一种理解是，当给定入射角度后，BRDF可以给出所有出射方向上的反射和散射光线的相对分布情况 第二种理解是，当给定观察方向(即出射方向)后，BRDF可以给出从所有入射方向到该出射方向的光线分布。一个更直观的理解是，当一束光线沿着入射方向l到达表面某点时，f(l,v)表示了有多少部分的能量被反射到了观察方向v上 18.1.3 漫反射项18.1.4 高光反射项18.1.5 Unity中的PBS实现 Unity5一共实现了两种PBS模型，一种是基于ggx模型的，另一种是基于归一化的Blinn-Phong模型的，这两种模型使用了不同的公式来计算高光中的法线分布函数和阴影遮盖函数 在默认情况下，Unity5.2使用归一化的Blinn-Phong模型来实现基于物理的渲染，而在Unity5.3及以后的版本中，默认会使用ggx模型 18.2 Unity5的Standard Shader18.2.0 当我们在Unity5中新创建一个模型或是新创建一个材质时，其默认使用的着色器都是一个名为Standard的着色器。这个Standard Shader就使用了我们之前所讲的基于物理的渲染 18.2.1 它们是如何实现的 文件 描述 UnityPBSLighting.cginc 定义了表面着色器使用的标准光照函数和相关的结构体等，如LightingStandardSpecular函数和SurfaceOutputStandardSpecular结构体 UnityStandardCore.cginc 定义了Standard和Standard(Specularsetup)Shader使用的顶点&#x2F;片元着色器和相关的结构体、辅助函数等，如vertForwardBase、 fragForwardBase、Metallicsetup、Specularsetup函数和VertexoutputForwardBase，FragmentcommonData结构体 UnityStandardBRDF.cginc 实现了Unity中基于物理的渲染技术，定义了BRDF1_Unity_PBS、BRDF2_Unity_PBS和BRDF3_Unity_PBS等函数，来实现不同平台下的 BRDF UnityStandardInput.cginc 声明了Standard Shader使用的相关输入，包括shader使用的属性和顶点着色器的输入结构体VertexInput，并定义了基于这些输入的辅助函数，如TexCoords、 Albedo、Occlusion、SpecularGloss等函数 UnityStandardUtils.cginc Standard Shader使用的一些辅助函数，将来可能会移到UnityCGcginc文件中 18.3 更复杂的例子(略) Unity支持的两种流行的基于物理的工作流程，分别是金属工作流和高光反射工作流 在它们的实现中，都定义了两个SubShader，第一个SubShader使用的计算比较复杂，主要是针对非移动平台的，并定义了前向渲染路径和延迟渲染路径所使用的Pass，以及用于投射阴影和提取原数据的Pass；第二个SubShader定义了4个Pass，其中2个Pass用于前向渲染路径，1个Pass用于投射阴影，另一个用于提取原数据，该SubShader主要针对于移动平台 基于金属工作流的标准Shader和基于高光反射工作流的工作流会使用不同的函数来设置各个参数 18.3.1 设置光照环境18.3.2 放置反射探针18.3.3 调整材质18.3.4 线性空间 在使用基于物理的渲染方法来渲染整个场景时，应该使用线性空间来得到更好的渲染效果，在Project Setting——Other Setting——Rendering——Color Space中调整，缺点在于需要硬件来支持线性计算，在一些平台对线性空间的支持并不好 18.4 答疑解惑18.4.1 什么是全局光照 全局光照指的是模拟光线是如何在场景中进行传播的，它不仅会考虑那些直接光照的结果，还会计算光线被不同的物体表面反射而产生的间接光照 而在使用基于物理的着色技术时，当渲染表面一点时，我们需要计算该点的半球范围内所有反射到观察方向的入射光线的光照结果，这些入射光照就包含了直接光照和间接光照 18.4.2 什么是伽马校正 针对于人眼的话，人眼对光的敏感度在不同亮度上是不一样的，在正常的光照条件下，人眼对较暗的区域变化会更加敏感，也就是说，亮度上的线性变化对人眼感知来说是非均匀的 如果对拍摄的图像使用一个伽马编码，对渲染有什么影响呢 如果使输出的图像是非线性的，也就是直接输出渲染结果而不进行任何处理的话，就会导致输出的图像可能会整体偏暗，也可能会导致颜色混合的边缘颜色不正常 18.4.3 什么是HDR 在使用基于物理的渲染时，经常会看到HDR HDR是High Dynamic Range的缩写，即高动态范围 与之相对的是LDR，低动态范围 这里的动态范围通常指的是最高和最低的亮度值之间的比值。在真实世界中，一个场景中最亮和最暗区域的范围可以非常大，比如太阳发出的光会比为场景中某个影子上的点的亮度高很多 这些范围往往是操作图像或显示器能够显示的范围的，因为通常在显示设备中所使用的颜色缓存的每个通道的精度只有8位，有时只能用256种不同的亮度来显示真实世界中所有的亮度，因此这个过程中一定会存在一定的精度损失。这是早期使用伽马曲线来对捕捉到的图像进行编码，尽可能地充分利用这些有限的存储空间的原因 HDR的出现带来了一些不一样的处理方式，HDR可以使用远远高于8位的精度，比如32位来记录亮度信息，使得我们可以使用超过0~1内的一个亮度值，从而更加精确地反映真实的光照环境 通过HDR，可以让亮的物体非常亮，暗的物体非常暗，同时可以看到两者之间的细节 使用HDR来存储的图像被称为高动态范围的图像，HDR的天空盒可以更加真实地反映物体周围的环境，从而得到更加真实的反射效果 HDR对于光照叠加也有非常重要的作用，如果场景中有很多光源或是光源强度很大，那么一个物体在经过多次的光照渲染叠加后，最终得到的光照亮度可能会超过1，如果没有选择HDR，超过1的部分就会被截取到1，使得场景丢失了很多亮部区域的细节，尽管最后我们需要把它转换到LDR来进行显示，我们可以用色调映射技术来控制这个转换过程，从而保留需要的亮部细节 HDR也有一些缺点，由于使用的浮点缓冲来存储高精度的图像，从而不仅需要更大的显存空间，渲染速度也会变慢，除此之外有些硬件也不支持HDR 18.4.4 PBS适合什么样的游戏 我们需要考虑到使用PBS会带来一些代价，因为PBS会需要复杂的光照配合，比如使用大量的光照探针和反射探针等等，而且PBS也需要开启HDR及一些必不可少的屏幕特效，比如抗锯齿、Bloom和色调映射，如果这些屏幕特效对当前游戏来说需要消耗过多的性能，那么使用PBS就不适合当前游戏。同时使用PBS会和传统Shader有一些不同，普通的法线纹理和高光反射纹理的组合也不再适用，我们需要创建更加细腻复杂的纹理集，包括金属值纹理、高光反射纹理、粗糙度纹理、遮挡纹理等等 19 Unity5更新了什么19.1 场景”更亮了” Unity5之后，默认对光照强度增强2倍，让场景看起来更亮 19.2 表面着色器更容易”报错”了 这是因为Unity5表面着色器在背后会进行更多的计算，这些新添加的计算和插值计算通常是为了计算阴影和雾效、非统一缩放模型的法线变换矩阵等等，解决方法是使用更高的Shader Model就可以，另一个方法是减少表面着色器背后的计算 19.3 自己控制非统一缩放的网格 非统一缩放的网格不会由Unity在CPU中进行处理 19.4 固定管线着色器逐渐退出舞台20 世界那么大"},{"title":"Unity编辑器扩展常用方法与特性","date":"2024-06-07T01:46:48.000Z","url":"/2024/06/07/Editor-extend/","tags":[["Unity","/tags/Unity/"],["文档","/tags/%E6%96%87%E6%A1%A3/"],["Unity编辑器拓展","/tags/Unity%E7%BC%96%E8%BE%91%E5%99%A8%E6%8B%93%E5%B1%95/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp;0. 准备工作 Editor文件夹(可以多个)：主要用来存放编辑器下使用的一些脚本和资源，一般用来扩展Unity编辑器使用，不会发布到应用程序中，也不会在运行时运行 Editor Default Resources文件夹(根目录唯一)：用来存储编辑器下的一些默认资源，这些资源只能通过EditorGUIUtility.Load函数按需进行加载 Editor文件夹中的子文件夹Resources：用来存储一些原型设计时可以从脚本中按需加载的资源，其中的资源需要通过Editor脚本进行加载，并会从构建发布中剥离 Gizmos文件夹：用来存储编辑器中的特殊对象图标，用来标记特殊对象或位置，Gizmos允许将图形添加到Scene视图中，以帮助可视化不可见的设计细节。同样也不会发布到运行时 Editor文件夹内针对编辑器组件的方法，需要设置为Static方法 1. MenuItem 需要引用UnityEditor命名空间 1.1 添加菜单栏按钮[MenuItem(string path, bool? hide, int? priority)] 第一个参数：菜单的路径 第二个参数：是否为有效函数，是否需要显示 第三个参数：优先级，用来表示菜单按钮的先后顺序，默认值为1000。数值相差大于10会分栏 注意：需要是静态方法 示例： 1.2 添加菜单栏按钮快捷键 示例： 1.3 给特定组件添加右键菜单栏按钮[MenuItem(string path)] 参数：按钮的路径，以”CONTEXT&#x2F;[ComponentName]&#x2F;“开头 示例： 1.4 获取当前操作的组件MenuCommand 示例：给自定义组件Test添加右键Init按钮 2. Selection.objects 需要引用UnityEditor命名空间 返回场景或者Project中选择的多个对象 示例： 3. ContextMenu 无需引用UnityEditor命名空间 3.1 给某组件添加右边小齿轮菜单选项[ContextMenu(string buttonName)] 示例： 3.2 给某属性添加右键菜单选项[ContextMenuItem(string buttonName, string functionName)] 示例： 4. Gizmos辅助调试工具4.1 绘制 Gizmos是Scene窗口的可视化调试或辅助工具 可以通过两种方式实现 通过OnDrawGizmos或者OnDrawGizmosSelected方法，无需引用UnityEditor命名空间 通过DrawGizmos特性，需要引用UnityEditor命名空间 OnDrawGizmos方法：绘制效果一直显示 OnDrawGizmosSelected方法：绘制效果在选中对象时显示 DrawGizmo特性：该方法需要将该类放在Editor文件夹内，使用特性的方法可以将业务逻辑和调试脚本分开 GizmosType： 常用Gizmos的方法： Gizmos.DrawCube() : 绘制实体立方体 Gizmos.DrawWireCube() : 绘制立方体边框 Gizmos.DrawRay() : 绘制射线 Gizmos.DrawLine() : 绘制直线 Gizmos.DrawIcon() : 绘制Icon，Icon素材需要放在Gizmos文件夹中，代码中需要加图片后缀名 Gizmos.DrawFrustum() : 绘制摄像机视椎体的视野范围 方式一示例： 方式二示例： 一直显示主摄像机视野范围示例： 5. 特性5.1 System命名空间下的特性 Serializable : 序列化一个类，作为一个子属性显示在监视面板 NonSerialized : 反序列化一个变量，在监视面板上隐藏 5.2 UnityEngine命名空间下的特性 AddComponentMenu : 可以添加一个组件菜单项到编辑器里 效果： AssemblyIsEditorAssembly : 汇编级别的属性。带了这个属性的类就被认为是编辑器类。只能对于程序集有效 ColorUsage : 可以修改Color的配置，是否显示Alpha通道，或者使用HDR模式 参数1：是否显示透明度(Alpha) 参数2：是否用HDR模式，若为true，需要下面四个参数 3、4：最小、最大亮度 5、6：最小、最大曝光 示例：[ColorUsageAttribute(true, true)] public Color targetColor; ContextMenu : 给脚本的右键菜单添加一个自定义方法，不能是静态的 ContextMenuItem : 给字段的右键菜单添加一个自定义方法，不能是静态的 CreateAssetMenu : 用于Scriptable的子类，使其可以在Asset菜单项中创建 参数1：fileName 新创建的此类实例使用的默认文件名（创建文件必须以 .asset 结尾） 参数2：menuName 此类型显示的名称显示在”Asset&#x2F;Create”菜单中 参数3：order 菜单项在”Asset&#x2F;Create”菜单中的位置 示例： Delayed : 用于float、int或string变量，只有按了回车或焦点离开字段才会返回新值 DisallowMultipleComponent : 用于MonoBehaviour或其子类，不能重复添加这个类的组件，重复添加会弹出对话框 ExecuteInEditMode : 带了这个特性的实例会直接在编辑模式下执行，但不是像进入游戏模式那样时刻执行 （1）Update在这个场景中任意物体变化了执行 （2）OnGUI在Game View接收到一个Event时执行 （3）OnRenderObject和其他渲染回调函数在Scene View或Game View重新渲染时执行 GUITarget : 选择哪些显示器调用OnGUI函数 示例： Header : 标题特性，给监视面板上的属性加一个小标题 HelpURL : 给类提供一个自定义文档URL，可以点击组件右上角小书或代码中按Ctrl+鼠标左键跳转到目标 HideInInspector : 在监视面板里隐藏变量，不改变序列化属性 ImageEffectAllowedInSceneView : 使用了这个特性的图像特效可以渲染在SceneView的摄像机上 ImageEffectOpaque : 可以在不透明通道直接执行图像特效 ImageEffectTransformsToLDR : 在HDR渲染模式下，使用图像特效用LDR渲染模式 ImageEffet在Unity Pro上才有 Multiline : 可以让string变量在监视面板上多行显示 PreferBinarySerialization : 只能用于ScriptableObject子类，用二进制序列化，有利于处理大量数据的资源文件，提升读写性能。主要缺点是二进制的文件我们看不懂，并且不能用版本控制软件合并它 Property : 监视面板里面修改样式的抽象基类，例如显示小标题、显示多行编辑文本等等都是以它为基类 Range : 在监视面板里限制int或float类型的变量值 RequireComponent : 自动添加需要的组件。若已存在则不额外添加。这使得脚本可以安全的使用该组件 RPC : 用于Networking，但废弃了 RuntimeInitializeOnLoadMethod : 不用作为组件添加到对象也可以直接自动调用初始化方法。要求方法为静态，类、方法可以为私有。当游戏开始就会调用，但有多个这种特性的方法调用时，执行顺序是不能确定的 场景加载前调用：[RuntimeInitializeOnLoadMethodAttribute(RuntimeInitializeLoadType.BeforeSceneLoad)] 场景加载后调用：[RuntimeInitializeOnLoadMethod(RuntimeInitializeLoadType.AfterSceneLoad)] SelectionBase : 带这个特性的GameObject，如果点击本身就一定选中本身，即便父对象也有这特性；如果子对象没有带这个特性，则当在场景点击子对象时，选中的是带特性的父对象；如果父对象和父父对象都有这特性，选父对象 SerializeField : 序列化字段，主要用于序列化私有字段 SharedBetweenAnimators : 用于StateMachineBehaviour，类似Prefab，Animator之间共用这个实例，减少内存消耗 Space : 在监视面板上加空行 TextArea : 让string在监视面板上显示成带滚动条的文本域 第1参数：默认显示几行，默认值为3 第2参数：最多显示几行，默认值为3 [TextArea]默认显示3行，最多显示3行，超出自动显示滚动条 [TextArea(2,5)]默认显示2行，最多显示5行，当大于5行，会自动显示滚动条 Tooltip : 给监视面板的字段添加小贴士，即鼠标指向字段显示的提示 UnityAPICompatibilityVersion : 用来声明程序集API版本，避免处理时是否可以用旧版本的Unity API 5.3 UnityEditor命名空间下的特性 CallbackOrder : 所有带order(顺序)回调属性的特性基类 CanEditMultipleObjects : 使自定义编辑器支持同时编辑多个对象，一般配合CustomEditor使用类 示例： CustomPreview : 添加自定义类型的preview在监视面板 CustomPropertyDrawer : 自定义属性渲染，如果要自定义PropertyDrawer或DecoratorDrawer，要加上该特性 DrawGizmo : 自定义Gizmo渲染方法，用法见4.1方法二 InitializeOnLoad : 当Unity工程装载时，会自动调用一个类来初始化，这个类必须有静态构造函数 InitializeOnLoadMethod : InitializeOnLoad的静态方法 MenuItem : 添加菜单项，必须是静态方法。第二参数若为true，则会先判断该方法是否返回true，是则可以使用，否则按钮是不可用(灰色)的 PreferenceItem : 给Preference窗口添加菜单项，调用的也是静态方法 官方示例： 6. 自定义Inspector面板 新建一个脚本(一般命名为需要被扩展的脚本名+Editor，例如Test脚本的Inspector扩展类命名为TestEditor)，脚本需要继承自Editor，我们知道自定义的Window窗口需要在OnGUI中绘制，而自定义的Inspector面板需要在OnInspectorGUI中绘制 案例： 枚举示例： 7. Inspector面板上数组或List集合的显示方式 新版本Unity已经实现了显示数组或List，以及可排序列表的功能 示例： ReorderableList可以实现通过鼠标拖动，修改列表元素的排列顺序，其命名空间为UnityEditorInternal 更多功能参考 CSDN 8. 自定义编辑器窗口 示例： 9. 具体应用通过反射来拷贝自定义组件的字段 编辑器拓展ScriptableObject的显示 拓展Spine插件中的Timeline轨道创建SkeletonAnimat Clip时自动引用SkeletonDataAsset 拓展Spine插件中SkeletonAnimation组件的AnimationName属性的popup下拉框显示方式"},{"title":"Unity Shader入门精要 第十七章","date":"2024-06-05T06:13:33.000Z","url":"/2024/06/05/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-16/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"Unity中的表面着色器探秘 17.0 在一般的渲染流程中，一般会分为顶点着色器和片元着色器两个阶段。但Unity的渲染工程师Aras则不这么认为，觉得这是一种不易理解的抽象 他说，这种在顶点&#x2F;几何&#x2F;片元着色器上的操作是对硬件友好的—种方式，但不符合我们人类的思考方式 相反，他认为，应该划分成表面着色器、光照模型和光照着色器这样的层面 其中，表面着色器定义了模型表面的反射率、法线和高光等，光照模型则选择是使用兰伯特还是Blinn-Phong等模型。而光照着色器负责计算光照衰减、阴影等 这样，绝大部分时间我们只需要和表面着色器打交道，例如，混合纹理和颜色等。光照模型可以是提前定义好的，我们只需要选择哪种预定义的光照模型即可 而光照着色器一旦由系统实现后，更不会被轻易改动，从而大大减轻了Shader编写者的工作量。有了这样的想法，Aras在随后的文章中开始尝试把表面着色器整合到 Unity中 最终，在2010年的Unity 3中，表面着色器(Surface Shader)被加入到Unity的大家族中了 虽然Unity换了一个新的”马甲”，但表面着色器实际上就是在顶点&#x2F;片元着色器之上又添加了一层抽象 按Aras的话来解释就是，顶点&#x2F;几何&#x2F;片元着色器是硬件能”理解”的渲染方式，而开发者应该使用一种更容易理解的方式 很多时候我们使用表面着色器，只需要告诉Shader，应该用纹理去填充颜色，以及使用法线纹理去填充表面法线，以及使用兰伯特光照模型，我们不需要考虑是使用前向渲染路径还是延迟渲染路径。场景中有多少光源、它们的类型是什么、怎样处理这些光源、每个Pass需要处理多少个光源等问题 17.1 可以看到，相比于顶点&#x2F;片元着色器来实现同样一个功能，表面着色器代码减少了，同时在场景中添加的点光源和聚光灯也可以很好的去实现光照效果 同时可以看到，实现光照模型的过程非常简单，甚至不需要和任何光照变量打交道，Unity就帮我们处理好了每个光源的光照结果；和顶点&#x2F;片元着色器需要包含到一个特定的Pass中不同，表面着色器的C代码是直接也必须写在SubShader中，Unity会在背后生成多个Pass，当然我们可以在SubShader一开始处使用Text来设置该表面着色器所使用的标签 一个表面着色器最重要的部分是两个结构体，以及编译指令 17.2 编译指令 编译指令会指明表面着色器所使用的表面函数和光照函数 这里的surface指明定义表面着色器的，surf是表面函数，Lambert是光照模型(光照函数) 17.2.1 表面函数 表面着色器的优点在于抽象出了”表面”这一概念。与之前遇到的顶点&#x2F;片元抽象层不同，一个对象的表面属性定义了它的反射率、光滑度、透明度等值 而编译指令中的surfaceFunction就用于定义这些表面属性 surfaceFunction通常就是名为surf的函数(函数名可以是任意的)，它的函数格式是固定的 void surf (input IN, inout SurfaceOutput o) void surf (input IN, inout SurfaceOutputStandard o) void surf (input IN, inout SurfaceOutputStandardSpecular o) 后两个是Unity5中，由于引入了基于物理的渲染，而新添加的两个结构体 它们需要配合不同的光照模型使用，会在后面介绍 17.2.2 光照函数 光照函数会使用表面函数中设置的各种表面属性，来应用某些光照模型模拟物品表面的光照效果 Unity内置了基于物理的光照模型函数，Standard和StandardSpecular(在UnityPBSLighting.cginc文件中被定义)，以及简单的非基于物理的光照模型函数Lambert和Blinn-Phong(在Lighting.cginc文件中被定义) 我们也可以定义自己的光照函数，例如： half4 Lighting &lt;Name&gt;(SurfaceOutput s, half3 lightDir, half atten); &#x2F;&#x2F; 用于不依赖视角的光照模型，例如漫反射 half4 Lighting &lt;Name&gt;(SurfaceOutput s, half3 lightDir, half3 vieDir, half atten); &#x2F;&#x2F; 用于依赖视角的光照模型，例如高光反射 17.2.3 其他可选参数 在编译指令的最后，我们还可以设置一些可选参数(optionalparams)。这些可选参数包含了很多非常有用的指令类型，例如，开启&#x2F;设置透明度混合&#x2F;透明度测试，指明自定义的顶点和颜色修改函数，控制生成的代码等。下面将选取一些比较重要和常用的参数进行更深入地说明 自定义的修改函数：除了表面函数和光照模型外，表面着色器还可以支持其他两种自定义的函数，顶点修改函数和最后的颜色修改函数 其中顶点修改函数可以为我们制定一些顶点属性，比如把顶点颜色传递给表面函数，或是修改顶点位置，实现某些顶点动画等等 颜色修改函数则可以在颜色绘制到屏幕前，最后一次修改颜色值，比如实现自定义的雾效等 阴影：我们可以通过一些指令来控制和阴影相关的代码 透明度混合和透明度测试：我们可以通过Alpha和AlphaTest指令来控制透明度混合和透明度测试 光照：一些指令可以控制光照对物体的影响 控制代码的生成：一些指令还可以控制由表面着色器自动生成的代码，默认情况下Unity会为一个表面着色器生成相应的前向渲染路径、延迟渲染路径使用的Pass 17.3 两个结构体 上节讲过，表面着色器支持最多自定义4种关键的函数：表面函数，用于设置各种表面性质，如反射率、法线等等；光照函数，是定义表面使用的光照模型；顶点修改函数，可以修改或传递顶点属性；颜色修改函数，对最后的颜色进行修改 这些函数的信息传递是怎么实现的呢，比如想把顶点颜色传递给表面函数，从而添加到表面反射率的计算中，要怎么做呢，这就是两个结构体的工作 一个表面着色器需要使用两个结构体，分别是表面函数的输入结构体Input及存储表面属性的结构体SurfaceOutput，Unity5中又引入了两种同种的结构体，SurfaceOutputStandard和SurfaceOutputStandardSpecular 17.3.1 数据来源：Input结构体 Input结构体包含了许多表面属性的数据来源，因此，它会作为表面函数的输入结构体(如果定义了顶点修改函数，它还会是顶点修改函数的输出结构体) Input支持很多内置的变量名，通过这些变量名可以告诉Unity需要使用的数据信息，比如uv_MainTex和uv_BumpMap，这些采样坐标是必须以”uv”为前缀的，实际上也可以使用”uv2”，表明是使用次纹理坐标结构，后面紧跟纹理名称。 以主纹理_MainTex为例，如果需要使用它的采样坐标，就需要在Input结构体中声明float2 uv_MainTex 其他变量： float3 viewDir：包含了视角方向，可用于计算边缘光照等 使用COLOR语义定义的float4变量：包含了插值后的逐顶点颜色 float4 screenPos：包含了屏幕空间的坐标，可以用于反射或屏幕特效 float3 worldPos：包含了世界空间下的位置 float3 worldRefl：包含了世界空间下的反射方向，前提是没有修改表面法线o.Normal float3 worldRefl; INTERNAL_DATA：如果修改了表面法线o.Normal，需要使用该变量告诉Unity要基于修改后的法线计算世界空间下的反射方向。在表面函数中，需要使用WorldReflectionVector(IN, o.Normal)来得到世界空间下的反射方向 float3 worldNormal：包含了世界空间的法线方向，前提是没有修改表面法线o.Normal float3 worldNormal; INTERNAL_DATA：如果修改了表面法线o.Normal，需要使用该变量告诉Unity要基于修改后的法线计算世界空间下的法线方向。在表面函数中，需要使用WorldNormalVector(IN, o.Normal)来得到世界空间下的法线方向 我们不需要去计算这些变量，而只需在Input结构体上按上述名称严格声明这些变量就可以了，Unity会在背后为我们准备好这些数据，我们只需在表面函数中直接使用就可以了 一个例外的情况是，我们定义的顶点修改函数，必须要向表面函数中传递一些自定义的数据。比如自定义雾效，我们可能需要在顶点修改函数中根据顶点在视角空间下的位置信息去计算雾效混合系数，像这样我们就可以在Input结构体中去定义自己的变量，并把计算结果存储在该变量后进行输出 17.3.2 表面属性：SurfaceOutput结构体 有了Input结构体来提供所需要的数据后，我们就可以据此计算各种表面属性 因此，另一个结构体就是用于存储这些表面属性的结构体，即SurfaceOutput、SurfaceOutputStandard和SurfaceOutputStandardSpecular，它会作为表面函数的输出，随后会作为光照函数的输入来进行各种光照计算 相比与Input结构体的自由性，这个结构体里面的变量是提前就声明好的，不可以增加也不会减少(如果没有对某些变量赋值，就会使用默认值) 在一个表面着色器中，我们只需选择上述三者中的其一就可以了，这取决于所使用的光照模型 Unity内置的光照模型有两种，一种是Unity5之前的简单的非基于物理的光照模型，包含了Lambert和Blinn-Phong；另一种是Unity5添加的基于物理的光照模型，包括Standard和StandardSpecular，这种模型会更加符合物理的规律，但是计算也会复杂很多 一般使用非基于物理的光照模型就使用第一种结构体，使用基于物理的光照模型就使用下面两种结构体 其中SurfaceOutputStandard结构体用于默认的金属工作流程，而SurfaceOutputStandardSpecular结构体用于高光工作流程 本节中先介绍SurfaceOutput结构体中的变量和含义 在表面函数中，我们需要根据Input的结构体去传递各个变量，计算表面的属性 这里对光源的反射率进行计算，它通常是由采样纹理和颜色属性来得到的 然后是Normal表面法线方向 然后是Emission自发光，Unity通常会在片元着色器最后输出前，通过使用简单的颜色叠加来加上Emission的值 之后是Specular，是高光反射中的指数部分的系数，它会影响高光反射的计算 接下来是Gloss，它是高光反射中的强度系数 最后是Alpha，透明通道，如果开启透明度的话，会使用该值进行颜色混合 17.4 Unity背后做了什么 尽管表面着色器极大的减少了我们的工作量，但它带来的另一个问题是，我们经常不知道为什么会得到这样的渲染结果，如果我们不管这些的话，我们可以很轻松地用它来实现一些不错的渲染效果。但是我们往往也会有这样的疑问，为什么场景里没有灯光，但物体不是全黑的；又或者把光源的颜色调成黑色，物体还是会有一些渲染颜色。这些问题都源于表面着色器对我们隐藏了一些实现的细节。如果想要更加得心应手地使用表面着色器，我们需要学习它的工作流水线，并了解Unity是如何为一个表面着色器生成对应的顶点&#x2F;片元着色器的 表面着色器的本质就是包含了很多Pass的顶点&#x2F;片元着色器 这些Pass有些是为了针对不同的渲染路径，例如，默认情况下Unity会为前向渲染路径生成LightMode为ForwardBase和ForwardAdd的Pass，为Unity5之前的延迟渲染路径生成LightMode为PrePassBase和PrePassFinal的Pass，为Unity5之后的延迟渲染路径生成LightMode为Deferred的Pass 可以在Unity中点击Show generated code按钮来查看背后生成的代码，通过查看这些代码，我们就可以了解Unity是如何根据表面着色器来生成各个Pass 首先会直接将表面着色器之间的cg代码部分复制过来，这些代码包含了Input结构体和表面函数、光照函数等变量和函数的定义 对比前面的表面着色器代码，前面部分是完全一样的，在cg代码之间就不一样了，我们在表面着色器定义的这些函数和变量会在之后的处理过程中被当成正常的结构体和函数来进行调用 流程为：顶点数据——&gt;输入给顶点着色器——&gt;输入给片元着色器。在顶点着色器中又会经过两块，第一块是顶点修改函数，再经过根据Input的需要去计算的变量，并存储在相应的结构体中，之后输入到片元着色器，在片元着色器中，首先会填充Input结构体，然后进入表面函数，再进入光照函数，如果有其他对颜色的修改，比如添加逐顶点光照的话，会继续往后加入可选的函数，最后输出最终颜色 在代码中，首先会生成顶点着色器的输出，也就是v2f_surf结构体，用于在顶点着色器和片元着色器之间进行数据传递，Unity会分析我们在自定义函数中所使用的变量，比如纹理坐标、视角方向、反射方向等等，会根据我们预定义的不同，分别调用不同的surface结构体。有时我们在Input中定义了某些变量，但Unity在分析后续代码时，如果发现我们并没有使用这些变量的话，那么这些变量是不会在v2f的surface中生成的，也就是说Unity做了一些优化，v2f中还包含了一些其他需要的变量，就比如阴影纹理坐标、光照纹理坐标、逐顶点光照等等 接着去生成顶点着色器，也就是vert_surf，Unity会首先调用顶点修改函数来修改顶点数据，或填充我们自定义的Input结构体变量，然后Unity会分析顶点着色器中修改的数据，在需要时通过Input结构体将修改的结果存储到v2f_surf相应的变量中。在计算v2f_surf中其他生成的变量值里面，会包括顶点位置、纹理坐标、法线方向、逐顶点光照、光照纹理的采样坐标等等。最后通过v2f_surf传递给接下来的片元着色器 片元着色器也就是frag_surf，它会使用v2f_surf中的对应变量来填充Input结构体，比如纹理坐标、视角方向等等，以及它会去调用我们自定义的表面函数，接下来调用光照函数去得到初始的颜色值。如果使用的是内置Lambert或Blinn-Phong光照函数的话，Unity还会去计算动态全局光照，并添加到光照模型的计算中，之后就进行其他的颜色叠加，比如如果没有使用光照烘焙的话，还会添加逐顶点的光照的影响，最后，如果自定义了最后的颜色修改函数，Unity还会调用它来进行最后的颜色修改 17.5 表面着色器实例分析实现沿法线方向扩张顶点位置 为了分析表面着色器中4个可自定义函数(顶点修改函数、表面函数、光照函数和最后的颜色修改函数)的原理，在本例中对这4个函数全部采用了自定义的实现方式 在顶点修改函数void myvert中，使用顶点法线来对顶点位置做偏移 表面函数void surf中，使用了主纹理去设置表面属性中的反射率，并使用法线纹理去设置表面的法线方向 光照函数half4 LightingCustomLambert就是实现简单的Lambert漫反射光照模型 在最后的颜色修改函数void mycolor中，简单地使用颜色参数对输出的颜色进行调整 除了这4个函数外，还在#pragma surface编译指令一行中指定了一些额外的参数。由于修改了顶点位置，需要对其他物体产生正确的阴影效果，它并不能直接依赖某FallBack中找到的阴影投射的Pass。addshadow的参数告诉Unity要生成一个该表面着色器对应的阴影投射的Pass，默认情况下Unity会为所有支持的渲染路径去生成相应的Pass，我们为了缩小自动生成的代码量，可以使用exclude_pass:deferred和exclude_pass:prepass来告诉Unity不要为延迟渲染路径生成相应的Pass。最后使用nometa的参数去取消对提取原数据的Pass生成 Unity会生成3个Pass，即ForwardBase、ForwardAdd及ShadowCaster，分别对应了前向渲染路径中的处理逐像素平行光的Pass、处理其他像素光的Pass、处理阴影投射的Pass，其中有大量的if和def语句，这些可以判断一些渲染条件，比如是否使用了动态光照纹理，是否使用了逐顶点光照，是否使用了屏幕空间的阴影等等，Unity会根据这些条件来进行不同的光照计算，而这正是表面着色器的魅力，把所有烦人的光照计算都交给Unity来做 17.6 表面着色器的缺点 表面着色器只是Unity在顶点&#x2F;片元着色器上面提供的一种封装，是一种更高层的抽象 任何在表面着色器中完成的事情，都可以在顶点&#x2F;片元着色器中重现。不幸的是，这句话反过来并不成立 任何事情都是有代价的，如果我们想要得到便利，就需要牺牲自由度为代价 表面着色器虽然可以快速实现各种光照效果，但我们失去了对各种优化和各种特效实现的控制 因此，使用表面着色器往往会对性能造成一定的影响，而内置的Shader，例如Diffuse、Bumped Specular等都是使用表面着色器编写的 尽管Unity提供了移动平台的相应版本，例如Mobile&#x2F;Diffuse和Mobile&#x2F;Bumped Specular等，但这些版本的Shader往往只是去掉了额外的逐像素Pass、不计算全局光照和其他一些光照计算上的优化 "},{"title":"UI动效 05","date":"2024-05-28T09:28:36.000Z","url":"/2024/05/28/MyUIProject-05/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["UI","/tags/UI/"],["动效","/tags/%E5%8A%A8%E6%95%88/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"按钮UI动效——水波纹涟漪点击效果 效果图： 按钮Mask贴图：可以自己画 源代码： Shader(不使用SDF)： Shader(使用SDF)： C#(两种shader共用)： "},{"title":"UI动效 04","date":"2024-05-27T11:06:18.000Z","url":"/2024/05/27/MyUIProject-04/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["UI","/tags/UI/"],["动效","/tags/%E5%8A%A8%E6%95%88/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"图片UI动效——流光加载进度条 效果图： 彩色贴图： 来自网站： 源代码： Shader： C#： "},{"title":"UI动效 03","date":"2024-05-24T07:53:27.000Z","url":"/2024/05/24/MyUIProject-03/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["UI","/tags/UI/"],["动效","/tags/%E5%8A%A8%E6%95%88/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"按钮UI动效——流光按钮 效果图： 效果演示视频：视频 彩色贴图： 来自网站： 说明：比较简单的UV流动效果，一个坑点在于鼠标经过控制流速，不能用C#控制shader中的_speed变量控制uv.x +&#x3D; _Time.x * _speed，这样会重置uv的偏移量，所以这里使用了_OffsetX变量 源代码： Shader： C#： "},{"title":"UI动效 02","date":"2024-05-21T01:26:42.000Z","url":"/2024/05/21/MyUIProject-02/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["UI","/tags/UI/"],["动效","/tags/%E5%8A%A8%E6%95%88/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"图片UI动效——紫外光效果&#x2F;手电筒效果&#x2F;图片替换效果 效果图： 源码： Shader： C# "},{"title":"UI动效 01","date":"2024-05-20T07:53:49.000Z","url":"/2024/05/20/MyUIProject-01/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["UI","/tags/UI/"],["动效","/tags/%E5%8A%A8%E6%95%88/"]],"categories":[["开发记录","/categories/%E5%BC%80%E5%8F%91%E8%AE%B0%E5%BD%95/"]],"content":"按钮UI动效 效果图： 效果演示视频：视频 源代码： Shader： C#： "},{"title":"Unity Shader入门精要 第十六章","date":"2024-05-07T03:26:21.000Z","url":"/2024/05/07/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-15/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"Unity中的渲染优化技术 16.1 移动平台的特点 和PC平台相比，移动平台上的GPU架构有很大的不同 由于处理资源等条件的限制，移动设备上的GPU 架构专注于尽可能使用更小的带宽和功能，也由此带来了许多和PC平台完全不同的现象 比如，我们需要为了尽可能移除那些隐藏的表面从而减少overdraw，PowerVR芯片使用了基于瓦片的延迟渲染架构，它会把所有渲染图元装入一个个瓦片中，再由硬件找到可用的片元，而只有这些可见片元才会执行片元着色器 另一些基于瓦片的GPU架构则会使用Early-Z或相似的技术实现一些低精度的深度检测，来剔除不需要的渲染片元 还有一些GPU，如英伟达的芯片，则使用了传统的架构设计，因此在这些设备上，overdraw就会造成更多的性能瓶颈 因为芯片的架构不同，游戏往往需要针对不同的芯片发布不同版本，以便对每个芯片进行更有针对性的优化 16.2 影响性能的因素 对一个游戏来说，它最主要需要的是两种资源，分别是CPU和GPU，它们会互相合作，来让游戏可以在预期的帧率和分辨率下工作 其中CPU主要负责保证游戏的帧率，GPU主要负责分辨率相关的处理，据此可以把游戏性能瓶颈分为以下几个方面： CPU 过多的draw call 复杂的脚本或者物理模拟 GPU 顶点处理 过多的顶点 过多的逐顶点计算 片元处理 过多的片元，既可能是由于分辨率造成的，也可能是由于overdraw造成的 带宽 使用了尺寸很大且未压缩的纹理 分辨率过高的帧缓存 优化技术有： CPU优化 使用批处理技术减少draw call数目 GPU优化 减少需要处理的顶点数目 优化几何体 使用模型的LOD(Level of Detail)技术 使用遮挡剔除(Occlusion Culling)技术 减少需要处理的片元数目 控制绘制顺序 警惕透明物体 减少实时光照 减少计算复杂度 使用Shader的LOD技术 代码方面的优化 节省内存带宽 减少纹理大小 利用分辨率缩放 16.3 Unity中的渲染分析工具 渲染统计窗口(Rendering Status Window) 主要关注Graphics图像部分 Batch：一帧中需要进行批处理的数目 Saved by batching：合并的批处理数目，这个数字表面了批处理为我们节省了多少draw call Tris及Verts：需要绘制的三角面片和顶点数目 Screen：屏幕的大小及它所占用的内存大小 SetPass：渲染所使用的Pass数目，每个Pass都需要UnityRuntime来绑定一个新的Shader，这就可能造成CPU的瓶颈 Visible skinned meshes：渲染的蒙皮网格的数目 Animations：播放的动画数目 性能分析器 值得注意的是，性能分析器给出的draw call数目和批处理数目、Pass数目并不相等，而且看起来好像要大于我们估算的数目。这是因为Unity在背后需要进行很多的工作，比如初始化各个缓存、为阴影更新深度纹理和阴影映射纹理等等，因此需要花费比预期更多的draw call 因此，有一个更好的工具做查看，帧调试工具Frame Debugger 为了得到真机上的结果，也有一些其他的分析工具 Adreno分析工具 NVPerfHUD工具 Unity内置的分析器 PowerVRAM的PVRUniSCo shader分析器 Xcode中的OpenGL ES Driver Instruments 16.4 减少draw call数目16.4.0 批处理的实现原理就是为了减少每一帧需要的draw call数目。为了把一个对象渲染到屏幕上，CPU需要检查哪些光源影响了该物体，绑定shader并设置它的参数，再把渲染命令发送给GPU 当场景中包含了大量对象时，这些操作就会非常耗时，这时draw call数就会成为性能瓶颈 因此批处理的原理很简单，就是在每次调用draw call时尽可能的去处理多个物体 什么样的物体可以一起处理呢?答案就是使用同一个材质的物体。这是因为这些物体之间的不同仅仅在于顶点数据的差异，我们就可以把这些顶点数据合并在一起，再发送给GPU，就可以完成一次批处理 Unity中支持动态批处理和静态批处理 16.4.1 动态批处理 优点是一切都由Unity自动完成，不需要自己操作，而且物体是可以移动的 缺点是限制过多，一不小心就会破坏机制，导致Unity无法动态批处理一些使用相同材质的物体 随着Unity版本的迭代，这些限制条件也在改变 主要的限制在于，能够进行动态批处理的网格的顶点属性规模要小于900；如果在Shader中需要使用顶点位置、法线、纹理坐标这三个顶点属性时，它们的顶点属性不能超过300 在早期版本，所有的对象都需要使用同一个缩放尺度，现在已经不需要了 使用光照纹理的物体需要小心处理，因为需要额外的渲染参数，以及多Pass的Shader会中断批处理 16.4.2 静态批处理 优点是自由度很高，限制很少 可能会占用更多的内存，且经过静态批处理的物体不可以再移动了 相比于动态批处理来说，静态批处理适用于任何大小的几何模型。它的实现原理是，只在运行开始阶段，把需要进行静态批处理的模型合并到一个新的网格结构中，这意味着这些模型不可以在运行时刻被移动 但由于它只需要进行一次合并操作，因此，比动态批处理更加高效。静态批处理的另一个缺点在于，它往往需要占用更多的内存来存储合并后的几何结构 在内部实现中，Unity首先会把静态空间下的物体变换到世界空间下，然后为它们构建一个更大的顶点和索引缓存，对于使用了同一个材质的物体，Unity只需要使用一个draw call就可以绘制全部的物体；而对于使用不同材质的物体，静态批处理同样可以提升渲染性能，尽管这些物体仍然需要调用多个draw call，但静态批处理可以减少这些draw call之间的状态切换，这些切换往往是费时的操作 VBO是顶点缓冲对象，使用静态批处理会占用更多内存，会导致VBO数目上升。同时，如果增加一个光源的话也并没有什么关系，因为Base Pass的部分仍然会被静态批处理 16.4.3 共享材质 可以发现，无论是静态批处理还是动态批处理，都要求模型之间需要共享一个材质，但不同模型之间总会有不同的渲染属性，就比如使用了不同的纹理颜色等等，这时需要一些策略来尽可能的合并材质 如果两个材质只有使用的纹理不同，就可以把这个纹理合并到一张更大的纹理中，也就是称为图集的东西。一旦使用了同一张纹理，就可以使用同一个材质，再使用不同的采样坐标，就可以对纹理进行采样 但有时除了纹理不同，不同的物体在材质上还有一些微小的参数变化 不管是动态批处理还是静态批处理，它们的前提都是要使用同一个材质 是同一个材质，而不是使用了同一种Shader的材质，也就是说它们指向的材质必须是同一个实体 这意味着，只要我们调整了参数，就会影响到所有使用这个材质的对象。那么想要微小的调整怎么办呢? 一种常用的方法就是使用网格的顶点数据(最常见的就是顶点颜色数据)来存储这些参数 经过批处理后的物体会被处理成更大的VBO发送给GPU，VBO的数据可以作为输入传递给顶点着色器，因此就可以巧妙地对VBO中的数据进行控制，从而达到不同效果的目的 比如，森林场景中所有的树都使用了同一种材质，不同的树颜色可能是不同的，但我们希望它们可以通过批处理减少draw call，这时我们可以利用网格的顶点的颜色数据进行调整 值得注意的是，如果在脚本中访问共享材质的话，根据访问方式的不同，就有可能会将修改应用到所有的使用该材质的物体上，也有可能会创建一个该材质的复制品，从而破坏批处理在该物体上的应用 16.4.4 批处理的注意事项 尽可能选择静态批处理，但得时刻小心对内存的消耗，并且记住经过静态批处理的物体不可以再被移动 如果无法进行静态批处理，而要使用动态批处理的话，那么请小心上面提到的各种条件限制。尽可能让这些物体包含少量的顶点质性和顶点数目 对于游戏中的小道具，例如可以捡拾的金币等，可以使用动态批处理 对于包含动画的这类物体，我们无法全部使用静态批处理，但其中如果有不动的部分，可以把这部分标识成”Static” 由于批处理需要把多个模型变换到世界空间下才合并它们，因此如果Shader中存在一些基于模型空间下的坐标的运算往往会得到错误的结果，可以使用Shader中的Disable Batching标签来强制使用该系列的材质，不会被批处理 使用半透明材质的物体，通常需要严格的，从后往前的顺序绘制，从而保证透明混合的正确性。对于这些物体，Unity会首先保证绘制的正确性，再尝试对它们进行批处理。这也意味着，当渲染顺序无法满足时，批处理就无法在这些物体上成功的运用 16.5 减少需要处理的顶点数目16.5.1 优化几何体 尽可能减少模型中三角面片的数目，一些对于模型没有影响、或是肉眼非常难察觉到区别的顶点都要尽可能去掉 移除不必要的硬边以及纹理衔接，避免边界平滑和纹理分离 16.5.2 模型的LOD技术 当一个物体离摄像机很远时，模型上的很多细节是无法被察觉到的。因此，LOD允许当对象逐渐远离摄像机时，减少模型上的面片数量，从而提高性能 Unity中的LOD Group组件 16.5.3 遮挡剔除技术 遮挡剔除可以用来消除那些在其他物件后面看不到的物件，这意味着资源不会浪费在计算那些看不到的顶点上，进而提升性能 要区分视椎体剔除和遮挡剔除 视椎体剔除只会剔除那些不在摄像机视野范围内的物体，但不会判断视野中是否有物体被其他物体挡住而剔除 而遮挡剔除会使用一个虚拟的摄像机来遍历场景，从而构建一个潜在可见的对象集合的层级结构，在运行时刻，每个摄像机将会使用这个数据来识别哪些物体是可见的，哪些是被其他物体挡住不可见的 使用遮挡剔除技术不仅可以减少处理的顶点数目，还可以减少overdraw 16.6 减少需要处理的片元数目16.6.0 另一个造成GPU瓶颈的是需要处理过多的片元 这部分优化的重点在于减少overdraw 简单地说，overdraw指的是同一像素被绘制了多次 16.6.1 控制绘制顺序 为了最大限度地避免overdraw，一个重要的优化策略就是控制绘制顺序 由于深度测试的存在，如果我们可以保证物体都是从前往后绘制的，那么就可以很大程度上减少overdraw 这是因为，在后面绘制的物体由于无法通过深度测试，因此，就不会再进行后面的渲染处理 对于渲染队列小于2500的物体，它们都是从前往后绘制的，而其他的则是从后往前绘制的 16.6.2 时刻警惕透明物体 对于半透明对象来说，由于它们没有开启深度写入，因此，如果要得到正确的渲染效果，就必须从后往前渲染 这意味着，半透明物体几乎一定会造成overdraw 如果我们不注意这一点，在一些机器上可能会造成严重的性能下降 16.6.3 减少实时光照和阴影 实时光照对于移动平台是一种非常昂贵的操作。如果场景中包含了过多的点光源，并且使用了多个Pass的Shader。那么很有可能会造成性能下降 可以用烘焙技术，把光照提前烘焙到一张光照纹理上，在运行时刻只需要根据纹理去采样得到光照结果就可以了 另一种方法是使用GodRay，场景中很多小型的光源效果都是靠这种方法来模拟的，它们一般并不是真的光源，很多时候是通过透明纹理的模拟来得到的 在实际的游戏中，很多看起来非常复杂的高级的光照计算都是优化后的结果，开发者们通过把复杂的光照计算存储到一张查找纹理中，也就是LookUpTexture(LUT)，在运行时刻只需要使用光源方向、视角方向和法线方向等参数对LUT进行采样，就可以得到光照效果。可以给影响中的主角使用更大分辨率的LUT，而一些NPC则使用较小的LUT 实时阴影也是一个非常消耗性能的结果，不仅使CPU需要提高更多的draw call，GPU也需要进行更多的处理，因此我们应该尽量减少实时阴影。例如，通过烘焙把静态物体的阴影信息存储到光照纹理中，而只对场景中的动态物体使用适当的实时阴影 16.7 节省带宽16.7.1 减少纹理大小 之前提到过，使用纹理图集可以帮助减少draw call的数目，而这些纹理的大小同样是一个需要考虑的问题 需要注意的是，所有纹理的长宽比最好是正方形，而且长宽值最好是2的整数幂。这是因为有很多优化策略只有在这种时候才可以发挥最大效用 使用MipMap 不同的纹理压缩格式 16.7.2 利用分辨率缩放 过高的屏幕分辨率也是造成性能下降的原因之一，尤其是对于很多低端手机。除了分辨率高其他硬件条件并不尽如人意,而这恰恰是游戏性能的两个瓶颈:过大的屏幕分辨率和糟糕的GPU 因此，我们可能需要对于特定机器进行分辨率的放缩。当然，这样可能会造成游戏效果的下降，但性能和画面之间永远是个需要权衡的话题 16.8 减少计算复杂度16.8.1 Shader的LOD技术 Shader的LOD技术可以控制使用的Shader等级。它的原理是，只有Shader的 LOD值小于某个设定的值，这个 Shader才会被使用，而使用了那些超过设定值的Shader的物体将不会被渲染 在Shader中使用，只需加上LOD标签，比如LOD 200，这样的话只有Shader的LOD值小于设定的值，这个Shader才会被使用，而超过设定值的物体不会被渲染 16.8.2 代码方面的优化 在实现游戏效果时，我们可以选择在哪里进行某些特定的运算。通常来讲，游戏需要计算的对象、顶点和像素的数目排序是对象数&lt;顶点数&lt;像素数 因此，我们应该尽可能地把计算放在每个对象或逐顶点上 首先第一点是，尽可能使用低精度的浮点值进行运算 对于绝大多数GPU来说，在使用插值寄存器把数据从顶点着色器传递始下一个阶段时，我们应该使用尽可能少的插值变量 尽可能不要使用全屏的屏幕后处理效果。如果美术风格实在是需要使用类似 Bloom、热扰动这样的屏幕特效，应该尽量使用fixed&#x2F; lowp进行低精度运算（纹理坐标除外，可以使用half&#x2F;mediump)。那些高精度的运算可以使用查找表(LUT)或者转移到顶点着色器中进行处理 16.8.3 根据硬件条件进行缩放 一个非常简单且实用的方式是使用所谓的放缩(scaling)思想 我们首先保证游戏最基本的配置可以在所有的平台上运行良好，而对于一些具有更高表现能力的设备，我们可以开启一些更”养眼”的效果，比如使用更高的分辨率，开启屏幕后处理特效，开启粒子效果等 "},{"title":"Unity Shader入门精要 第十五章","date":"2024-05-07T01:55:29.000Z","url":"/2024/05/07/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-14/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"使用噪声 15.1 消融效果 消融(dissolve)效果常见于游戏中的角色死亡、地图烧毁等效果。在这些效果中，消融往往从不同的区域开始，并向看似随机的方向扩张，最后整个物体都将消失不见 Shader： _BurnAmount用于控制消融程度 _LineWidth控制模拟烧焦效果的线宽，值越大，火焰边缘的蔓延范围越广 _MainTex和_BumpMap对应漫反射纹理和法线纹理 _BurnMap就是噪声纹理 还定义了一个阴影Pass，这是因为如果被剔除的区域仍然向其他物体投射阴影的话，会产生穿帮的效果，为了让阴影也能配合透明度测试产生正确的效果，需要定义一个投射阴影的Pass 15.2 水波效果 在模拟实时水面的过程中，往往也会使用噪声纹理。此时，噪声纹理通常会用作一个高度图。以不断修改水面的法线方向。为了模拟水不断流动的效果，会使用和时间相关的变量来对嗓声纹理进行采样，当得到法线信息后，再进行正常的反射+折射计算，得到最后的水面波动效果 Shader： _WaveMap是一个由噪声纹理生成的法线纹理 _CubeMap是用于模拟反射的立方体纹理 _Distortion用于控制模拟折射时的图像扭曲程度 _WaveXSpeed和_WaveYSpeed分别控制法线纹理在x和y方向上的平移速度 把Queue设置成Transparent可以确保改物体渲染时，其他所有的不透明物体已经被渲染到了屏幕上。否则就可能无法正确得到透过水面看到的图像 设置RenderType是为了在使用着色器替换时，该物体可以在需要时被正确的渲染。这通常发生在需要得到摄像机深度和法线纹理时 通过关键词GrabPass来定义一个抓取屏幕图像的Pass，在这个Pass中定义了一个字符串，该字符串内部的名称就决定了抓取得到的屏幕图像会被存储在哪个纹理中，也就是此处的_RefractionTex _RefractionTex_TexelSize可以得到该纹理的像素大小。比如一个大小为256x512的纹理，它的纹素大小就是1&#x2F;256及1&#x2F;512。需要对屏幕图像的采样坐标进行偏移时，就使用该变量 使用ComputeGrabScreenPos()函数得到对应被抓取的屏幕图像的采样坐标 之后对两个纹理运用平移和缩放 之后为了在片元着色器中把法线方向从切线空间变换到世界空间下，以便对CubeMap进行采样，因此需要在这里计算该顶点对应的从切线空间到世界空间的变换矩阵，并把该矩阵每一行分别存储在TtoW0、1、2中，其中xyz分量就是变换矩阵的分量，w分量为了不浪费，把世界空间下的顶点坐标放进去了 在片元着色器中做实际的运算 首先将w分量取出来，得到顶点的世界坐标，并用该值得到该片元对应的视角方向 利用_Time.y和WaveSpeed计算法线纹理的偏移量，并利用该值对法线纹理做二次采样 为了模拟两层交叉的水面波动效果，对两次结果相加并归一化后，就得到了切线空间下的法线方向 利用该值和_Discortion属性及_RefractionTex_TexelSize对屏幕图像的采样坐标进行偏移以模拟折射效果，_Discortion值越大，偏移就越大，水面背后的物体看起来变形程度就越大 这里选择使用切线空间下的法线进行偏移，是因为该空间下的法线可以反应顶点局部空间下的法线方向 需要注意的是，把这个偏移量和屏幕坐标的z分量相乘，是为了模拟深度最大，折射程度最大的效果。也可以把屏幕偏移值叠加到屏幕坐标上面 之后对sorPos运用透视除法，再使用该坐标对屏幕抓取的图像进行采样得到模拟的折射颜色 之后把法线从切线空间变换到世界空间下，这里使用到前面获取的变换矩阵，并据此得到视角方向对于法线方向的反射方向，随后使用反射方向对CubeMap进行采样，并把结果和主纹理颜色相乘以得到反射的颜色。同时对主纹理进行这样的纹理动画，以模拟水波的效果 为了去混合折射和反射的颜色，随后计算分量系数，使用之前的公式计算，并据此混合折射反射的颜色，以得到最终的输出颜色 15.3 再谈全局雾效 在前面讲到了如何使用深度纹理来实现一种基于屏幕后处理的全局雾效。我们由深度纹理重建每个像素在世界空间下的位置，再使用一个基于高度的公式来计算雾效的混合系数，最后使用该系致来混合雾的颜色和原屏幕颜色。前面的实现效果是一个基于高度的均匀雾效，即在同一个高度上，雾的浓度是相同的 然而，一些时候我们希望可以模拟一种不均匀的雾效，同时让雾不断飘动，使雾看起来更加飘渺 而这就可以通过使用一张噪声纹理来实现 MainCamera上的脚本： 首先获取摄像机的相关参数，这是为了计算摄像机在世界空间下的位置，以及世界空间下该像素对应摄像机的偏移量 fogDensity用于控制雾的浓度 使用的雾效模拟函数是基于高度的，因此fogStart用于控制雾的起始高度，fogEnd用于控制雾的终止高度 Shader： "},{"title":"Unity Shader入门精要 第十四章","date":"2024-04-29T02:14:47.000Z","url":"/2024/04/29/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-13/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"非真实感渲染 14.0 尽管游戏渲染一般都是以照相写实主义(photorealism)作为主要目标，但也有许多游戏使用了非真实感渲染(Non-Photorealistic Rendering，NPR)的方法来渲染游戏画面 非真实感渲染的一个主要目标是，使用一些渲染方法使得画面达到和某些特殊的绘画风格相似的效果，例如卡通、水彩风格等 14.1 卡通风格的渲染14.1.0 卡通风格是游戏中常见的一种渲染风格。使用这种风格的游戏画面通常有一些共有的特点，例如物体都被黑色的线条描边，以及分明的明暗变化等 要实现卡通渲染有很多方法，其中之一就是使用基于色调的着色技术(tone-based shading) 除了光照模型不同外，卡通风格通常还需要在物体边缘部分绘制轮廓 14.1.1 渲染轮廓线 在实时渲染中，轮廓线的渲染是应用非常广泛的一种效果 通常有以下几类方法： 基于观察角度和表面法线的轮廓线渲染 优点是简单，缺点是效果不太好 过程式几何轮廓线渲染 这种方法核心是使用2个Pass进行渲染，第一个Pass渲染背面的面片，并使用某些技术让轮廓可见，第二个Pass正常渲染正面的面片 优点在于快速有效，并且能适用于绝大多数表面平滑的模型；缺点是不适合类似于立方体这类平整的模型 基于图像处理的轮廓线渲染 12、13章介绍的边缘检测方法就属于这类 优点在于可以适用于任何种类的模型，但也有自身的局限所在，比如一些深度和法线变化很小的轮廓就无法被检测出来，比如桌上的纸张 基于轮廓边检测的轮廓线渲染 一个最大问题就是无法控制渲染轮廓的渲染风格，对于一些情况，我们希望可以渲染出独特风格的轮廓线，如水墨风等等，就可以使用这种方法来做轮廓线渲染 最后一个种类就是混合了上述的几种渲染方法 比如首先找到精确的轮廓边，把模型和轮廓边渲染到纹理中，再使用图像处理的方法识别轮廓线，并在图像空间下进行风格化渲染 14.1.2 添加高光 卡通风格中的高光往往是模型上一块块分界明显的纯色区域 对于卡通渲染需要的高光反射光照模型 14.1.3 实现 本节中，将使用过程式几何轮廓线渲染 它会在第一个Pass中，使用轮廓线颜色渲染整个边缘的面片，并在视角空间下，把模型顶点沿着法线方向向外扩张一段距离 这里将模型顶点沿着法线方向向外扩张一段距离，以此让背部轮廓线可见 如果直接使用顶点法线来进行扩展的话，对一些内凹的模型就可能会发生背面面片遮挡正面面片的情况。为了尽可能防止这样的情况，在扩张背面顶点之前，首先对顶点法线的z分量进行一些处理，使它等于一个定值，然后把法线归一化后，再对顶点做扩张 这样做的好处在于扩展后的背面更加扁平化，从而降低了遮挡正面面片的可能性 卡通风格中的高光，往往是模型上一块块分界明显的纯色区域，为了实现这种效果，就不能使用前面的光照模型 之前的Blin-Phon模型使用的是法线点乘光照方向以及视角方向和的一半，再和另一个参数进行指数操作，以得到高光反射的系数 对于卡通渲染所需要的高光反射模型，同样需要计算normal和halfdr的点积结果，但不同的是，我们会把该值和一个阈值进行比较，如果小于该阈值，高光反射为0，否则为1, 但是这个比较的过程中，会产生锯齿效果，为了防止锯齿效果，使用了smoothstep函数做了一个光滑处理 w可以选择邻域像素之间的近似导数值，得到后作为阈值 乘上step目的是在_SpecularScale为0时可以完全消除高光反射的光照 Shader： 在顶点着色器中把顶点和法线都变换到视角空间下，这时为了描边可以在观察空间中达到最好的效果 14.2 素描风格的渲染 在顶点着色器首先计算逐顶点的光照，然后根据光照的结果决定六张纹理的混合权重 使用提前生成的素描纹理来实现实时的素描风格的渲染，这些纹理会组成一个色调映射，它们会从左到右逐渐增多纹理中的笔触，以用于模拟不同光照下的漫反射效果 Shader： Hatch 0至Hatch 5对应了渲染时所使用的六张素描纹理，它们的线条密度是逐次增大的 由于素描风格往往也需要在物体的周围渲染轮廓线，因此直接使用14.1节中渲染轮廓的那个Pass，使用方法就是使用UsePass命令调用 需要计算六张纹理的混合权重，首先在v2f结构体中添加相应的变量，也就是hatchWeight0和hatchWeight1，因为是两个fixed3类型的变量，所以两个足够了 为了添加阴影效果，添加了worldPos变量以及SHADOW_COORDS宏来为阴影纹理采样坐标 对顶点坐标做基本的变化，变换到裁剪空间下，然后使用_TileFactor得到纹理采样的坐标 在计算六张纹理的混合权重前，首先需要去计算逐顶点的光照，因此，使用世界空间下的光照方向和法线方向来得到漫反射系数diff 把权重值初始化为0，并把diff缩放到0~7的范围之间，得到hatchFactor 通过判断hatchFactor所处的子区间来计算对应的纹理混合的权重 最后计算了顶点的世界坐标，并使用TRANSFER_SHADOW来计算阴影纹理的采样坐标 在片元着色器部分，得到了六张纹理混合权重后，就可以对每张纹理进行采样，并和它们对应的权重值做一个相乘，以得到每张纹理的采样颜色 同时计算了纯白在渲染中的贡献，这段方法用1减去六张纹理的权重来得到的，这是因为素描中往往会有留白的部分，因此我们希望在最后的渲染中，光照最亮的部分是纯白色 最后混合各个颜色值，并和阴影值相乘来得到最终的渲染结果 效果： "},{"title":"Unity Shader入门精要 第十三章","date":"2024-04-18T03:03:00.000Z","url":"/2024/04/18/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-12/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"使用深度和法线纹理 13.1 获取深度和法线纹理13.1.1 背后的原理 深度纹理实际上是一种渲染的纹理，只不过它里面存储的像素值不是颜色值，而是一个高精度的深度值，由于被存储在一张纹理上，深度纹理的深度范围就都是[0,1]，而且是非线性分布的 这些深度值来自于顶点变换后得到的归一化的设备坐标(Normalized Device Coordinates, NDC) 一个模型要想最终被绘制在屏幕上，需要把它的顶点从模型空间变换到齐次裁剪坐标系下，这是通过在顶点着色器中乘以MVP变换矩阵得到的 在变换的最后一步，我们需要使用一个投影矩阵来变换顶点，当我们使用的是透视投影类型的摄像机时，这个投影矩阵就是非线性的 在得到了归一化的设备坐标也就是NDC之后，深度纹理中的像素值就可以很方便的计算得到，这些深度值就对应NDC中顶点坐标的z分量的值，由于NDC中z分量的范围在[-1,1]，为了让这些值能够存储在一张图像中，就需要使用 d &#x3D; 0.5z + 0.5 这样一个公式对其做一个映射，d对应了深度纹理中的像素值，z对应了NDC坐标的z分量值 13.1.2 如何获取 在Unity中，深度纹理可以直接来自于真正的深度缓存，也可以是由一个单独的Pass渲染得到，这取决于我们使用的渲染路径和硬件 当使用延迟渲染路径，深度纹理也可以很方便的获取，因为延迟渲染会把这些信息渲染到GBuffer中，而当无法直接获取深度缓存时，深度和法线纹理是通过一个单独的Pass渲染得到的 具体而言，Unity会使用着色器替换技术，选择那些渲染类型为Opaque的物体，判断它们的渲染队列是否小于等于2500，如果满足条件就把它渲染到深度和法线纹理中 因此，需要让物体出现在深度和法线纹理中，我们必须在Shader中设置正确的RenderType标签 在Unity中，我们可以选择让一个摄像机生成一张深度纹理，或是一张深度加法线的纹理。选择前者只需要一张单独的深度纹理时，Unity会直接获取深度缓存，或是着色器替换技术选取需要的不透明物体，并使用它投射阴影时使用的Pass，也就是LightMode设置为ShadowCaster的Pass，来得到深度纹理，如果Shader中不包含这样一个Pass，那么这个物体就不会出现在深度纹理中，当然它也不能向其他物体投射阴影 深度纹理的精度通常是24或16位的 如果选择生成一张深度加法线纹理，Unity会创建一张和屏幕分辨率相同，精度为32位的纹理，也就是每个通道为8位，其中观察空间下的法线信息会被编码进纹理的R和G通道，而深度信息则会被编码进B和A通道 法线信息的获取在延时队列中是可以非常容易得到的，Unity只需要合并深度和法线缓存即可，而在前向渲染中的默认情况下是不会创建法线缓存的，因此Unity底层使用了一个单独的Pass，把整个场景再次渲染一遍来完成，这个Pass包含在底层的一个内置Shader中 Unity中获取： 只需要设置摄像机的DepthTextureMode就可以了，一旦设置好摄像机模式，就可以在Shader中通过声明的sampler2D _CameraDepthTexture变量来访问它 要想获取深度加法线纹理，只需与上DepthNormals Shader中获取后，使用SAMPLE_DEPTH_TEXTURE来采样 使用这样的获取方式有个好处就是，可以处理由于平台差异造成的问题 其中i.uv_depth是float类型的变量，它对应了当前像素的纹理坐标，是一个宏 当通过纹理采样得到深度之后，深度值往往是非线性的，这种非线性是来自于透视空间使用的裁剪矩阵，然而在我们计算过程中通常需要线性的深度值，也就是说，需要把投影后的深度值变换到线性空间下，比如视角空间下的深度值 这个过程比较复杂，不过可以直接使用Unity提供的两个辅助函数为我们进行上述的计算 13.1.3 查看深度和法线纹理 使用帧调试器查看到的深度纹理是非线性空间的深度值，而深度加法线纹理都是由Unity编码后的结果 帧调试器(Frame Debug)、 深度纹理(UpdateDepthTexture)、 深度加法线纹理(UpdateDepthNormalsTexture) 看到的画面可能是几乎全黑或全白的，这时可以把摄像机的裁剪平面距离调小，使视椎体范围刚好覆盖场景所在区域 有时，显示出线性空间下的深度信息或解码后的法线方向会更加有用，此时，我们可以自行在片元着色器中输出转换或解码后的深度和法线值 13.2 再谈运动模糊 在12.6中学习了如何通过混合多张屏幕图像来模拟运动模糊的效果 但是，另一种应用更加广泛的技术则是使用速度映射图 速度映射图中存储了每个像素的速度，然后使用这个速度来决定模糊的方向和大小 速度缓冲的生成有多种方法 一种方法是把场景中所有物体的速度渲染到一张纹理中。这种方法的缺点在于需要修改场景中所有物体的Shader代码，使其添加计算速度的代码并输出到一个渲染纹理中 另一种方法是利用深度纹理在片元着色器中，为每个像素其在世界空间下的位置，这是通过使用当前的视角乘以投影矩阵的逆矩阵，对NDC下的顶点坐标进行变换得到的，当得到世界空间下的顶点坐标后，就可以使用前一帧的视角乘以投影矩阵对其进行变换以得到该位置在前一帧中的NDC坐标，然后就可以计算前一帧和当前帧的位置差，并生成该像素的速度 这种方法的优点就是可以在一个屏幕后处理步骤中完成整个效果，但缺点就是需要在片元着色器中进行两次矩阵乘法的操作，对性能有影响 脚本： Shader： 首先利用深度纹理和当前帧的视角乘以投影矩阵逆矩阵来求得该像素在世界空间下的坐标 这个过程一开始先使用内置的宏SAMPLE_DEPTH_TEXTURE对深度纹理进行采样得到深度值d，d是NDC下的坐标映射而来的，因此想要构建像素的NDC坐标H的话就需要把这个深度值重新映射回NDC，只需要使用原映射的函数就可以了，也就是 d * 2 - 1 ，这里NDC的xy分量可以由像素的纹理坐标映射而来。当得到NDC下的坐标H后，就可以使用当前帧的投影矩阵对其进行一个变换，并把它的结果除以它的w分量，能得到世界空间下的坐标表示worldPos，一旦得到它之后，就可以使用前一帧的视角，再乘以投影矩阵对它进行变换，以得到前一帧在NDC下的坐标previousPos，同样除以w分量，最后得到位置差，也就是该像素的速度velocity，得到后，就可以使用该速度值对它的邻域像素进行采样，相加后取平均值以得到模糊的效果 之后定义了运动模糊所使用的Pass 13.3 全局雾效13.3.0 Unity内置的雾效可以产生基于距离的线性或指数雾效 如果想要在自己编写的顶点&#x2F;片元着色器中实现这些雾效，需要在Shader中添加#pragma multi_compile_fog指令，同时还需要使用相关的内置宏，例如UNITY_FOG_COORDS、UNITY_TRANSFER_FOG和UNITY_APPLY_FOG等 这种方法的缺点在于，我们不仅需要为场景中所有物体添加相关的渲染代码，而且能够实现的效果也非常有限 当需要对雾效进行一些个性化操作时，例如使用基于高度的雾效等，仅仅使用Unity内置的雾效就变得不再可行 13.3.1 全局雾效 所以本节中将学习基于屏幕后处理的全局雾效，使用这种方法我们不需要更改场景中渲染物体所使用的Shader代码，而仅仅依靠一次屏幕后处理的步骤就可以了，这种方法的自由度很高，而且可以方便地模拟出各种雾效，比如均匀的雾效、基于距离的线性或者指数雾效、基于高度的雾效等等 基于屏幕后处理的全局雾效的关键是，我们要根据深度纹理来重建每个像素在世界空间下的位置 尽管在前面模拟运动模糊时就已经实现了这个要求，即构建出当前像素的NDC坐标，再通过当前摄像机的视角乘以投影矩阵逆矩阵，得到世界空间下的像素坐标，但是这样的实现需要在片元着色器上进行矩阵乘法的操作，这通常会影响游戏的性能 在本节中，会学习一个快速从深度纹理中重建世界坐标的方法 这种方法首先会对图像空间下的视椎体射线(这个射线是从摄像机出发，指向图像上某点的射线)进行一个插值，这条射线就存储该像素在世界空间下到摄像机的方向信息，然后把该射线和信息化后的视角框架的深度值相乘，再加上摄像机的世界位置，就可以得到该像素在世界空间的位置 当我们得到世界坐标后，就可以轻松地使用各个公式来模拟全局雾效了 重建世界坐标的过程就是这行代码，只需要知道摄像机在世界空间的位置以及世界空间下该像素相对于摄像机的偏移量，把它们相减就可以得到该像素的世界坐标 其中_WorldSpaceCameraPos是摄像机在世界空间下的位置，这可以由Unity内置变量直接返回得到 而 linearDepth 乘以 interpolatedRay 则可以计算出该像素相当于摄像机的偏移量，linearDepth是由深度纹理得到的线性值，在这里是通过LinearEyeDepth来把深度纹理的采样结果转换到视角空间下的深度值，使用它可以很方便地将之前提到的非线性的结果给映射为线性的结果 interpolatedRay是前面计算得到的，它的来源是我们对近裁剪平面四个角的某个特定向量的插值，这四个量包含了它们到摄像机的方向和距离信息，我们可以利用摄像机的近裁剪平面距离、fov横坐标比来计算得到 _FrustumCornersRay的计算是在C#中定义的 在一开始先计算得到两个分量toRight和toTop，它的起点位于裁剪平面的中心，分别指向摄像机的正右方和正上方的分量 得到这两个辅助向量后，就可以计算四个角相对于摄像机的方向 由于它们并非是点到摄像机的欧氏距离，而是在z方向上的距离，因此对其做一个归一化，然后乘上缩放因子 13.3.2 雾的计算 雾效系数f有很多计算方法，在Unity内置的雾效实现中，支持三种雾效的计算方式——线性(Linear)、指数(Exponential)以及指数的平方(Exponential Squared) 雾效系数f作为混合原始颜色和雾的颜色的混合系数 这里使用的是最简单的雾效计算方式，也就是线性的雾效的计算方式，它也是基于高度的雾效 当给定一点在世界空间下的高度y之后，就可以对其计算 脚本： fogDensity用于控制雾的浓度、fogStart控制雾效的起始高度、fogEnd控制雾效的终止高度 Shader： 在v2f的结构体中除了定义顶点位置、屏幕图像、深度纹理的坐标，还定义了interpolatedRay这个变量来存储插值后的像素向量 顶点着色器中，对深度纹理的采样坐标进行了平台差异化的处理，同时决定了该点对应了四个角中的哪个角，采用的方法是判断它的纹理坐标，在Unity中纹理的(0,0)点对应了左下角，(1,1)点对应了右上角，据此来判断该顶点对应的索引，对应关系和脚本中对变量的赋值是完全一样的 实际上不同平台的纹理坐标不一定是满足上面条件的，就比如DirectX中左上角对应(0,0)点，但大多数情况下Unity会把这些平台下的屏幕图像进行翻转，因此仍然可以使用这个条件。但如果在类似DirectX的平台上开启抗锯齿，Unity就不会进行这个翻转，为了此时还可以得到相应顶点位置的索引值，也对这个索引值做了平台差异化的处理 尽管这里使用了很多判断语句，但由于屏幕后处理所用的模型是一个四边形的网格，只包含了四个顶点，所以它也不会对性能造成很大的影响 接下来首先重建该像素在世界空间下的位置 首先对深度纹理进行采样，再使用LinearEyeDepth得到视角空间下的线性深度值，之后与interpolatedRay相乘，再和世界空间下的摄像机位置相加就得到了世界空间下的位置 得到世界坐标后，模拟雾效就非常容易，在本例中实现基于高度的雾效模拟，用计算公式得到fogDensity，再和定义的参数_FogDensity相乘，再截取到0~1范围内，就可以作为雾效系数 使用这个雾效系数和原始颜色进行混合并返回 也可以使用其他公式来定义其他种类的雾效 需要注意的是，这里的实现是基于摄像机的投影类型是透视投影的前提下 如果需要在正交投影的情况下去重建世界坐标，需要使用不同的公式 13.4 再探边缘检测 之前的做法是直接对颜色信息进行边缘检测的，可以看到，物体的纹理和阴影等位置也被描上了黑边 本节将学习如何在深度和法线纹理上进行边缘检测 使用Roberts算子来进行边缘检测 定义了调整边缘线强度、描边颜色、背景颜色的参数，同时添加了控制采样距离，以及对深度和法线进行具体检测时的灵敏度参数等 sampleDistance用于控制对深度加法线纹理采样时，使用的采样距离，从视觉上来看，值越大，描的边越宽 sensitivityDepth和sensitivityNormals将会影响当邻域的深度值或法线值相差多少时，会被认为存在一条边界，如果把灵敏值调得很大，那么可能即使是深度或法线上很小的变化，也会形成一条线 在OnRenderImage()上添加一个[ImageEffectOpaque]，在默认情况下，OnRenderImage()函数在所有不透明和透明的Pass执行完毕后被调用，以便对场景中所有游戏对象产生影响，但有时我们希望在不透明Pass执行完毕后立即调用该函数，而不对透明物体产生影响，此时就可以添加这个特性 本例中只希望对不透明物体进行描边，不希望对透明物体也描边，所以添加了这个特性 Shader： 其中_Sensitivity的xy分量对应了法线和深度检测的灵敏度，zw分量并没有什么用途 为了获取摄像机的深度加法线纹理，定义了_CameraDepthNormalsTexture 同时由于需要对邻域像素进行纹理采样，也声明了存储纹理大小的变量_MainTex_TexelSize 使用四个纹理坐标对深度加法线进行了采样，之后调用CheckSame()函数分别计算对角线上两个纹理值的差异 CheckSame()的返回值为0或1，返回0表明这两个点之间存在一条边界，反之返回1 在CheckSame()函数中，首先对参数进行处理，得到两个采样点的法线和深度值，这里并没有解码得到真正的法线值，而是直接使用了xy分量，这是因为只需要比较两个深度之间的差异，而不需要真正的法线值。然后把两个采样点的对应值相减并取绝对值，再乘以灵敏度的参数，并把差异值的每个分量相加，和阈值进行比较，如果和小于0.1，返回1，说明差异不明显，不存在一条边界，否则返回0，说明差异比较明显 最后把法线和深度的结果相乘，作为组合之后的结果 有了边缘信息，就可以利用该值进行颜色混合，和之前做边缘检测是一致的 "},{"title":"Unity Shader入门精要 第十二章","date":"2024-04-07T07:32:40.000Z","url":"/2024/04/07/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-11/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"高级篇 屏幕后处理效果 12.1 建立一个基本的屏幕后处理脚本系统 屏幕后处理,顾名思义,通常指的是在渲染完整个场景得到屏幕图像后，再对这个图像进行一系列操作，实现各种屏幕特效 使用这种技术，可以为游戏画面添加更多的艺术效果,例如景深(Depth ofField)、运动模糊(Motion Blur)等 因此，想要实现屏幕后处理的基础在于得到渲染后的屏幕图像，即抓取屏幕，而Unity为我们提供了这样一个方便的接口– OnRenderImage函数 当我们在脚本中声明此函数后,Unity会把当前渲染得到的图像存储在第一个参数对应的源渲染纹理中，通过函数中的一系列操作后，再把目标渲染纹理,即第二个参数对应的渲染纹理显示到屏幕上 在OnRenderImage函数中，我们通常是利用Graphics.Blit函数来完成对渲染纹理的处理 它有3种函数声明，其中src就是当前屏幕的渲染纹理，或是上一步处理后得到的渲染纹理 参数dest是目标渲染纹理，如果值为null，则直接将结果显示在屏幕上面 参数mat是使用的材质，这个材质所用的UnityShader将会进行各种屏幕后处理操作，而src纹理将会被传递给Shader中名为_MainTex的纹理属性 参数pass的默认值为-1，表示将会依次调用Shader内的所有Pass，否则只会调用给定的所有Pass 在默认情况下，OnRenderImage函数会在所有不透明和透明的Pass执行完毕后被调用，以便于对场景中所有的游戏对象都产生影响。 但有时如果希望在不透明的Pass(渲染队列小于等于2500)执行完毕后立即调用OnRenderImage函数，从而不对透明物体产生任何影响，此时可以在OnRenderImage函数前添加Image Effect Opacity属性来实现这样的目的 总结而言，要想在Unity中实现屏幕后处理效果，过程通常如下： 首先在摄像机中添加一个用于屏幕后处理的脚本 在这个脚本中实现OnRenderImage函数来获取当前屏幕的渲染纹理 12.2 调整屏幕的亮度、饱和度和对比度 脚本: 在这个基类里，会检查一系列条件是否满足，比如当前平台是否支持渲染纹理和屏幕特效 继承这个基类的脚本需要绑定在Camera上面 在CheckShaderAndCreateMaterial()里可以指定一个Shader来创建一个用于后处理渲染的材质 首先检查Shader的可用性，通过后返回一个使用了该Shader的材质 亮度饱和度对比度脚本: 让材质使用Shader，这个材质是动态生成的 在OnRenderImage()里面给材质设置三个属性，再用Graphics.Blit()进行绘制 而这个材质会被传递给Shader中名为_MainTex的属性纹理 src传递给_MainTex；material所设定的会被传递给下面三个属性；Pass默认值是-1，它会调用Shader中所有的Pass；dest会被渲染到屏幕上面，也就是目标渲染纹理，值为null则会直接将结果显示在屏幕上面 我们需要在SubShader中定义好Pass，关闭深度写入是为了防止它挡住在其后面被渲染的物体，比如当前OnImageRender()函数在所有不透明的Pass执行完毕后立即被调用，不关闭深度写入就会影响后面透明Pass的渲染。这些状态设置可以认是用于屏幕后处理的系列的标配，其实就是关闭深度写入、关闭深度测试以及不做剔除 12.3 边缘检测 边缘检测是使用一系列边缘检测算子对图像进行卷积 12.3.0 边缘检测是描边效果的一种实现方法 12.3.1 什么是卷积 在图像处理中,卷积操作指的就是使用一个卷积核(kernel)对一张图像中的每个像素进行一系列操作 卷积核通常是一个四方形网格结构(例如2×2、3×3的方形区域),该区域内每个方格都有一个权重值 当对图像中的某个像素进行卷积时,我们会把卷积核的中心放置于该像素上，翻转核之后再依次计算核中每个元素和其覆盖的图像像素值的乘积并求和,得到的结果就是该位置的新像素值 通俗来说，原图是个w×h的矩形，算子也是个矩形，把算子矩形框覆盖在上面，对应元素做一个乘积再求和 在实际的使用中，卷积需要进行一下翻转，先上下翻转再左右翻转 12.3.2 常见的边缘检测算子 Roberts Prewitt Sobel 12.3.3 实现 使用算子: Gx会在横向上对其梯度做一个计算，Gy会在竖向上对y轴进行计算 最后会得到Gx和Gy各自的值 标准的梯度计算是用G &#x3D; sqrt(Gx^2 + Gy^2) 但平方开根号比较影响性能，可以用G &#x3D; |Gx| + |Gy|做代替 这个梯度G就可以来判断哪些像素点对应的是边缘，G越大，像素变化越剧烈，越可能是边缘 Sobel算子: 脚本: 依然继承PostEffectsBase，与之前类似，只改变了几个属性 分别用于调整边缘线强度、描边颜色、背景颜色 同时需要指明一个Shader: 接收刚才的三个参数，以及接收src的值 Camera组件上的Target Texture为空则直接输出到屏幕，不为空就输出到目标纹理上 对uv使用一个手动定义的9维数组，它对应了使用Sobel算子采样时需要的9个邻域纹理坐标 通过把采样纹理坐标的代码从片元着色器中转移到顶点着色器，可以减少运算提高性能，同时由于从顶点着色器到片元着色器的插值是线性的，因此这样的转移并不会影响纹理坐标的计算结果 相当于以每一个像素为原点(0,0)，组成9个点 16.23 利用边缘检测结果去分别计算背景为原图和纯色下的颜色值 定义水平方向和竖直方向使用的卷积和Gx和Gy，一直对9个像素进行采样 edge值越小表明它越可能是边缘点 12.4 高斯模糊 还可以使用均值模糊和中值模糊，只需要对刚才的卷积做一下更改，全部改成1&#x2F;9就得到了均值模糊 高斯模糊同样是使用卷积核做运算 σ^2为标准方差，取值一般为1；xy分别对应了当前位置到卷积中心的整数距离 要构建一个高斯核，只需要计算高斯核中各个位置对应的高斯值 为了保证滤波后的图像不会变暗，需要对高斯核中的权重进行归一化处理，即让每个权重除以所有权重的和，这样可以保证所有权重和为1，因此高斯核中e前面的系数实际上不会对结果有任何影响 在脚本中提供了调整高斯模糊的迭代次数、模糊范围和缩放系数的参数 先使用缩放系数进行缩放 然后将缩放后的原图渲染到buffer0中，缩放的方式是Bilinear线性缩放 之后根据轮数进行迭代 下采样downSample越大，需要处理的像素越少。它能进一步提高模糊程度，但过大的下采样会导致图像的像素化 模糊范围blurSpread越大，模糊程度越高，但不会影响到采样数downSample 之后循环迭代，使用高斯模糊对图像进行处理 不同在于Blit中一个0一个1，它分别会使两个Pass做这样的处理 需要使用一个中间缓存来存储第一个Pass执行完毕的结果，也就是buffer1 其实际上先用竖直方向的一维来做滤波，再使用水平方向上的一维进行滤波，这是对高斯的一个优化，它是一个矩阵二维的和，但是当n不断增加时，采样次数就变得非常巨大，所以可以将其拆成两个一维的来减少计算复杂度 Shader: 有2个Pass 在接受的过程中，会将原图也就是_MainTex传递过来，然后是模糊范围_BlurSize 使用_MainTex_TexelSize以计算相邻像素的纹理坐标的偏移量 在顶点着色器中，分别使用垂直方向和水平方向上两组来计算 数组的第一个坐标储存了当前的采样值，剩余的4个坐标，是高斯模糊中对邻域采样时使用的纹理坐标 和属性_BlurSize相乘来控制采样距离，在高斯和维数不变的情况下，_BlurSize越大，模糊程度就越高，而采样数不会受到影响，但过大的_BlurSize会造成虚影 通过把计算采样纹理的坐标从片元着色器转移到顶点着色器中，可以有效地减少运算，提高性能 在片元着色器中，之前一个5x5的二维高斯核可以拆分成两个大小为5的一维高斯核，并且由于它们的对称性，需要记录3个高斯权重，也就是代码中weight变量 首先声明了各个邻域像素对应的权重weight，将其结果sum初始化为当前像素乘以它的权重值，根据对称性进行2次迭代，每次迭代包含了2次纹理采样，并把像素值和权重相乘后的结果迭代到sum中，最后函数返回滤波的结果sum 之后定义了高斯模糊所使用的两个Pass，首先设置了渲染状态，为两个Pass使用了NAME语义来定义了它们的名字，因为高斯模糊是很常见的操作，很多屏幕特效都建立在它的基础上。为Pass定义名字后可以在其他系统中直接通过名字来使用该Pass，而不需要重复写代码 在最后关闭该Shader的FallBack 12.5 Bloom效果 Bloom特效是游戏中常见的一种屏幕效果。这种特效可以模拟真实摄像机的一种图像效果，它让画面中较亮的区域”扩散”到周围的区城中，造成一种朦胧的效果 脚本: Bloom是建立在高斯模糊基础上的，加了一个阈值来控制较亮区域阈值的大小，尽管大多数情况下图像的亮度值不会超过1，但在开启HDR后，硬件会允许颜色存在一个更高精度的范围缓冲中，此时的像素亮度值就可能会超过1，因此这里将阈值限定在0-4之间 Shader: 在这里有4个Pass,分别是第0、1、2、3个Pass 定义了较亮区域使用了顶点着色器，以及提取较亮元素所使用的片元着色器 在片元着色器中，将采样得到的亮度值减去阈值，并把结果约束到0-1之间，把该值和原像素值相乘，就得到了提取得到的亮部区域，也就是第0个Pass 在第1、2个Pass中使用前面的垂直和水平的高斯计算 接下来去混合亮部区和原图像 定义混合的过程v2fBloom vertBloom，这里使用的顶点着色器和之前的有所不同，定义了2个纹理坐标，xy订阅了原图_MainTex的纹理坐标，zw就是Bloom模糊后较亮区域的纹理坐标 在片元着色器中，直接对两个纹理做混合 12.6 运动模糊 运动模糊是真实世界中摄像机的一种效果 如果在摄像机曝光时，拍摄场景发生了变化，就会产生模糊的画面 运动模糊的实现有多种方法 一种是利用一块累积缓存(accumulation buffer)来混合多张连续的图像，当物体快速移动产生多张图像后，取它们之间的平均值作为最后的运动模糊图像 然而，这种暴力的方法对性能的消耗很大，因为想要湖区多张帧图像往往意味着需要在同一帧里渲染多次场景 另一种应用广泛的方法是创建和使用速度换成(velocity buffer)，这个缓存中存储了各个像素当前运动速度，然后利用该值来决定模糊的方向和大小 使用第一种方法实现： 我们不需要在一帧中把场景渲染多次，它需要保存之前的渲染结果，不断地把当前的渲染图像叠加到之前的渲染图像中，从而产生一种运动轨迹的视觉效果，这种方法对比原始的利用缓存累积的方法相比，性能更好，但模糊的效果会略有影响 代码： 定义了模糊参数blurAmount，值越大，运动的拖尾效果越明显。同时为了防止拖尾效果完全替代当前帧的渲染结果，把它的值截取在0~0.9范围内 定义了RenderTexture类型的变量，去保存叠加的结果 在脚本不运行时，也就是OnDisable()中会立即销毁这个累计的渲染结果，这样在下次开始运用运动模糊时，它会重新叠加图像 首先判断用于混合图像的RT是否可用，不可用则重新创建一个，创建完对它做一个调整，将它的hideFlags设置为HideAndDontSave，也就是这个变量不会显示到Hierarchy面板中也不会保存到场景中 然后使用当前帧初始化accumulationTexture，也就是在Graphics.Blit(src,accumulationTexture)这里，将当前帧渲染到accumulationTexture 当得到有效的accumulationTexture变量后，调用它的MarkRestoreExpected()函数来表明需要进行一个渲染纹理的恢复操作，恢复操作发生在渲染到纹理而该纹理没有被提前清空或销毁的情况下 在本例中，每次调用OnRenderImage()时，都需要把当前帧图像和accumulationTexture中的图像混合，而accumulationTexture不需要提前清空，因为它保存了之前的混合效果 然后将参数传递给材质，并根据材质对纹理做一个混合，最后把它直接输出到屏幕上面 Shader部分： Shader部分比较简单，经过了两个Pass，第一个Pass用于更新渲染纹理的RGB通道，另一个用于更新渲染纹理的A通道 RGB通道会对RGB的图像做一个采样，A通道直接返回采样结果就行了 实际上只是为了维护渲染纹理的透明通道值，不让其受到模糊混合时所使用的透明度值的影响 最后将结果输出，就完成了模糊的过程 这是一种运动模糊的简单实现，混合了连续帧之间的图像，就得到了一张具有模糊拖尾的图像 当然，当物体移动速度过快时，这种方法可能会造成单独的帧图像变得可见 "},{"title":"Unity Shader入门精要 第十一章","date":"2024-04-07T05:49:52.000Z","url":"/2024/04/07/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-10/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"让画面动起来 11.1 Unity Shader中的内置时间变量 名称 类型 描述 _Time float4 4个分量(t&#x2F;20, t, 2t, 3t)，t是自该场景加载开始所经过的时间 _SinTime float4 4个分量(t&#x2F;8, t&#x2F;4, t&#x2F;2, t)，t是时间的正弦值 _CosTime float4 4个分量(t&#x2F;8, t&#x2F;4, t&#x2F;2, t)，t是时间的余弦值 unity_DeltaTime float4 4个分量(dt, 1&#x2F;dt, smoothDt, 1&#x2F;smoothDt)，dt是时间增量 11.2 纹理动画11.2.1 序列帧动画 序列帧动画的原理非常简单，它像放电影―样,依次播放一系列关键帧图像，当播放速度达到一定数值时，看起来就是一个连续的动画 它的优点在于灵活性很强，我们不需要进行任何物理计算就可以得到非常细腻的动画效果 而它的缺点也很明显，由于序列帧中每张关键帧图像都不一样，因此,要制作一张出色的序列帧纹理所需要的美术工程量也比较大 11.2.2 滚动的背景 很多2D游戏都使用了不断滚动的背景来模拟游戏角色在场景中的穿梭，这些背景往往包含了多个层(layers)来模拟一种视差效果。 _MainTex、_DetailTex 第一层较远和第二层较近的背景纹理 _ScrollX、_Scroll2X 各自的水平滚动速度 _Multiplier 纹理的整体亮度 11.3 顶点动画11.3.1 流动的河流 河流的模拟是顶点动画最常见的应用之一，它的原理通常就是使用正弦函数等来模拟水流的波动效果 变量分别是，河流纹理、整体颜色、水流波动的幅度、波动的频率、波长的倒数、河流纹理的移动速度 一些SubShader在使用Unity的批处理功能时会出现问题，这是可以通过DisableBatching标签直接指明是否对该SubShader使用批处理。这些需要特殊处理的Shader通常是包含了模型空间的顶点动画Shader，这是因为批处理会合并所有相关的模型，而这些模型各自的模型空间就会丢失 定义一个偏移量offset，只控制它的x分量，相当于x &#x3D; sin(xt+y)·A 11.3.2 广告牌 另一种常见的顶点动画就是广告牌技术(Billboarding)。广告牌技术会根据视角方向来旋转一个被纹理着色的多边形(通常就是简单的四边形，这个多边形就是广告牌)，使得多边形看起来好像总是面对着摄像机。广告牌技术被用于很多应用,比如渲染烟雾、云朵、闪光效果等 _VerticalBillboarding用于调整是固定法线的还是固定指向上的方向，也就是约束垂直方向的一个程度 首先选择模型空间下的一个原点作为广告牌的一个锚点 利用内置变量获取模型空间下的视角位置 计算目标法线，根据_VerticalBillboarding来控制垂直方向上的约束度 接下来得到粗略的向上方向，为了防止法线方向和向上方向平行，对法线方向的y分量进行判断以得到合适的向上方向 根据法线方向和粗略的向上方向得到向右的方向 根据原始位置相对于锚点的偏移量以及三个正交矢量，可以得到新的顶点位置 需要说明的是，这里必须使用四边形Quad而不能使用Plane，这是因为代码是建立在一个竖直摆放的多边形的基础上的。也就是说，这个多边形的顶点结构需要满足在模型空间下是竖直排列的，这样才能使用v.vertex来计算得到正确的相对于中心的偏移位置 11.3.3 注意事项 首先，如11.3.2节看到的那样，如果我们在模型空间下进行了一些顶点动画，那么批处理往往就会破坏这种动画效果 这时，我们可以通过SubShader 的DisableBatching标签来强制取消对该Unity Shader的批处理。然而，取消批处理会带来一定的性能下降,增加了Draw Call，因此我们应该尽量避免使用模型空间下的一些绝对位置和方向来进行计算 在广告牌的例子中，为了避免显式使用模型空间的中心来作为锚点,我们可以利用顶点颜色来存储每个顶点到锚点的距离值，这种做法在商业游戏中很常见 其次，如果我们想要对包含了顶点动画的物体添加阴影，那么如果仍然像9.4节中那样使用内置的Diffuse等包含的阴影Pass来渲染,就得不到正确的阴影效果(这里指的是无法向其他物体正确地投射阴影) 这是因为,Unity的阴影绘制需要调用一个ShadowCaster Pass,而如果直接使用这些内置的ShadowCaster Pass，这个Pass中并没有进行相关的顶点动画，因此 Unity会仍然按照原来的顶点位置来计算阴影，这并不是我们希望看到的 这时，我们就需要提供一个自定义的ShadowCaster Pass，在这个Pass 中，我们将进行同样的顶点变换过程。需要注意的是，在前面的实现中，如果涉及半透明物体我们都把Fallback设置成了Transparent&#x2F; VertexLit,而Transparent&#x2F;VertexLit没有定义ShadowCaster Pass,因此也就不会产生阴影（详见9.4.5节)。 实现阴影效果: 删除所有透明效果的标签，打开深度写入，关闭混合，增加自己的ShadowCast Pass "},{"title":"Unity Shader入门精要 第十章","date":"2024-03-26T09:16:03.000Z","url":"/2024/03/26/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-9/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"高级纹理 10.1 立方体纹理10.1.0 立方体纹理是环境映射的一种实现方法 环境映射可以模拟物体周围的环境 使用了环境映射的物体，看起来像镀了一层金属一样，可以反射出周围的环境 立方体纹理一共包含了6张图像，对应了一个立方体的6个面，立方体纹理的名称也由此而来 立方体的每个面，表示沿着世界空间下的轴向（也就是上下左右前后）观察所得的图像 对这种纹理进行采样，需要提供一个三维的纹理坐标，这个坐标表示了在世界空间下的一个3D方向，这个方向矢量是从立方体的中心出发，当它向外部延伸时会和立方体纹理之一发生相交，而采样所得的结果就是由该交点计算而来的 使用立方体纹理的好处在于，它的实现简单快速，得到的效果也比较好 但它也有一些缺点： 例如当场景中引入了新的物体、光源，或者物体发生移动时，我们就需要重新生成立方体纹理 立方体纹理也仅可以反射环境，不能反射使用了该立方体纹理的物体本身。这是因为立方体纹理不能模拟多次反射的结果，因此应该尽量对凸面体而不是凹面体使用立方体纹理，凹面体会反射自身 10.1.1 天空盒子 天空盒子这个名字包含了两个信息：它是用来模拟天空的，它是一个盒子 当场景中使用了天空盒子时，整个场景就被包围在一个立方体内 如何创建一个Skybox材质 新建一个材质，假设命名为SkyboxMat 在SkyboxMat的UnityShader下拉菜单中选择Unity自带的Skybox&#x2F;6 Sided，该材质需要6张纹理 对SkyboxMat的6张纹理进行赋值，需要把6张纹理的Wrap Mode设置为Clamp，以防止在接缝处出现不匹配的现象 在Window –&gt; Lighting菜单中，把SkyboxMat赋给Skybox选项 保证渲染场景的摄像机的Clear Flags要设置为Skybox 如果想让某些摄像机不渲染该天空盒，可以设置其他的Clear Flags 如果想让某些摄像机使用不同的天空盒，可以Add Component下选择Skybox组件 在Unity中，天空盒是在所有不透明物体之后渲染的 背后使用的网格是一个立方体或一个细分后的球体 10.1.2 创建用于环境映射的立方体纹理 除了天空盒外，立方体纹理的最强用处就是用于环境映射，通过这种方法模拟出金属的材质 在Unity5中，创建用于环境映射的立方体纹理的方法有三种 第一种是直接由一些特殊布局的纹理创建 第二种是手动创建一个CubeMap资源，再把6张图赋给它 第三种是由脚本生成 第一种方法需要一张特殊布局的纹理，例如立方体展开图的交叉布局、全景布局等等，然后只需把该纹理的Texture Type设置为CubeMap即可 在基于物理的渲染中，通常会使用一张HDR图像来生成高质量的CubeMap，之后再介绍 第二种方法是Unity5之前的版本使用的方法，首先在项目资源中创建一个CubeMap，然后把6张纹理图拖到它的面板中 在Unitry5中，官方推荐使用第一种方法创建立方体纹理，这是因为第一种方法可以对纹理数据进行压缩，而且可以支持边缘修正、光滑反射和DFR的功能 前面两种方法都需要提前准备好立方体纹理的图像，它们得到的立方体纹理往往是被场景中的物体所共用的，但在理想情况下，我们希望根据物体在场景中位置的不同，生成它们各自不同的立方体纹理，这是我们就可以在Unity中使用脚本来创建 这是利用Unity提供的Camera.RenderToCubemap函数实现的，这个函数可以把从任意位置观察到的场景图像存储到6张图像中，从而创建出该位置上对应的立方体纹理 示例用法（脚本放Editor目录）： 它是利用Camera.RenderToCubemap来创建立方体纹理的代码，在renderFromPosition处动态创建了一个摄像机，名字就叫CubemapCemera，调用RenderToCubemap把从当前位置观察到的图像渲染到用户指定的立方体纹理Cubemap中，完成后销毁临时摄像机 在场景中新建一个GameObject用来表示位置，再新建一个用于存储的立方体纹理Create–&gt;Legacy–&gt;Cubemap，勾选Readable可读的，再使用菜单选项创建即可，Face size越大，渲染出的立方体纹理分辨率就越大，效果越好，但内存也越大 准备好了立方体纹理后，就可以对该物体使用环境映射技术 而环境映射最常用常见的应用就是反射和折射 10.1.3 反射 使用了反射效果的物体通常看起来就像是镀了层金属 只需要通过入射光线的方向和表面方向来计算反射方向，再利用反射方向对立方体纹理进行采样就可以了 反射shader： _ReflectColor用于控制反射的颜色 _ReflectAmount用于控制这个材质的反射程度 _Cubemap就是用于模拟反射的环境纹理映射 10.1.4 折射 折射遵循公式： η为各介质的折射率 在实时渲染中通常只模拟第一次折射 折射Shader： _RefractRatio就是需要使用该属性得到不同介质的一个透射比，以此来计算折射方向 10.1.5 菲涅尔反射 在实时渲染中，经常使用菲涅尔反射来根据视角方向控制反射程度 通俗来讲，菲涅尔反射描述了一种光学现象，即当光线照射到物体表面时，一部分发生了反射，一部分则进入物体内部发生折射或散射，被反射的光和入射光之间会存在一定的比例关系，这个比例关系可以用菲涅尔等式来进行计算 一个简单的例子，当我们站在湖边时，看近处的湖面是透明的，可以直接看到水底的石子，但当我们看远处的水面时，会发现几乎看不到水下的情景，而只能看到水面反射的环境。这就是所谓的菲涅尔效果 真实世界的菲涅尔等式是非常复杂的，但在实时渲染中，我们可以把它简化一下 F0是反射系数，用于控制菲涅尔反射的强度 可以更广泛一下：F &#x3D; max(0,min(1,bias + scale X (1-v·n)^power)) bias就是F0 使用上面的菲涅尔近似等式可以在边界处模拟反射光强和折射光强以及漫反射光强之间的变化，在许多车漆、水面等材质的渲染中，我们会经常使用菲涅尔反射来模拟更加真实的反射效果 菲涅尔Shader： 10.2 渲染纹理10.2.0 再之前的学习中，一个摄像机的渲染结果会输出到颜色缓冲中，并显示到我们的屏幕上-现代的GPU允许我们把整个三维场景渲染到一个中间缓冲中，即渲染目标纹理（Render Target Texture，RTT），而不是传统的帧缓冲或后备缓冲（back buffer） 与之相关的是多重渲染目标（Multiple Render Target，MRT），这种技术指的是GPU允许我们把场景同时渲染到多个渲染目标纹理中，而不再需要为每个渲染目标纹理单独渲染完整的场景。延迟渲染就是使用多重渲染目标的一个应用 Unity为渲染目标纹理定义了一个专门的纹理类型，也就是Render Texture 在Unity中使用渲染纹理往往有两种方式 在Project目录下创建一个渲染纹理，把摄像机的渲染目标设置成该渲染纹理，该摄像机的渲染结果就会实时更新到渲染纹理中，而不会显示在屏幕上。使用这种方法还可以选择渲染纹理的分辨率、滤波模式等纹理属性 在屏幕后处理时使用Grab Path命令或者OnRenderImage函数来获取当前的屏幕图像，Unity会把这个屏幕图像放到一张和屏幕分辨率等同的渲染纹理中， 10.2.1 镜子效果 使用Render Texture实现 10.2.2 玻璃效果 玻璃Shader： _MainTex是该玻璃的材质 _BumpMap是玻璃的法线纹理 _Cubemap是用于模拟反射的环境纹理 _Distortion是用于控制模拟折射时图像的扭曲程度 _RefractAmount用于控制折射的程度，为0时该玻璃只包含反射效果，为1时只包含折射效果 当Queue设置为Transparent可以确保该物体渲染时，会在其他所有不透明的物体都已经被渲染到屏幕上了，否则将无法正确看到透过玻璃看到图像的效果 设置RenderType是为了在使用着色器替换时，该物体可以在需要时能被正确的渲染，这通常会发生在我们需要得到摄像机的深度和法线纹理时 随后在GrabPass定义了一个抓取屏幕图像的一个Pass，该Pass中定义了一个字符串，该字符串内的名称决定了抓取得到的屏幕图像将会被存储在哪个纹理中 我们可以省略该字符串，但直接声明纹理名称的方法往往可以得到更高的性能 10.3 程序纹理10.3.1 在Unity中实现简单的程序纹理 程序纹理指的是那些由计算机生成的图像，我们通常使用一些特定的算法来创建个性化的图案或者非常真实的自然元素，例如木头或石子等等 使用程序纹理的好处就在于我们可以使用各种参数来控制纹理的外观，这些属性不仅仅是颜色属性，甚至可以是完全不同类型的图案属性，这使得我们可以得到更加丰富的动画和视觉效果 程序纹理脚本： 加上[ExecuteInEditMode]使脚本能在编辑器模式下运行 声明使用的各种属性，这里包括材质宽度、背景颜色、园的颜色、模糊因子等等 纹理大小通常是2的整数幂，模糊因子用于模糊圆形边界 在Start中获取材质，更新材质，需要有一个_MainTex的变量 生成程序纹理函数 首先初始化一张二维纹理 计算生成纹理时所需要的一些变量(圆的间隔、半径、模糊因子) 利用双重循环遍历纹理上每个像素，并在纹理上绘制9个圆形 最后调用Tex2D的Apply()强制把像素写入到纹理中并返回 10.3.2 Unity中的程序材质 在Unity中，有一类专门使用程序纹理的材质，叫做程序材质(Procedural Material) 程序材质和之前的其他材质在本质上是一样的，不同的是它们使用的不是普通的纹理，而是程序纹理 同时程序材质和它使用的程序纹理并不是在Unity中创建的，而是使用Substance Designer软件在Unity外部生成的 Unity5升级到高版本后，Substance Designer材质已经从Unity中移除，为了继续使用Substance Designer材质，需要从Asset Store中找出并安装Allegorithmic的资源包 "},{"title":"数学可视化(11)——Phong与Blinn-Phong","date":"2023-11-21T01:48:19.000Z","url":"/2023/11/21/Mathematical-Visualization-11/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 前言 对于光滑表面表现出来的镜面反射高光，Lambert模型的表现就乏力了 Phong经验光照模型 镜面反射分量的光强，与反射光线向量r及视线向量v的夹角α相关 Phong光照方程： Ispec &#x3D; Clight * mspec * (r · v)mgloss &#x3D; Clight * mspec * (cosα)mgloss Clight为光源颜色或强度 mspec为材质的镜面反射系数，也可理解为材质镜面反射的颜色 反射光线方向r可由入射方向光l和物体表面法线n求出。公式为：r &#x3D; 2 (n · l) * n - l mgloss代表光泽度，也就是物体表面的光滑程度 反射光线方向与观察方向的夹角越小，镜面反射高光的贡献值就越大，高光强度就越强 换句话说，镜面反射的光强与观察者的角度有关。Phong光照模型有助于观察者了解物体表面的弯曲情况，判断出光源方向和位置 先计算反射光方向，再根据光源颜色、镜面反射系数、反射光方向和观察者向量点乘的结果，以及光泽度，计算出镜面反射分量 白点就是Phong光照模型计算出的镜面反射分量，也就是高光的表现 再将环境光照、漫反射光照与镜面反射光叠加，就可以得到一个经典的局部光照模型了 Blinn-Phong经验光照模型 是基于Phone光照模型的修正模型，只是将公式中的(r · v)换成了(n · h) h为半角向量（半程向量），位于观察向量v与光线l的角平分线方向，可以由l+v单位化后获得，比计算反射向量r更快 对比发现，Blinn-Phong与Phong模型都有高光表现，但Blinn-Phong的高光表现在相同的光泽系数下，高光表现更为分散一些 "},{"title":"数学可视化(10)——Lambert漫反射模型","date":"2023-11-21T00:01:58.000Z","url":"/2023/11/21/Mathematical-Visualization-10/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 光照模型 分为经验光照模型、通用光照模型 经验光照模型（模拟光照，局部光照模型） Lambert HalfLambert Phong Blin-Phone Cook-Torrance … 光照分量是叠加的 Itotal &#x3D; Iamb + Idiff + Ispec Iamb 环境光 Idiff 漫反射光 Ispec 镜面反射光 通用光照模型（真实光照，全局光照模型） Lambert光照模型 当光照射到理想的漫反射体上时，漫反射光强与入射光方向和入射点的法向量之间的夹角余弦成正比。在0°~90°范围内，夹角越大，漫反射的光线越少。且反射的光强不会随着观察者角度不同发生改变 Idiff &#x3D; max((n·l),0) mdiff * sdiff n为光线入射点物体表面的法向量 l为光向量方向 mdiff为材质漫反射颜色 sdiff为光源漫反射颜色 颜色的操作分为加色与减色 一般加色对应加法，减色对应乘法 m与s项都是可以通过预定义得到的 物体受光点表面的法线是需要我们计算的 因此求物体的漫反射光照情况的前提是，要计算出物体表面各个点的法线 由于在SDF下定义一个特定点的参数曲面是f(p)&#x3D;0,因此可以通过该表面上的点的SDF梯度来计算该等值面的法线，也就是分别计算f(p)在xyz3个方向的偏导数 比较简单的方法是，可以利用梯度的定义给物体表面p点的某一个方向加上一个很小的epsilon值，来计算某个方向的前项微分值，但可能会存在后项差异 因此，我们可以将前项与后项微分的值相加除以二来消除这种后项微分可能性的差异，得到更精确的结果 因此一个比较精确的法线值，可以通过以下公式计算得到 这种方式虽然说计算比较精确，但需要6次的f(p)计算。在不考虑精确度的情况下，使用前项微分替代的话。需要计算4次f(p)的值 而如果在假设 f(p) &#x3D; 0 的前提下，可以进一步简化 考虑到条件苛刻与精度的前提下，有另外一种比较好的替代方案，同样采用中心差异梯度定义的技术，利用四面体技术通过4次f(p)的计算，就可以达到6次计算的精度。这种方法也是目前大多数情况下比较通用的计算法线的方法 模型的背部过于黑了，这是由于Lambert模型将漫反射强度，也就是dot(n,l)的值，范围映射本身在[-1，1]间，我们用max()函数强制截断到了[0，1] 如果将dot(n,l)的值*0.5+0.5映射到[0,1]区间，这样Lambert模型计算出的光照结果值大于0 这样物体本身提升了亮度 这就是Half Lambert光照模型了 也可以利用经验光照模型中的环境光分量的方式做到这一点 "},{"title":"数学可视化(09)——Rayarch光线步进算法","date":"2023-11-14T00:55:30.000Z","url":"/2023/11/14/Mathematical-Visualization-09/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 图形学中的几何对象表现方式 3D几何对象的表示有显式和隐式两种方式 显式 隐式 多边形面片 数学函数公式 点云 距离场函数 NURBS CSG(Constructive Solid Geometry) 体素 分形函数 隐式方式不能提供直观的视觉呈现，但在计算几何体相交、碰撞等方面更方便 通常用显式的方式去构建复杂场景的几何体，用隐式的方式去构建一些加速结构和简化几何体，用来处理优化算法 将用距离场函数及几何体的运算来构建3D几何对象 在二维屏幕上，即使使用隐式3D几何构造方式，提供了几何数据，输入数据也只有uv两个维度 绘制三维几何体，至少需要三个变量来描述，这时需要一个场景深度来辅助处理，也就是知道uv后，再获取该像素点在场景下的深度值 这就需要光线步进算法来协助完成了 光线步进算法 先讨论渲染体、相机、屏幕uv，3个基本的对象 通过屏幕坐标uv和相机的位置，可以得到多条以相机为起点，朝向场景发射的射线 针对每条射线，可以定义该射线的光线步进算法，伪代码： 我们需要预先定义一些关于光线的预定义数据,包括光线最大的步进步数、总共行进的最大距离长度、光线与物体表面距离的最小长度等 完成后可以得到当前屏幕场景所有深度值 "},{"title":"数学可视化(08)——分形Fractal","date":"2023-11-07T01:17:59.000Z","url":"/2023/11/07/Mathematical-Visualization-08/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 分形Fractal的概念和定义 分形Fractal最早是由数学家曼德波罗在《统计自相似性和分数维度》的论文中提出的 与随机、噪声等混沌状态不同，分形具有递归性定义 分形是以非整数维形式填充空间、对空间占有的特定形式 具有自相似性 分形维数与拓扑维数 拓扑维数:通过空间中的一个点需要几个变量定义来确定 如:地球表面一个点，只需要经度纬度就可定义，因此地球表面实际的拓扑维数是二维 分形维数:在拓扑维数下定义的一个图形，把它拆成更小的形状，需要几个更小的形状才能拼回原来的图形 分形维数公式:D&#x3D;logN &#x2F; logE，其中N为拼回原图形需要的小图形的个数，E为原图形被缩小为原来的几分之一的倒数 分形维数与原图形填充是可以有直观上的对比映射的 如:分形维数在1~2区间时，越接近1，图形越向一维线段的填充；越接近2时，越像二维图形的填充；而越接近3时，越接近三维几何体填充 实时渲染用的分形 最常用的是分形布朗运动(Fractual Brownian Motion，fbm) 简称fbm，是布朗运动的拓展 通过将不同频率和振幅的噪声函数进行叠加操作 布朗运动:布朗运动是一种随机运动，粒子的运动方向随时改变，其运动轨迹是一条处处连续但处处不可微的曲线，是一种无规分形曲线，也具有统计性质的自相似性 一般fbm公式为每级噪声函数，其振幅缩减为上一级的1&#x2F;2，频率增加为上一级的一倍，并通过参数控制fbm由几级噪声函数叠加而成。这里的噪声函数可以是任意噪声函数 公式: fbm &#x3D; noise(uv) + 0.5 * noise(2*uv)+ 0.25 * noise(4*uv)… fbm变种: 湍流（Turbulence )，在fbm中对噪声函数取绝对值，使噪声值在0时发生突变，产生湍流纹理，fbm &#x3D; |noise(uv)| + 0.5 *|noise(2*uv)| + 0.25*|noise ( 4*uv)|… 翘曲域(Domain Wrapping)，翘曲域噪声用来模拟卷曲、螺旋状纹理，如烟雾、大理石等，f(p) &#x3D; fbm( p + fbm( p + fbm( p ))) 通过调整算法和噪声函数，可以组合出各种各样的分形噪声效果 因此fbm常被用作生成程序化纹理中 "},{"title":"数学可视化(07)——随机与噪声","date":"2023-11-07T00:11:56.000Z","url":"/2023/11/07/Mathematical-Visualization-07/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 计算机中的随机数 通过算法生成的随机数一般都是伪随机数 除非我们每次通过不同的随机种子获取 由于shader中标量和向量的元素通常都在0-1区间，因此生成0-1的float值是非常必要的 frac：返回指定值的小数部分，返回大于0小于1的值 frac函数就是将值映射到0-1区间，可以将sin函数从[-1, 1]映射到[0, 1] 将这个函数拓展到二维 数字都是随机写的，主要看效果图够不够随机和混沌 还可以替换成rgb3个通道的二维随机 可以利用floor或cell函数来处理整数索引，使得某块或某段数据获得的随机值是一样的，这样可以做一些tile级别的随机 再利用frac函数处理每一个tile内的uv坐标 可以修改绘制函数 噪声 白噪声(White Noise)：是值较宽频率范围内，各等宽的频带所含噪声功率谱密度相等的噪声。也就是前面所用的随机值或哈希值产生的噪声，就属于白噪声 值噪声(Value Noise)：是由tile四个角上的点的随机值插值生成的噪声图，不过值噪声图只由简单的线性插值生成的话会出现晶格化的现象。前面以tile随机生成的噪声图就是值噪声图 梯度噪声(Gradient Noise)：所以会用一些梯度函数进行插值，其中经典的有Perlin噪声、Simplex噪声 网格噪声(Cellular Noise)：在程序化生成纹理时更为常用，它是基于距离场的，对于每个像素计算它到最近的特征点的距离，一般来说需要遍历所有四个特征点，计算它们到当前像素点的距离，并把最近的距离保存下来，也就是利用距离场生成了一个Voronoi图 "},{"title":"数学可视化(06)——平移、旋转、缩放变换","date":"2023-11-06T23:39:40.000Z","url":"/2023/11/07/Mathematical-Visualization-06/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 变换的基础概念 矢量、标量的概念 矢量点乘、叉乘、加减乘除运算 矢量单位化、正交化、长度的计算 矩阵与矢量、矩阵与矩阵的运算、单位矩阵、逆矩阵等 空间中物体位置的矩阵表示 2D空间中用三维矩阵表示 3D空间中用四维矩阵表示 平移矩阵 旋转矩阵 3D下旋转轴有3个，对应3个矩阵 缩放矩阵 注意变换矩阵左乘的顺序，不满足交换律 "},{"title":"数学可视化(05)——2D距离场与图像","date":"2023-11-06T05:22:47.000Z","url":"/2023/11/06/Mathematical-Visualization-05/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 有向距离场Signed Distance Field (SDF) 2D距离场是由原点到平面上任意一点的距离，定义为矢量，是有方向的。由这些有方向距离定义的空间，为有向距离场 可以利用距离的正负来定义图形的边界，这样就可以利用距离场来绘制图形了 2D距离场所需参数 原点O 目标点P 距离（可以是不同定义下的距离） 欧式距离 切比雪夫距离 曼哈顿距离 其他距离定义… 2D距离场 圆形：sdCircle(float2 pos, float d) 正方形：sdSquare(float2 pos, float d) 正菱形：sdRhombic(float2 pos, float d) 椭圆形：sdEllipse(float2 pos, float w, float h) 矩形：sdRect(float2 pos, float w, float h) 菱形：sdRhombus(float pos, float w, float h) 梯形：sdTrapezoid(float2 pos, float up, float down, float h) 等腰三角形：sdTriangleIsocaeles(float2 pos, float down, float h) 任意多边形：sdAnything(float2 pos, float2[] points) 极坐标下任意正多边形：sdPolygopn(float2 pos, float r)  SDF的值是可以进行数学运算的，包括加、减、min、max、与或非等 SDF操作还可以加圆角 还可以制作圆环效果 "},{"title":"数学可视化(04)——极坐标系与函数拟合","date":"2023-11-05T10:38:58.000Z","url":"/2023/11/05/Mathematical-Visualization-04/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 极坐标系 定义M点离极点的距离为极径ρ，向量M与极轴夹角为Θ 可以容易得到M点在两个坐标系下的相互转化公式： 函数拟合 数学是自然的语言，是对客观世界规律的描述（数学建模） 如何图像形状我们都可以用数学的函数集合（函数空间）来表示。而空间完备性就是函数空间是否可以逼近任意函数 闭区间上的连续函数可以用多项式基数一致逼近（泰勒级数） 闭区间上的周期函数可以用三角函数一致逼近（傅立叶级数） 函数拟合其实就是寻找映射、变换、组合的函数过程 函数拟合的步骤 到哪里找？确定某个函数空间 找哪个？度量哪个函数是好的或更好的 怎么找？求解或优化 图形学中的函数拟合的方法 直接法：采样点，最小二乘法寻找最小平方误差的函数，求解待定系数（连续函数） 间接法：多段区间函数拼接（可以是非连续函数的集合） 心型函数 "},{"title":"数学可视化(03)——函数可视化","date":"2023-11-05T09:46:27.000Z","url":"/2023/11/05/Mathematical-Visualization-03/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 绘制坐标轴的前半段代码，相当于绘制y &#x3D; 0的函数，相当于abs(function &#x3D; 0) "},{"title":"数学可视化(02)——ShaderLab内部常用函数","date":"2023-11-04T09:54:00.000Z","url":"/2023/11/04/Mathematical-Visualization-02/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; floor、ceil与frac 常用于数据分段 floor(x)：返回小于或等于指定值x的最大整数值(向下取整) ceil(x)：返回大于或等于指定值x的最小整数值(向上取整) frac(x)：返回指定值的小数部分，返回大于0小于1值 fmod(x,y)：返回指定值x&#x2F;y的浮点余数，这种方法对于非整数取模更灵活，但比使用floor&#x2F;ceil + frac方式开销更大一些 modf(x,out ip)：将指定值x拆分为小数部分和整数部分，其中返回值为小数部分，参数输出为整数部分，每个部分的符号与x相同，与fmod相比它更适合处理整数和取模的方式。效率高的同时同样不如fmod用起来灵活 saturate、clamp、step、sign 常用于数据值处理（数据截断） saturate(x)：将指定值固定在0-1的范围内 clamp(x,min,max)：将指定值固定到指定的最大最小值范围 step(y,x)：比较两个值，前者小于后者则返回0，否则返回1。可用于二元判断 sign(x)：返回指定值的符号，x小于0返回-1；x等于0返回0；x大于0返回1。可用于三元判断 lerp与smoothstep lerp(x,y,s)：执行两个指定值的线性插值，s为插值系数 smoothstep(min,max,x)：如果x在[min,max]范围内，则返回介于0和1之间的平滑埃尔米特插值 过渡部分是由外到内由白到黑的过渡部分 如果用白色去减就可以变成由黑到白的过渡了 "},{"title":"数学可视化(01)——坐标转换与距离","date":"2023-11-04T03:19:20.000Z","url":"/2023/11/04/Mathematical-Visualization-01/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"],["数学可视化","/tags/%E6%95%B0%E5%AD%A6%E5%8F%AF%E8%A7%86%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 本质 本质是构造一个造型函数（Sharping Function） 输入是一个二维的向量坐标XY，输出是一个三维向量RGB 在CPUSample中，输入的是分辨率下的像素索引i,j 在GPUSample中，输入的是屏幕坐标u,v 也就是说，我们默认屏幕处于正交笛卡尔坐标系的第四象限，即平面直角坐标系下的第四象限 造型函数：c.rgb &#x3D; uv.xxx; c.rgb &#x3D; uv.yyy; c.rgb &#x3D; half3(uv.x, 0, uv.y); 第四象限改为第一象限，只需将uv的y方向颠倒即可 uv.y &#x3D; 1.0 - uv.y; 这样uv的y方向就与Unity默认的y方向就一致了 如果想显示整个四个象限，将原点从(0,0)移动到屏幕中心 具体做法是：uv &#x3D; uv * 2.0 - 1.0; 这样将[0,1]的区间变成[-1,1]的区间 图形渲染中常用的距离的类型 以下都以四象限为例： uv &#x3D; uv * 2.0 - 1.0; 欧式距离 c &#x3D; sqrt((pow(uv.y, 2) + pow(uv.x, 2)) * 0.5); * 0.5 是为了不出现&gt;1.0的白色的截断的值，使颜色过渡更平滑 曼哈顿距离 x、y轴轴距绝对值的总和 如上图，绿色的线代表欧式距离，其他线是两点间等效的曼哈顿距离 c &#x3D; (abs(uv.y) + abs(uv.x)) * 0.5; 切比雪夫距离 也叫做棋盘距离 c &#x3D; max(abs(uv.y), abs(uv.x)); 马氏距离 是一种特殊的欧氏距离，要考虑不同量度特性间的联系 要考虑不同维度间，数据的协方差来计算距离 要将量度转换到同一维度下，再计算欧氏距离 屏幕的宽度高度属于不同维度，如果不统一量度，会造成图形的拉伸 为了图形不被拉伸，需要将宽高转换到同一量度上 half co &#x3D; h &#x2F; w;c &#x3D; sqrt((pow(uv.y * co, 2) + pow(uv.x, 2)) * 0.5); "},{"title":"Unity C#反射与特性","date":"2023-07-26T03:39:54.000Z","url":"/2023/07/26/unity-ClassRef-2/","tags":[["Unity","/tags/Unity/"],["底层原理","/tags/%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 知识点一、回顾 编译器是一种翻译程序，它用于将源语言程序翻译为目标语言程序 源语言程序 : 某种程序设计语言写成的，比如C#、C、C++、Java等语言写的程序 目标语言程序 : 二进制数表示的伪机器代码写的程序 说人话 : 我们写的如C#语言，计算机是不认识的，只是我们自己看得懂自己定的一些规则 所以需要编译器把这些C#等语言翻译成二进制，计算机能够认识的规则 二、程序集 程序集是经由编译器编译得到的，供进一步编译执行的那个中间产物 在Windows系统中，它一般表现为后缀为.dll(库文件)或者是.exe(可执行文件)的格式 说人话 : 程序集就是我们写的一个代码集合，我们现在写的所有代码 最终都会被编译器翻译为一个程序集供别人使用 比如一个代码库文件(dll)或者一个可执行文件(exe) 三、元数据 元数据就是用来描述数据的数据 这个概念不仅仅用于程序上，在别的领域也有元数据 说人话 : 程序中的类，类中的函数、变量等等信息，就是程序的元数据 有关程序以及类型的数据被称为元数据，它们保存在程序集中 四、反射的概念 程序正在运行时，可以查看其他程序集或者自身的元数据 一个运行的程序查看本身或者其他程序的元数据的行为就叫做反射 说人话 : 在程序运行时，通过反射可以得到其他程序集或者自己程序集代码的各种信息 类、函数、变量、对象等等，实例化它们、执行它们、操作它们 五、反射的作用 因为反射可以在程序编译后获得信息，所以它提高了程序的拓展性和灵活性 1.程序运行时得到所有元数据，包括元数据的特性 2.程序运行时，实例化对象，操作对象 3.程序运行时创建新对象，用这些对象执行任务 六、语法相关 Type、Assembly、Activator Type 创建一个测试类 Type(类的信息类) 它是反射功能的基础 它是访问元数据的主要方式 使用Type的成员获取有关类型声明的信息 有关类型的成员(如构造函数、方法、字段、属性和类的事件等) 获取Type 1.万物之父object中的GetType()可以获取对象的Type 2.通过typeof关键字，传入类名，也可以获取对象的Type 3.通过类的名字，也可以获取类型 注意 : 类名必须包含命名空间，不然找不到 type、type2、type3指向的内存地址一样，即一个类的元数据只有一份 Assembly(程序集类) 可以通过Type得到类型所在程序集信息 获取类中的所有公共成员 首先得到Type 然后得到所有公共成员 需要引用命名空间 using System.Reflection; 获取类的公共构造函数并调用 1.获取所有构造函数 2.获取其中一个构造函数，并执行 得到构造函数，要传入Type数组，数组中内容按顺序是参数类型 执行构造函数，要传入object数组，表示按顺序传入的参数 2-1得到无参构造 2-2得到有参构造 获取类的公共成员变量 1.得到所有成员变量 2.得到指定名称的公共成员变量 3.通过反射获取和设置对象的值 3-1通过反射，获取对象的某个变量的值 3-2通过反射，设置指定对象的某个变量的值 获取类的公共成员方法 通过Type类中的GetMethod方法，得到类中的方法 MethodInfo是方法的反射信息 1.如果存在方法重载，用Type数组表示参数类型 2.调用该方法 注意 : 如果是静态方法，Invoke中的第一个参数传null即可 其他 Type : 得枚举 GetEnumName GetEnumNames 得事件 GetEvent GetEvents 得接口 GetInterface GetInterfaces 得属性 GetProperty GetPropertys 等等 反射关键类Assembly和Activator（未完待续）"},{"title":"UnityUI-IMGUI","date":"2023-07-25T02:44:38.000Z","url":"/2023/07/25/UnityUI-IMGUI/","tags":[["Unity","/tags/Unity/"],["UI","/tags/UI/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 一、 工作原理和主要作用 二、文本和按钮控件 三、多选框和单选框 四、输入框和拖动条(滑动条slider) 五、图片绘制和框 六、工具栏和选择网格 七、滚动列表和分组 八、窗口 九、自定义皮肤样式 十、自动布局 IMGUI学习结束！"},{"title":"DOTS(5) 核心包学习 Jobs(1)","date":"2023-07-09T02:16:31.000Z","url":"/2023/07/09/dots-05/","tags":[["Unity","/tags/Unity/"],["Dots","/tags/Dots/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; Unity Jobs System 包含C# Jobs System和C++ Jobs System 利用多核计算平台来简单安全的编写与执行多线程代码 既可以与ECS结合使用也可以单独使用 编写代码时不需要关心运行平台CPU核心情况与线程资源的情况 Job System的调度 Jobs System是通过创建Job任务，而不是线程，来管理多线程代码的 Unity引擎内部会跨多个核心来管理一组工作线程，以避免上下文的切换 执行时，Jobs System会将我们创建的Job任务放到Job队列中，以等待执行 工作线程会从Job队列中获取并执行相应的工作 C# Jobs System 一般不会出现手写多线程程序中出现的Race Conditions问题 因为在每个Job任务中，只访问数据的拷贝 或者是转换一段buffer的所有权给这个Job(Native Container) C# Jobs System实际上使用的就是Unity引擎内C++ Jobs System的代码 所以在引擎与游戏线程之间没有上下文切换的开销 但毕竟C#与C++下的内存管理与值的类型定义不同，所以在写C# Jobs System代码时，需要区别哪些是Blittable Type类型的数据，哪些类型不是 Blittable Types VS Non-Blittable Types Blittable Types : 在托管代码和非托管代码的内存中具有相同的表示形式 值得注意的是，C#中的布尔值占用4个字节，C++中占1个字节 NativeContainers 在写Job程序时，除使用Blittable Type类型数据外，还可以用C++上非托管内存堆数据，不过需要依赖另外一个DOTS核心包——Collection中的NativeContainer，以及Unity引擎下为特殊用途，特殊定制的一些容器类型，如 : Unity引擎内定义的数组 : NativeArray NativeArray的子集 : NativeSlice 用于映射访问GameObject，Transform对象的TransformAccess以及TransformAccessArray Unity Collections Package 可变大小的NativeArray : NativeList 单键值对映射表 : NativeHashMap 单键多值的 : NativeMultiHashMap 先进先出的队列 : NativeQueue 支持多线程同时写入的各种数据容器等 可自定义的NativeContainers 这些数据容器都是非托管堆上分配的 有DisposeSentinel安全检查来避免内存泄露错误 有AtomicSafetyHandle来追踪所有权与访问权限，避免Race Condition错误 这些类型容器都需要用完手动调用dispose接口进行释放 没有引用返回，会在C#7中支持 Allocation Types 这些类型容器在创建时还会涉及分配类型的选择 一般最常用的有三种 : Persistent : 对应对象的长生命周期内存 TempJob : 对应在Job中存在的短生命周期内存，4帧以上会收到警告 Temp : 对应在一个函数内使用的更短生命周期内存 这些分配类型在Unity引擎内部分别对应不同的allocator类型 "},{"title":"DOTS(4) 核心包环境安装与工具概览","date":"2023-07-01T05:50:45.000Z","url":"/2023/07/01/dots-04/","tags":[["Unity","/tags/Unity/"],["Dots","/tags/Dots/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 2022.2.8b以上的编辑器版本 在Windows-Package Manager中选择Add package by name…输入com.unity.entities包名，等待安装完成 安装完后，会发现编辑器的Preferences属性列表中多了Entities标签和Jobs标签 Project Settings中新增了DOTS和Burst AOT Setting标签 编辑器的菜单中会多出一个Jobs菜单项 在Component菜单下也会看到DOTS的子菜单，里面的选项是将GameObject对象转化成Entity，不过这是DOTS暂时保存的旧接口，DOTS1.0中已不推荐使用 Windows菜单下会多出一个Entities标签，下面是Entities的一些工具窗口 在Inspector窗口右上角会出现一个小圆点，有纯灰色、纯橙色、灰底橙心三种形态，分别代表处于Authoring、Runtime、Mix三种模式下的哪种数据模式 Unity Profiler中还会增加Entities Memory、Entities Structural Change两个模块，分别用来记录DOTS下Entities相关内存分配和使用情况，以及显示运行时发生Entities Structural Change的事件 核心包学习路径图"},{"title":"DOTS(3) Cache层级结构与排队管理","date":"2023-06-20T23:50:15.000Z","url":"/2023/06/21/dots-03/","tags":[["Unity","/tags/Unity/"],["Dots","/tags/Dots/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 如何理解L1、L2、L3级缓存的这种树形结构设计 CPU指令执行也是在排队，很多算法也都是在处理数据队列 现实中各种队列的内外因素不同，我们可以通过一些设计、规则、以及调度的调整，去改善队列的效率 计算机上也一样，dots面向数据的设计部分，就是在设计队列的结构，ECS就是在组织队列中的规则，Job System就是在做队列的调度 队列类型 单队列 这样的队列比较简单，参与队伍管理的工作人员也可以很少 但队列中的任何一个人或业务人员出现了处理时间较长的问题，造成的阻塞会是整个系统级别的 这时，很容易就能想到用多条队列并行处理不就解决了吗 多队列 当初的计算机与CPU设计人员也是这么想的，并行计算、多核设计也是这么干的 但多行队列的占地会比较大，需要的服务人员与并行队列数量成正比 换到CPU上，就需要有更好的工艺，给多核留更大的空间 即使这样，单纯的多队列也并不一定能够高效，原因是木桶能装多少水要看最短的短板，我们不知道系统中每个人需要花费多久时间完成，当一个并行队列中，一个人花费时间太长时，也会造成整体的系统依旧很慢 这时处理并行，调度串行的队列就派上用场了 3.单队列+调度 这种队列需要一个如图中黄色的调度人员来管理队列，当某人窗口被阻塞时，调度人员会将长队列等待的人调到其他处理窗口中 长的单行队列，就很像队列的Catch缓存 与多行并行队列相比，这种队列更适合队伍中每个人员处理时间长度不一致，以及新到队列中的人到来时间随机的情况，这种情况下单行调度队列比纯并行队列更有效 4.复合队列 就是单行调度队列加上多行并行队列的组合，如现实中的做核酸队列 这种队列比较适合多阶段批次处理事务的队列，每个批次内每个人处理的时间近似的情况 这种复合队列中的并行队列，有点catch line的概念了 不过一旦出现每个人处理时间有巨大差异时，队列效率就会变得很差了，调度员的调度工作与复杂度也会上升 这时我们的队列可以做进一步演化 可以再增加一层并行队列，并增加两个调度人员，一个是应付进入整体队列系统的调度人员C，用来调度随机到来的人员进入类似属性的队列；另外一个调度员B则按照每个并行队列中，单个队列是否达到上限，将队列中的人统一调度到下一层的单行队列中进行等待 增加处理完队列后的后续工作，虽然队列按相同的属性组织完成了，但离开队列系统的情况是离散的，导致离开后队列变乱了，进而导致后续的系统效率又变差了 那么我们考虑在进入第一次并行队列时，按属性组分离队列的话，类比到CPU上，就是把数据组织成矢量，做对齐优化，处理时又可以兼容SIMD指令处理，这样一个指令处理多条类似数据，不仅加快了处理效率，还可以保持离开队列系统时数据的连续 最后，做一个更大胆的类比 可以将蓝色部分类比成L1级缓存，青色部分类比成L2级缓存，紫色部分理解为一个CPU的逻辑盒，红色部分就是逻辑盒共享的L3级缓存了 而每个不同级别的缓存内的队列，可以类比成catch line,或者Archetype Chunk的概念 而整个队列系统组织数据Layout的过程，可以理解成ECS 黄色调度员类比成不同调度方式下的Job System 进入到蓝色处理员处理的人员队列，类比成Burst编译器优化过后的，支持SIMD的代码指令 总之，Catch为什么会设计成这样的层级结构，是由不同核、不同计算单元的不同情况下，不同数据与指令的调度需求决定的 类比不能代表真实情况，只是帮助理解 一般来说，不同的队列结构设计依赖单通道、多通道与单阶段、多阶段两个维度，在现实生活中都能找到类似的实例 : 队列模型建模考虑的因素 : 到达分布 到达规模 队列中人员耐心程度 有限&#x2F;无限队长 队列结构…… "},{"title":"unity反射底层原理","date":"2023-06-19T01:56:37.000Z","url":"/2023/06/19/unity-ClassRef/","tags":[["Unity","/tags/Unity/"],["底层原理","/tags/%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; C#对象的内存布局 类 : 是一种类型描述，描述了这个类型有哪些数据组成，同时描述一些成员函数 类的实例 : new 类(); 是具体的内存对象，就是一块内存，包含这个类里的数据，这块内存是所有数据成员的集合 类的成员函数会到哪里去 类的成员函数属于代码指令，编译完成后，会变成代码指令，全局只有一份，所有的类的实例公用一份这个代码指令 存入到代码段 : 编译器把代码编译成.exe的可执行文件，在运行这个文件时，会把里面的所有代码加载到内存的代码段，再跳到main函数里一行一行执行 this实例的概念 成员函数里面，如果我们使用this，指的就是当前的对象实例 例 : 调用这个成员函数.test()的时候，我们会自动给成员函数，把当前的对象实例作为this传入进去 this.age操作的就是当前的对象实例这块内存 底层就会把t这个实例(这块内存)传递给this(this指向这块内存),通过this来操作 类的实例 类的数据成员的所有数据(看得见的，age，4个字节，name，引用类型变量，在32位系统下4个字节) 看不见的数据 : 编译器的对齐等 t表示一块内存，如何获取每个成员？ 编译器会根据一些编译的选项、数据的类型，在写好代码以后，定死一个数据成员相对这个类的内存的偏移，如age在对象实例里面，内存偏移多少，大小为age的类型(int 4字节) 当我们编写好一个类型后，编译器会知道 : 每个数据的相对于对象实例内存块的偏移 每个类的成员函数在代码段的偏移，因为最终是要把这些成员函数编译成机器指令，在运行时就可以让指令直接跳转到这里进行函数调用 什么是反射，反射有什么作用以Unity引擎为例 编辑器上挂脚本，我们给脚本初始化数据 编辑完了以后，保存到场景文件里面 运行的时候，根据场景文件里面的内容，游戏引擎把这个节点和组件实例new出来 上面我们描述一个类，每一个类都有一种类型，都有自己独立的描述 所以会导致我们每新加一个类，就会有多的一种方式来描述 上述问题的本质矛盾是 : 我们没有统一的方式来处理不同的类或类的实例 需要用一种方式来描述任意的类型 : 类的实例是一个内存块，内存块的大小就是这个类的所有数据成员的大小(通过编译器知道内存块大小) 类有哪些数据成员，我可以把这些数据成员的名字，通过数组等其他方式保存起来如 : 类有哪些成员函数如 : 任意的类都可以转化成一种描述 定义了这样一种描述方式，我们就解决了上面的问题，我们用统一的方式来描述任意不同的类型 类型描述 对象实例(Type, System)是什么 每个类，编译器都知道，数据成员的偏移、函数代码段的位置 运行的时候，C#系统会为每个类生成描述实例(数据内存)，称作Tpye实例；描述类的类型，称作Type类型，属于System名字空间 Type : 一些类型的描述信息伪代码 : 描述Test : 编译完成后，就可以根据编译信息，生成一个类型描述对象的数据，存起来，一起写入到.exe 底层就可以使用Type的方式来获得一个类的描述，可以根据类的描述来构建实例，调用方法和成员了 调用底层OS的API来分配一个xxxx大小的内存出来，作为对象实例的内存 调用构造函数，将这个内存块传递给构造函数，构造函数就会帮我们初始化对应的数据 编译每个类时，会为每个类生成一个全局数据，这个全局数据是Type类型，里面存放一个类的描述数据 只需要调用API : System.Type.GetType(“类型名字”) &#x2F; typeof(T) 根据类型或类型名字获取类型描述对象实例 Type类型系统已经给我们定义好了，包含 : FieldInfo : 数据成员信息 MethodInfo : 方法信息 通过反射来实例化一个对象 : Type t实例化一个对象出来，根据t这个Type实例 API : Activator.CreateInstance Type里存放了每个数据成员的偏移和大小，用这两个数据，就能从对象的内存里面读取&#x2F;设置成员的数据 从t里获取类型描述FieldInfo，结合t实例把大小、偏移等数据取出来就是数据的值了 API : SetValue&#x2F;GetValue 每个Type里面都存放了成员函数地址 MethodInfo &#x3D; t.getMethod(“名字”);Object returnObject &#x3D; MethodInfo.Invoke(instance, 参数列表); 代码"},{"title":"Unity底层是如何处理C#的","date":"2023-06-18T06:58:45.000Z","url":"/2023/06/18/Unity-Underlying-Principle/","tags":[["Unity","/tags/Unity/"],["底层原理","/tags/%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; Q1 : Unity的历史里面为什么会选择Mono？ Mono : 微软.net把.NET标准开放以后，Mono是一个跨平台的.net项目(Linux、Windows、Mac、Android等) 我们基于Mono来开发应用、开发游戏引擎、打包发布我们的游戏产品，都是可以跨平台的 Unity在设计的时候，为了跨平台，就采用了Mono来构建底层(Unity编辑器等) 快速地实现Unity编辑器以及Unity开发出来的app能够跨平台(主要原因) Q2 : Unity为什么又会推出il2cpp？il2cpp到底做了什么事情？ Mono .net的版权问题 .net本身也在迭代，每迭代上一个版本的时候都会有授权和版权的问题，这对Unity来说不是一个特别方便的东西，而是一个限制 Mono虚拟机解释执行.net的字节码，运行效率比较差 有些平台不允许内置.net虚拟机，比如IOS-如果有新的计算平台出现(如XBOX等)，Mono又不支持，这时Unity在跨平台上就没用了 整个Mono是另外一个项目的，如果要把Mono虚拟机移植到一个新的平台，可能要Unity自己动手，这时就会跟Mono主干分开。主干一个分支，Unity一个分支，这时维护起来是非常麻烦的 同时一些平台本就不好移植(如WebGL)，对Unity而言是非常被动的 这时，Unity推出了il2xxx技术 (xxx包括c++、javascript等) IL : .net字节码 IL2cpp : .net字节码 —&gt; C++代码，再编译，生成native平台相关东西 (1) Unity首先要开发一个C&#x2F;C++以及native层，来做一个跨平台的Runtime(Xcode, Android NDK,…) (2) Unity引擎需要把游戏开发者的代码(.net字节码)，要开发一个工具(IL2CPP)，把它转成C++的代码，这些C++代码基于一些库，结合跨平台的层，生成目标平台的应用程序 (3) C#有垃圾回收机制等，这时C++代码就需要对这些垃圾回收等提供支持。Unity为了提供这些特性的支持，开发了il2cpp vm(实际上是一个runtime库) : 支持C#，.net独有的一些特性，如垃圾回收等 Q3 : il2cpp有哪些优势？ 跨平台可移植性问题 : Unity本身只需要来移植这个il2cpp就可以了，比较方便 解决.net版权问题 性能获得提升 : .net是解释执行字节码，il2cpp是把它变成C++代码，其实就是本地的native代码，运行效率会更高一点 基本上都是基于il2cpp来进行发布，性能会更好 "},{"title":"DOTS(2) DOTS中的ECS架构与概念术语","date":"2023-06-17T04:03:23.000Z","url":"/2023/06/17/dots-02/","tags":[["Unity","/tags/Unity/"],["Dots","/tags/Dots/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; Entity-Component-System实体组件系统(ECS)架构 遵循组合优于继承的原则 面向数据设计 弱耦合 常被应用在游戏开发上 游戏引擎架构演变 在ECS架构出现之前，早期的游戏引擎或游戏的架构，多以多层对象继承的方式来组织，都是按空间节点为较基础的对象，一层一层抽象继承下来的 后来随着发展，游戏引擎逐渐演变成以Actor Component这种以轻继承，以对象组合代替多层继承的方式来组织 其中Actor是个Component的容器，而负责具体逻辑更新部分则由具体的Component负责 对象几乎没有多态，做到了对象间的解耦 如Reality Engine、UE3以后的版本以及Unity几乎都是这种架构 我们要明确ECS架构的本质，组合的是数据数组，而非对象数组。其中Entity本身虽然叫做实体，但并非对象，也不是一个容器，而是一个对象索引的id，是一个标识符，其中并不包含任何数据与逻辑；而Component才是个容器，但它不是一个对象容器，而仅是一个数据容器，其中不包含任何逻辑。 Entity与Component的关系，往往是Entity充当数据的标识符或Key来使用，而ECS中的S(System)才是真正负责对数据进行操作的部分 换句话说，System才是对具有特定组件的特定实体执行的操作 DOTS1.0中的ECS ECS架构一直在演变 应用场景不同，各家实现和工作流有差异 DOTS1.0中的ECS与老版本变化较大，不要看老资料 DOTS1.0中，为了让大家从面向对象设计向面向数据设计编写代码时，过度更平滑些，引入了不少特性与专有名词，让大家在编写代码时能找到一些面向对象的感觉。因此我们在学习DOTS时，不要先入为主去质疑DOTS下的ECS为什么如此设计，要以DOTS下的ECS工作流方式去学习。另外DOTS中的ECS只是DOTS中的一部分，并不是你了解ECS架构，甚至自己动手实践过ECS就一定能学好 开发心态去接受 DOTS下关于ECS的专有名词和概念 Archetypes原型和Archetypes Chunk的概念 Archetypes依然不是个对象，它依然是一个标识符，它标识的是所有具有相同Component组合的实体类型 举个例子，这里由Position、Rotation、Renderer、Rigid Body四个Component组件组合成的Entity A与Entity B共享一种原型，而由Position、Rotation、Renderer三个组件组合成的Entity C则属于另外一种原型 这里可以将Archetype原型理解成不同的Entity在内存上的Layout布局 如图所示，26个Entity被分为8种原型，而每个Archetype原型所标记的内存会被分成固定大小连续的非托管内存块，被称为Archetype Chunk，这里简称Chunk Chunk中会包含共享同一原型的实体组件数组，默认设置下每个Chunk大小为16KB，如果实体组件填充不满的情况下，也要有留白 Chunk存在的目的，是为了方便做数据并行计算，方便做缓存的prefetch在数据对齐的同时又可以匹配缓存的catch line，另外在Query查询时，无论是使用主线程查询、工作线程并行查询、还是按Chunk查询时，都可以利用其在Component的数组纵向维度上分块对齐的方式来做slice切片 World与EntityManager的概念 World是一系列Entity的组合，每一个Entity在一个World中是唯一的，统一受到world中的EntityManager结构的管理 EntityManager负责创建、销毁、修改世界中的实体 Structural Change的概念 所有导致需要重新组织内存块或内存块内容的操作都称为Structural Change 这里包括两个重点，一个是改变结构，一个是改变内容，这两种改变都只能在主线程中做，而不能在工作线程中做，是Resource Intensity资源密集类型的操作，效率很差 应该能想到，添加或删除一个Entity对应的组件，导致所属原型发生变化，就属于Structural Change的概念 另外，创建和销毁Entity实体、设置Share Component值也会被视为Structural Change，要尽量避免 而当我们明确我们一定不会有Structural Change的操作时，我们可以在编辑时做Bake的操作，虽然会降低运行时的逻辑灵活性，但会提高运行时效率 这张图可能会造成误解 不同原型内的相同组件，在内存上并不是像上图这样是连续的，这只是为了展示在Query查询时，会通过slice切片方式来阻止查询，让你感觉上是连续的，但并不会造成内存上的移动 Entities and Components术语 System术语 DOTS下的ECS Entity : Entity不是一个容器，它只是一个标识符，它用来指示某个对象的存在。系统可以用它来操作，可以通过组件来分配某些属性 Component : 组件是一个数据容器，没有任何逻辑，一组特定的参数关联在一起并定义属性 System : 系统是负责对数据进行操作的部分。换句话说，系统是对具有特定属性(组件)的特定实体执行的操作 补充 类比例子并不是为了说明缓存分级的原因 而是用组织排队去理解面向数据设计，可以更形象的理解ECS、Jobs与Burst在DOTS中分别扮演哪些角色，做了哪些事 缓存分层的原因本质是物理距离决定的 "},{"title":"DOTS(1) 面向数据设计DOD","date":"2023-06-16T01:38:31.000Z","url":"/2023/06/16/dots-01/","tags":[["Unity","/tags/Unity/"],["Dots","/tags/Dots/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"DOTS是面向数据的技术栈DO的缩写正是DOTS是以面向数据为基础的一个技术解决方案所以充分了解面向数据设计DOD是学习DOTS的基础 程序设计方法 这些程序设计方法都有很明显的时代特征，与程序语言的特性 Instructional Programming 指令化编程 正是计算机脱离纸带打孔输入后，伴随着机器汇编语言发展起来的 Functional Programming 函数化编程 伴随着Pascal语言出现的，以小函数模块化组合的编程范式 由于其限制小、易于调试等特点，主要用在数学和科学计算领域 如今如火如荼的机器学习、AI领域，函数化编程依然焕发着活力 Procedural Programming 过程化编程 是一种源于命令式的编程范式，基于过程调用的概念，包含一些要执行的步骤，任何给定的过程都可以在程序执行过程中的任何时刻调用 过程化编程伴随着一些更高级的编程语言，如Fortran、ALGOL、COBOL、BASIC等而出现 Object-Oriented Programming&#x2F;Design 面向对象编程&#x2F;设计(OOP&#x2F;OOD) 随着程序化规模越来越大，传统的编程范式已不足以满足易于理解、易于设计的需要了，这时，面向对象设计和编程的方式开始出现了 它是以对象为概念的多范式模型，包含字段形式的数据与过程形式的代码，通常以类为基础，强调数据的封装、类的继承与对象的多态特征，程序开始有了更高级的设计的概念 随之是一系列相关设计模式，诸如C++、Java、Python等广泛使用的面向对象的多范式编程语言的出现 Data-Oriented Design(DOD) 面向数据设计 是伴随着现代CPU多核并行计算、多级缓存、大缓存的设计而流行起来的 这里的DOD并不是面向数据编程，它并不是一种编程范式，而DOTS更可以理解为面向数据编程的一种范式 OOD -&gt; DOD 我们需要有从OOD面向对象设计到DOD面向数据设计的思想转变 面向对象设计的核心在于抽象、封装和继承，这样的设计对人类来说可能更直观、易于理解，但对于现代CPU来说，它的处理效率并不高效 而面向数据设计则侧重于数据，开发人员需要考虑需要什么数据，以及如何在内存中更好的构造数据，以便CPU处理数据系统时能够更有效地访问数据 DOD面向数据设计的本质，可以理解为是面向内存或缓存友好的设计 这要从CPU架构与缓存层级结构说起 CPU中会设置L1、L2、L3，3级缓存 其中一级缓存为每个指令处理单元独享，又可分为缓存数据的L1 D数据缓存与缓存指令用的L1 I指令缓存 L2级缓存则为CPU核内多个指令处理单元共享 L3级缓存则为CPU多个核共享，同时它还负责与内存以及显卡中的显存交换数据 CPU在执行程序指令时，会通过prefetching来获取指令与数据，每次访问的单位会根据系统与架构的不同而有所差异，一般是32或64个字节，把这个基础大小单位称为catch line缓存行。即使你请求一个字节大小，实际上你会得到一个catch line大小的缓存行数据 而在catch缓存内，可以将n个缓存行大小的缓存通过direct map直接映射到同一逻辑缓存行，而逻辑缓存行可以对应n个物理行，来帮助最小化缓存行的抖动。这里的抖动可以理解为 : 扭动指针到每个物理缓存行头 CPU逻辑处理单元，通过Fetch获得L1 I指令缓存中的指令，再通过Decode解码Execution执行，以及在指令完成后将数据回写到L1 D中，来完成一条程序指令 我们可以把Fetch、Decode、Execution这样一个循环时间定义为一个CPU指令的Cycle CPU处理指令时，从不同的缓存Catch中获取数据的时间开销也是不同的，这会导致我们获取的数据在某一级缓存没有命中时，向下一级缓存获取时花费的时间开销可能是数倍时间，甚至是数量级差异的时间开销，因此我们在编写程序时，如何做好面向数据设计，以达到缓存访问友好，对程序性能开销至关重要 Cache的3C与3R 3C即缓存未命中的三种情况 Compulsory misses : 首次读取数据时，不可避免的Miss Capacity misses : 缓存空间不足时，连续使用期间访问数据过多的话，无法保存所有活动的数据 Conflict misses : 发生访问冲突时，由于数据映射到相同的缓存行，导致缓存的抖动 3C伪代码 : 当变量i &#x3D; 0时，第一次进入循环，此时要访问data中的第一个int数据，这时catch中没有数据，会发生第一种情况下的Miss catch，这时需要进行profetching来加载一个catch line数据 接下来的第二遍循环会从catch line中加载数据，指令cycle数比第一次要少 当data数据足够大、循环次数足够多时(pointerToSomeData、1000000)，超过catch大小时会发生第二种情况，缓存不足导致的Miss catch 这里只是举例，真实情况不一定发生，而且现在GPU缓存很大，简单的代码触发缓存不足导致的Miss catch情况非常少 将 ++data 替换成 data+&#x3D;16 时，这时会触发第三种缓存抖动带来的Miss catch，也就是实际数据访问不连续，一次catch line获取的数据并没有你需要的，这种情况发生比较多，尤其是我们使用数组结构体AoS的数据Layout时 3R即3种优化访问catch命中的方法 Rearrange 重新排列(代码、数据) : 更改布局以增加数据空间的局部性 Reduce 减少(大小、缓存行读取) : 更小更智能的格式、压缩，如修改数据类型或使用位计算 Reuse 重用(Cache lines) : 增加数据的时间(和空间)的局部性，主要是对齐、连续访问，减少发生缓存抖动的几率 面向数据设计需要思考的问题总之，面向数据设计需要我们更了解内存&#x2F;缓存的特性，需要更了解系统和硬件，需要更了解芯片指令与数据结构设计，与面向对象设计相比，数据比代码更重要 DOTS面向数据设计原则 先设计，后编码 为高效使用内存与缓存而设计 为Blittable Data设计 为普通情况设计 拥抱迭代 "},{"title":"DOTS(0) DOTS的5W1H问题","date":"2023-06-14T08:07:04.000Z","url":"/2023/06/14/dots-00/","tags":[["Unity","/tags/Unity/"],["Dots","/tags/Dots/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 5W1H What——DOTS是什么 Who——谁需要关注DOTS Where——Dots可以应用到哪些地方 Why——为什么我们需要DOTS When——什么时候DOTS1.0能正式发布 How——我们该怎么样学习DOTS DOTS是什么 Data-Oriented Technology Stack(面向数据的技术栈) 实际上是通过Unity5个核心包来定义的一种全新的Unity代码编写模型，并在这些核心包之外，还提供了一系列游戏功能相关的额外包与相关工具，是Unity下面向数据设计与编程的一整套技术解决方案 它的五个核心包包括 : The C# job system : 用来提供快速安全和使用简单的编写多线程代码的方式，从而让开发者更容易地利用现代CPU的多核设计来处理并行任务 The Burst compiler : 这是一种优化C#代码的编译器，它可以编译生成比通过Mono或IL2CPP更快的代码，并且它并不只是为了编译DOTS代码而存在，它同样可以编译Unity中的任何代码 Unity Mathematics : 这是一套可以在job system中使用的数学库，它提供的功能在burst编译的代码中使用时是经过特别优化的 Unity Collections : 它提供了常见的集合类型，如列表、哈希映射表等，这些类型的内存分配属于非C#托管类型，可以在burst编译代码中的job system中使用，并且这些集合类型支持安全检查，有助于它们在job system中安全地使用 Entities(Unity ECS)(Entity-Component System) : 其中entity对象是GameObject更轻量、更高效的替代品，与GameObject和MonoBehaviour不同，entity本身并不承担任何代码，components也只是数据片段集合，它们都有对应的System代码单元进行处理 其他游戏功能相关的额外包包括 : Entities.Graphics(DOTS1.0之前的Hybird Renderer) : 它是一套支持URP与HDRP的entity渲染解决方案，值得注意的是，它并不是优化GPU上的性能，而是为了优化CPU上性能而设计的 Netcode : 这是一个建立在五个核心包基础上的DOTS网络解决方案，它提供了网络多人连线的服务器功能与客户端预测等相关功能 Physics : 同样是一个建立在五个核心包基础上的物理解决方案，这个包支持两个后端 : 默认的是Unity Physics包，它是一个无状态的确定性物理库，比较适合多人网络游戏；另外一个后端是Havok，这是一个有状态但不具备确定性的物理库，但相较而言这个库会更稳定，功能也会更强大 其他还有一些目前正在开发中的与游戏相关的额外包 Animation(WIP) Audio(WIP) 谁需要关注DOTS 技术负责人 处理游戏逻辑部分的工程师 处理网络通信部分的工程师 处理动画部分的工程师 处理物理模拟部分的工程师 开发工具与工作流相关内容的工程师 技术美术 AssetStore中DOTS相关工具与插件的开发人员 DOTS可以应用到哪些地方 具有大世界流式加载的游戏 具有复杂的大规模模拟的游戏 具有多种网络类型的多人联线游戏 具有需要客户端模拟预测的网络游戏，如射击游戏 这些都是一些多线程加载、通讯以及充分利用多核并行计算的游戏类型 总结就是CPU-bound类的游戏应用都可以考虑应用DOTS来做并行优化。目前很多游戏的性能瓶颈并不在渲染，而在CPU，这就是我们为什么需要DOTS 为什么我们需要DOTS CPU与Memory的速度发展不均衡以及带宽限制 是靠添加高速的缓存Cache内存层级结构去弥补的 如L1、L2、L3级的CPU缓存是最近十几年越加越多、越加越大的，甚至GPU上也为了效率采用了类似的设计 即使这样，一些程序设计的不合理依然会造成Cache使用上低效，导致大型缓存收益边界效益递减 而面向数据设计本身是面向缓存友好的，可以极大增加缓存Cache的命中，提高效率 摩尔定律的延续与现代CPU设计 越来越好的工艺，目前已经达到2nm极限了，那么提高CPU速度主要靠提高主频，提高功率的同时降低发热，在占用空间越来越小的同时通过增加核数做并行处理来提高处理能力，但需要做指令并行，改进编译技术的支持，才能发挥现代CPU设计的真正效能。这些条件下，如果你不去关心CPU指令与编译这一层是很难做到的，不要指望编译器能为你自动做这些事，编译器做的事很有限，程序性能的提升可远没有硬件提升这么快 据统计，程序性能每18年才能提高一倍，比摩尔定律要慢得多。另外，游戏主机硬件的发展也是不遵循摩尔定律的，因为它们往往是固定的硬件 所以DOTS是提供了一套更简单的面向数据的代码编写模型，用DOTS编写出的程序可以充分利用现代CPU多核的并行设计 并行编程的发展 并行编程库虽然有英特尔TBB(Intel Threading Building Blocks)、OpenMP、CUDA(Compute Unified Divice Architecture)、OpenCL(Open Computing Language)等很多，但它们要么依赖于特定的硬件，要么是针对于科学计算方面设计的，集成到Unity中使用几乎是不可用的 DOTS则充分考虑了游戏设计方面的需求，并在Unity中兼容了多平台多硬件的支持 什么时候DOTS1.0能正式发布(略) 我们该怎么样去学习DOTS 看 : 视频、官方文档、官方论坛DOTS区，官方Github中例子代码 查 : 专业术语、相关概念、扩展资料 学 : 五大核心包、游戏扩展包、三方扩展包与工具 改 : 官方Github中例子、Unity Assets Store中的例子 调 : 官方Github例子，自己的Demo 写 : Demo，小工程、DOTS游戏 交流 : 官方论坛，社交媒体群，评论区等 "},{"title":"Unity面试题搜集（一）","date":"2023-06-10T03:49:28.000Z","url":"/2023/06/10/questions-1/","tags":[["Unity","/tags/Unity/"]],"categories":[["undefined",""]],"content":"&nbsp; 面试必问题目之一：先来个简单的自我介绍吧！ 面试必问题目之二：你对自己的发展有什么规划？ 面试必问题目之三：你觉得你的优势是什么？ 面试必问题目之四：工作中遇到的比较难处理的问题是什么?如何解决的? 面试必问题目之五：你对公司有什么想了解的吗 题目大多由个人面试所总结，不同岗位的面试的侧重点都是不同的，以下仅供参考 PS：很多面试其实更关注的是你的项目经历，以及你简历里所填写的内容 AssetBundle读取时主要用的方法是什么？ AssetBundle.LoadFromFile：从本地文件系统加载AssetBundle。 AssetBundle.LoadFromMemoryAsync：从内存异步加载AssetBundle。 AssetBundle.LoadFromStreamAsync：从流异步加载AssetBundle（可以是网络流或本地文件）。 AssetBundle.GetAllAssetNames：获取所有资源名称列表。 AssetBundle.LoadAssetAsync：异步加载指定类型的资源（例如场景、纹理、模型等）。 Assetbundle.Unload: 卸载已经加载过的AssetBundle以及其依赖项。 LightMap是什么？有什么作用？ 光照贴图，是一种纹理类型，编码格式取决于不同的平台 预先计算场景中物体表面的亮度，可以包含直射光和间接光，并将结果存储在LightMap中供以后使用 通过降低实时光照计算量，在保证效果的同时，大幅提升游戏性能，适合性能较低的硬件，如移动平台 打包有使用过什么自动化工具吗？ OrangeStudio Assetbundle插件：自动打AB包、自动加密AB包 RenderTexture是什么，它有什么作用？ 一种特殊的Texture类型，本质是将一个FrameBufferObject连接到一个server-side的Texture对象 可以显示一个摄像机渲染的画面 FrameBuffer就是gpu里渲染结果的目的地，我们绘制的所有结果（包括color depth stencil等）都最终存在这个这里，有一个默认的FBO它直接连着我们的显示器窗口区域，就是把我们的绘制物体绘制到显示器的窗口区域。但是现代gpu通常可以创建很多其他的FBO，这些FBO不连接窗口区域，这种我们创建的FBO的存在目的就是允许我们将渲染结果保存在gpu的一块存储区域，待之后使用 在渲染过程中，贴图最开始是存在cpu这边的内存中的，这个贴图我们通常称为client-side的texture，它最终要被送到gpu的存储里，gpu才能使用它进行渲染，送到gpu里的那一份被称为server-side的texture。这个tex在cpu和gpu之间拷贝要考虑到一定的带宽瓶颈 unity的RenderTexture将这个fbo直接关联一个gpu上的texture对象，这样就等于在绘制时就直接绘制到这个texure上，这样也省去了拷贝时间 谈一谈你所知道的Unity内存优化方法 关键词：Mipmap、Shader变体、开发者编程习惯、项目设置、资源导入设置、AB包、剔除、合批、简化、UI Shader层面 做好Shader变体的剔除，主要原因是Shader的关键字过多 托管内存优化 C#语言层面： 装箱操作：指类型转换到引用类型的转换，会造成额外的内存开销。使用Lua等脚本语言做热更新逻辑的开发者，在封装交互接口时，尽量不要传递Unity引擎里定义的对象，尽量保证调用的函数接口传递或返回基础类型值对象 String字符串拼接：做字符串拼接应尽量使用StringBuilder进行 闭包分配：一般是指代码段中使用了代码段之外定义的变量，如匿名函数或Lambda表达式，当调用这一类代码段时，托管堆中会生成一个类来保存这些代码段中引用到的外部变量，会有额外的内存开销 避免使用Linq库写任何游戏内的代码：它们会生成大量托管堆上的垃圾内存 Unity相关代码调用： Unity中提供了很多NonAlloc函数（无托管内存开销的函数） 一些Unity类成员变量访问的方式：如直接通过”.”调用的成员变量，应尽量采用”.Get”的方式去调用 无论是C#还是Unity相关的代码调用，如果发生在循环或者每帧更新的函数里，造成的托管内存开销会更大 不要在循环或每帧更新的逻辑中反复去Instance对象，应尽量在初始化时利用内存池预先分配好，避免在运行过程中的GC开销 当发现游戏每帧GC开销变化过大时，可以开启BuildSetting-Player中的增量GC选项，它可以将一帧中的GCCollect调用分摊到多帧进行，可以有效地平滑你的游戏帧率 BuildSetting中的关于程序集优化的配置：在Optimization标签下，默认会勾选Strip Engine Code选项，开启这个选项后，如果backend是IL2CPP的情况下，Unity会删除项目不使用的Unity引擎的代码，不仅会对包体大小有优化，对应用程序内存的占用也可以减小 Strip Engine Code选项下面的Managed Stripping Level，可以根据包体和内存的需求进行配置，它会根据不同的选项自动删除托管dll中的不使用的代码，同样也可以减小包体的同时减少内存的占用，不过当设置的级别过高时会导致误删某些C#接口导致编译出错，这时你可以为误删除的接口打上Preserve的属性标签以防止这个接口被删除。也可以使用linker.xml文件进行更详细的配置，不过这个选项只针对需要极限优化的项目，如果嫌配置麻烦，默认选项就好 打包优化 AssetBundle可以用于资源更新，减少安装大小，针对平台加载优化资源，减轻运行时内存压力。AssetBundle是一个容器，包含存档文件包头、以及序列化类型文件与资源文件 AB包体不能因为避免重复引用，拆得过于细碎，2M-5M的包体是一个合理的参考值（移动平台下）。过小的包体，包头占用内存压力会比较大。一些操作系统，如IOS，也会有同时开启多个文件具体的数量限制，很容易就超过系统限制上限了；另外资源加载与销毁，反复创建销毁文件句柄，会造成系统资源开销大，电量消耗也会加大 如果确定使用相同版本Unity发布打包，后续开发不会升级Unity版本，AB包体不做Unity版本兼容时可以尝试开启打包选项BuildAssetBundleOption.DisableWriteTypeTree选项，这样TypeTree信息不会被打到AB中，可以极大减小包体大小及运行加载时的内存开销 避免同一个资源被打入多个AB中，会增加运行时内存开销，可以使用UPR Assets Checker工具来做检查。某些情况下，Unity创建资源时，会默认引用一些Unity内置资源，打包时不注意的情况下，这份内置资源会被打到多个AB包中。如创建默认粒子时，默认引用Unity内置资源DefaultParticle.png,如果要避免这种情况，可以用自定义资源替换默认引用资源 剔除(Culling)层面 剔除的对象有：看不见的像素、网格和对象，重复的、用不到的资源，不需要、不执行的代码 常用剔除操作有： 像素剔除：摄像机平截头剔除、Back-face Culling（背面剔除）、Early-Z、Pre-Z Pass。其中摄像机剔除、背面剔除与Early-Z都是渲染库或硬件直接支持的部分，而Pre-Z Pass是针对于前向渲染下Early-Z失效的情况下，通过Pre-Z Pass方式提前获取场景深度，后续绘制像素时，根据场景深度外壳进行像素着色计算的剔除。是Unity2021URP下直接提供的新功能 网格对象级别的剔除：Unity提供了Layer Mask、可视距离对象剔除与Occlusion Culling的方案，前两种都可以通过简单的设置完成，而Occlusion Culling是一种CPU+烘焙的方案，在某些OverDraw严重而又存在大面积建筑或遮挡体类型的游戏中，可以起到加速的效果，但Occlusion Culling本身是一把双刃剑，由于烘焙会有额外的内存开销，而所有关于遮挡剔除的计算又在CPU端，会由额外的CPU开销。如果剔除给GPU端的优化弥补不了CPU端的开销时，这种方案可能是一种负优化，需要测试使用 灯光剔除：这部分需要依赖特殊的图形库和硬件的架构完成，比如Tile-Based Deferred Rendering，也就是通常所说的TBDR管线和Forward+渲染管线，针对于多实时光源在游戏项目上的光源剔除优化，在灯光处理上会为每个Tile建立可用的灯光列表，这时不能影响该Tile内像素的灯光将会被剔除在列表之外，这样在计算该Tile中的像素着色时可以大大节省像素光照着色的开销。目前URP下的Tile-Based延迟渲染在Unity2021中已经支持。URP Forward+管线目前仍在实验阶段，但仍可在Unity2021URP下通过定义URP_ENABLE_CLUSTERED_UI的宏来开启，从宏定义中我们也可以看出URPForward+采用的加速结构是基于Clustered的。对比而言，即使Tile-Based延迟渲染在带宽与内存上做了优化，但仍会比Forward+要高，而Forward+的性能瓶颈依然在场景对象复杂度上。因此如何选择管线要根据自己的游戏类型和目标设备来进行选择 场景剔除：是针对于大场景、多场景拼接的地图，这时我们可以通过Unity Additive的场景根据逻辑来做异步的加载和卸载，以实现场景的动态剔除，这也算是另类的Culling的一种了 用户也可以扩展自己的Culling优化方案。如默认Unity下没有场景数据结构管理，可以通过添加各种场景结构来对场景中的对象进行管理，如Octree、BSP Tree、Portal等，还有对整个场景进行体素化（Voxelization），或者计算场景的SDF，这些数据结构都是为了做Culling加速或其他功能的必要数据。另外还有一些利用GPU加速的算法，如通过Hi-Z Pass利用上一帧的深度图和摄像机矩阵；利用Temporal Reprojection Culling算法来对当前这个场景做剔除；另外还有Cluster、Tile-based Visible Buffer算法，这些都可以在Unity的管线中进行扩展集成 合批(Batching)层面 常用合批操作有： 资源Batching(Mesh、Texture、Shader参数、材质属性) Draw call Batching(Static Batching、Dynamic Batching) GPU Instancing(直接渲染、间接渲染、程序化间接渲染) Set Pass call Batching(SRP Batching) 注意： 我们可以将临近且不移动的网格对象通过Mesh.CombineMesh合并到一起，合并后用一次网格的渲染调用代替每个网格的渲染调用。但这种方案也有一定的弊端，一旦合并的网格对象较大时，可能造成摄像机剔除不掉的问题以及OverDraw的问题，另外在内存上也会增加一定的开销 Static Batching功能会有额外的内存开销，所有合批的网格对象都会在内存中保留一份额外的拷贝，是一个典型的空间换时间的优化方案 简化(Simplization)层面 运行效率较重的资源是做Simplization的对象。如运行时内存占用较高，或处理耗时较长的资源 常用简化操作有： Quality Settings：通过这个设置，你可以自定义在不同平台、设备下，Unity现有的一些功能的设置分级。你可以预先设置在哪些平台下开启或不开启某些功能，包括分辨率、贴图分辨率、阴影质量等的一系列设置 通过烘焙光照简化实时光照：在静态灯光场景下，可以使用烘焙的方案替代实时光照方案 通过BoundingBox或替代体碰撞代替Mesh碰撞 用Local Volume代替Global Volume来做特效与后效的区分 用多条RayCast射线检测方式代替开销比较高的SphereCast、CapsuleCast等 用纹理字体代替系统文字 Mesh LOD：根据距离采用不同复杂度级别的Mesh进行渲染，以达到不影响视觉表现，同时带来更小的开销 Shader LOD：来做多平台或低端设备上的兼容性，尤其是一些Shader效果需要图形API版本要求时 HLOD：是Unity针对于大世界提出的一种简化方案。它可以在长视距下用单个静态网格组合替代多个静态网格对象，有助于减少场景渲染对象的个数，同时减少DrawCall调用次数来做场景渲染优化。这个方案会有一定的CPU与内存开销，要看具体项目类型测试后采用 通过Camera Override代替URP管线中的一些通用设置：避免了在管线中创建一些长时间无用的渲染资源，比如Copy Depth、Copy Color等这些创建的RP资源 各种OnDemand更新或分级设置接口：如OnDemandRendring 用户也可以通过脚本或插件做一些自定义的简化操作 SDF体素化、点云等都是做简化渲染的重要手段 第三方LOD方案：如Automatic LOD、Poly Few|Mesh Simplifier and Auto LOD Generator、Mesh Simplify、Amplify Impostors等，在资源商店搜索LOD或Simplify可以找到很多插件 Mesh Impostor Animation LOD：不光模型，动画方面也可以尝试做LOD。比如做动画频率的LOD，可以根据视距降低远处角色的动画频率，或使用骨骼LOD为远距角色采用另一套骨骼较少的骨骼框架 2D寻路代替Navigation Mesh 扩展类似OnDemand接口：实现按需创建或按需更新的逻辑，对于一些复杂的游戏资源或逻辑也是非常必要的 其他层面 Texure2D纹理资源优化 当场景中所有使用的纹理都开启了MipMap模式，这样我们可以通过Quality Setting中的Texture Quality选项来强制使用某一级别的MipMap Level Texture进行渲染，这样实际被加载到显存中的纹理，只有这一级Mipmap及其以下级别的纹理，占用的显存也会相对更少 还可以利用Unity提供的Mipmap Streaming功能来做运行时动态调整，除需要对应纹理开启Mipmap导入设置的同时，还需要将纹理导入设置的Streaming Mipmap功能选项打开，同时开启Quality Settings中的Texture Streaming功能选项，该功能会强制Unity仅加载渲染当前相机所需级别的Mipmap层级，使用少量CPU资源来节省大量GPU上的内存，不过这个功能需要开发者非常了解其实现原理，如果只是傻瓜式开启，往往达不到优化效果，甚至设置不合理会导致画面损失较大，甚至负优化的产生 Alpha Is Transparency选项： 指定Alpha通道是否开启半透明，如果位图像素不关心是否要半透明可以不开启此选项。这样Alpha信息只需要占1bit，节省内存 Read&#x2F;Write选项：开启会导致纹理内存使用量增加一倍 Wrap Mode、Filter Mode、Aniso Level： 有选择地使用三线性过滤，因为与双线性过滤相比，它需要更多的内存带宽；使用双线性和 2x 各向异性过滤，而不是三线性和 1x 各向昇性过滤，因为这样做不仅视觉效果更好，而且性能也更高；保持较低的各向异性级别。仅对关键游戏资源使用高于 2 的级别 Filter Mode中的Trilinear：几乎和Bilinear一样，只是Trilinear还会在多级渐远纹理之间进行一个混合，多级渐远纹理技术是将原纹理提前用滤波处理来得到很多更小的图像，形成一个图像金字塔，每一层都是对上一层的图像降采样的结果，需要在实时运行时快速得到像素，但也会额外多占用33%的内存。 纹理的大小 直接影响内存与显存占用的大小，同时对GPU纹理采样、CPU加载和带宽造成影响 选择合适纹理大小应尽量遵循以下经验： 不同平台、不同硬件配置选择不同的纹理大小，Unity下可以采用Bundle变体设置多套资源、通过Mipmap限制不同平台加载不同level层级的贴图 根据纹理用途的不同选择不同的纹理加载方式，如流式纹理加载Texture Streaming、稀疏纹理Sparse Texture、虚拟纹理VirtualTexture等方式 不能让美术人员通过增加纹理大小的方式增加细节，可以选择细节贴图DetailMap或增加高反差保留的方式 在不降低视觉效果的情况下尽量减小贴图大小，最好的方式是纹理映射的每一个纹素的大小正好符合屏幕上显示像素的大小，如果纹理小了会造成欠采样，纹理显示模糊；如果纹理大了会造成过采样，纹理显示噪点。这一点做到完美很难保障，充分利用SceneView -&gt; DrawMode -&gt; Mipmap来查看在游戏摄像机视角下哪些纹理过采样，哪些纹理欠采样来调整纹理大小 现代显卡对纹理的支持为2的幂次方，如1024x1024、512x256,不要求长宽相等，只要求长宽大小为2的幂次即可。不符合大小的纹理，Unity在导入时会自动设置成最小符合2的幂次方的大小，但这样的设置一定会造成纹理大小的浪费 纹理压缩：纹理压缩是指图像压缩算法，保持贴图视觉质量的同时，尽量减小纹理数据的大小。默认情况下我们的纹理原始格式采用PNG或TGA这类通用文件格式，但与专用图像格式相比他们访问和采样速度都比较慢，无法通用GPU硬件加速，同时纹理数据量大，占用内存较高。所以在渲染中我们会采用一些硬件支持的纹理压缩格式，如ASTC 、ETC、ETC2、DXT等 使用纹理图集可以减少碎纹理过多，因为他们打包在一个图集里，通过压缩可以有效的利用压缩，隆低纹理的内存成本和冗余数据 PostProcessing优化 尽量将不需要的效果直接删除，而不是通过复选框禁用。因为有些效果即使你禁用了，它的一些渲染资源依旧会被预先绑定，会导致内存的浪费 UI字体资源导入时的设置 如果使用的是对应操作系统中已有的字体，不勾Include Font Data选项则可以节省内存与输出包大小 滚动视图Scroll View 首先，它是个容器，需要大量实例化子对象控件，子对象控件简单点还好，如果过于复杂会有效率问题。不光对象大量实例化开销，由于视图滚动还要触发UI的Rebuild开销。这时我们需要做两个工作来进行优化： 使用RectMask2d组件裁剪，通过模板缓冲剔除不必要的渲染。注意不要使用不规则的滚动视图，因为RectMask2d没有使用模板缓冲，而直接使用Rect相交检测去裁剪，如果是不规则形状则需要PixelMask写额外的Shader来做剔除，这样会有额外的渲染开销 可以通过可视化位置构建子元素对象池，以减小内存与实例化的开销。这里的内存池是根据子对象的渲染位置来做的内存池，而不是对所有子对象做的内存池 工程结构优化 Resources文件夹通常是Unity项目中性能问题的主要来源。使用不当很容易造成Unity项目构建出现膨胀，导致内存消耗过高、应用程序启动时间显著增加、应用程序包体过大等问题。强烈建议在正式项目中，不要使用Resources目录，应尽量使用AssetsBundle方式进行构建和加载资源 音频层面 Force To Mono选项：强制将双声道的音频改为单声道。当左右两声道音频完全相同时，开启此选项可以在内容不丢失的情况下，减小内存和大小，尤其是在移动平台 当游戏需要静音时，不要简单得将音量设置为0，应该销毁音频组件（Audio Source），将其从内存中完全卸载 音乐音效一般不会成为优化的瓶颈，但可以减小内存的使用和安装文件的大小，使用第三方的和带有复杂逻辑的除外 什么是DrawCall？如何降低DrawCall？ 每次CPU准备数据并通知GPU的过程就称之为一个DrawCall Unity中的碰撞器和触发器的区别？ 略 如何处理AssetBundle资源依赖问题？ Unity3d中的灯光有哪些？ 有接过SDK吗？ 动态加载资源的方式有哪些？ RectTransform和Transform的关系和区别是什么？ 请尝试写一个跟踪弹逻辑（平滑跟踪）为跟踪弹添加一个刚体组件，为刚体添加一个指向目标物体的力（需归一化向量） 如何安全的在不同工程间安全地迁移asset数据？ 向量的点乘、叉乘以及归一化的意义是什么？ Unity3d的物理引擎中，有几种施加力的方式，请分别描述出来 MeshRender中material和sharedmaterial的区别？ 什么是渲染管线？并写出渲染管线的3个阶段，说出顶点着色器和片元着色器在其中的哪些阶段进行 简述四元数Quaternion的作用，四元数对欧拉角的优点？ 单例模式的作用和缺点是什么？ UI框架是如何实现的？ 如何用Animtor做融合动画？ 在项目里都用过哪些设计模式？ Lua多继承如何实现？ UI多层级叠加是如何处理的 写一个算法，将数字67、58、43先转换为二进制，再转换为12位字符串(不够12位的话用0补齐)。如5的二进制为101，对应的12位字符串为000000000101 JSON和XML的区别是什么？ Lua为什么能进行热更新？ 请用Shader实现简单的Phong光照模型，至少包含放相关和环境光的计算 Lua和C#是如何进行交互的？ 请使用一个int变量记录多个状态？如记录英雄同时存在跑步、攻击、跳跃等状态，并判断英雄是否有某个状态 请写一个你熟悉的游戏类型（如贪吃蛇），并说明这个游戏类型可抽象出哪些模块 如何优化性能、内存、包体大小？有借助什么工具？ 不同的手机设备尺寸分辨率都不一样,该如何进行适配? LineRenderer中的关键参数有哪些？ Unity中如何知道一个游戏包体大小，具体的素材占用情况？ 说一下游戏中的对象池有什么作用，如何实现？ 如何处理场景中物体的点击事件？ 事件中心有什么作用？如何实现？ TCP协议与UDP协议的区别 请简述GC产生的原因，并描述如何避免？ LOD和MipMap分别是什么？并简要描述他们的优缺点 Lua中pairs 和 ipairs区别是什么？ 请为任意类型的数组，拓展一个获取数组中随机索引对应值的方法 反射的实现原理是什么？"},{"title":"games101_L09_着色3(纹理映射 续)","date":"2023-04-15T13:10:59.000Z","url":"/2023/04/15/games101-L09/","tags":[["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; "},{"title":"games101_L08_着色2(渲染管线、纹理映射)","date":"2023-04-15T06:23:10.000Z","url":"/2023/04/15/games101-L08/","tags":[["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; "},{"title":"games101_L07_着色1(光照、着色)","date":"2023-04-15T04:42:36.000Z","url":"/2023/04/15/games101-L07/","tags":[["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; "},{"title":"games101_L06_光栅化(续) 反走样与深度缓冲","date":"2023-04-14T11:50:00.000Z","url":"/2023/04/14/games101-L06/","tags":[["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; "},{"title":"games101_L05_光栅化","date":"2023-04-13T10:38:22.000Z","url":"/2023/04/13/games101-L05/","tags":[["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; "},{"title":"games101_L04_变换 (续)","date":"2023-04-13T10:38:18.000Z","url":"/2023/04/13/games101-L04/","tags":[["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; "},{"title":"games101_L03_变换","date":"2023-04-11T12:54:50.000Z","url":"/2023/04/11/games101-L03/","tags":[["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; "},{"title":"games101_L02_线代综述","date":"2023-04-11T12:54:46.000Z","url":"/2023/04/11/games101-L02/","tags":[["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; "},{"title":"算法与数据结构_6_","date":"2023-03-29T05:22:21.000Z","url":"/2023/03/29/LeetCode-6/","tags":[["算法与数据结构","/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; "},{"title":"算法与数据结构_5_二叉树","date":"2023-03-22T11:26:36.000Z","url":"/2023/03/22/LeetCode-5/","tags":[["算法与数据结构","/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 二叉树 二叉树节点结构 一个值类型 一个指向左孩子的指针 一个指向右孩子的指针 左孩子、右孩子都为空的叫做叶节点 最顶的节点叫做根节点或头节点 二叉树的遍历，最简单是递归 先序 (头左右) : 递归序中第一次遇到该节点 中序 (左头右) : 递归序中第二次遇到该节点 后序 (左右头) : 递归序中第三次遇到该节点 非递归先序 流程 : 准备一个栈，先把头节点放进去 每次 : 从栈中弹出一个节点cur 打印(处理)cur 先右再左(如果有) 周而复始 非递归后序 流程 : 准备一个栈，先把头节点放进去，再准备一个收集栈 每次 : 弹当前节点cur cur放入收集栈，弹一个放一个 先压左再右 周而复始 非递归中序 流程 : 每颗子树，整棵树左边界进栈，依次弹的过程中，打印，对弹出节点的右树重复 如何直观打印一颗二叉树 如何完成二叉树的宽度优先遍历 宽度遍历(层序遍历)用队列，头部进尾部出，先进先出，先放左孩子再放右孩子 常见题目 : 求一棵二叉树的最大宽度 二叉树的相关概念及其实现判断如何判断一颗二叉树是否是搜索二叉树 搜索二叉树 :对于每一颗子树来说，都满足 : 左数的节点都比它小，右树的节点都比它大(没有重复值) 中序遍历 如何判断一颗二叉树是否是完全二叉树 完全二叉树 :每层是满的，最后一层即使不满，也是从左往右变满的情况 判断条件 : 1)任一节点，有右无左返回false 在1)不违规的条件下，如果遇到了第一个左右孩子不双全的情况下，那么接下来遇到的节点都为叶节点，否则返回false 如何判断一颗二叉树是否是满二叉树 麻烦做法 :先求最大深度L，再求节点个数N，满足深度N &#x3D; 2^L - 1 如何判断一颗二叉树是否是平衡二叉树 平衡二叉树 :对于任何一颗子树来说，左树与右树的高度差不超过1递归套路，返回两个信息，是否平衡和高度 树型DP的题，用递归套路，在可以向左右树索取信息的想法下 题目 : 给定两个二叉树的节点node1和node2，找到它们的最低公共祖先节点(首个汇聚的点) 在二叉树中找到一个节点的后继节点 后继节点 :中序遍历中，一个节点的下一个节点 二叉树的序列化和反序列化就是内存里的一颗树如何变成字符串形式 做法 :先序遍历，数值直接写，值的结束用下划线_，遇到null用特殊字符#下划线换成用逗号分割，类似数组先建头节点，先建左子树，遇到空(#)返回上级建右子树 题目 : 对折一张纸n次打开，请打印出折痕凹凸情况规律 : 每次对折后，在上一次的每个折痕的上下都会出现一个新的折痕，上面的是凹折痕，下面的是凸折痕 这是一颗头节点为凹折痕，每一棵左子树都是凹折痕，每一颗右子树都是凸折痕的满二叉树 "},{"title":"算法与数据结构_4_稳定性、排序算法总结、综合排序、哈希表、有序表","date":"2023-03-20T11:57:48.000Z","url":"/2023/03/20/LeetCode-4/","tags":[["算法与数据结构","/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 稳定性 值排完序后相同的值，次序不变 排序算法总结 总结： 一般来讲，选择快排，因为参数项较优 空间实在不够时用堆排 需要稳定性时用归并 基于比较的排序，目前找不到时间复杂度在O(N * logN)以下的 基于比较的排序，在时间复杂度O(N * logN)时，目前找不到空间复杂度做到O(N)以下且稳定 常见的坑： 归并排序的额外空间复杂度可以变成O(1)，非常难不需要掌握，搜“归并排序 内部缓存法”，那时稳定性会丧失，那为什么不用堆排呢 “原地归并排序”的帖子都是垃圾，它让额外空间复杂度变成O(1)，但时间复杂度变成O(N^2)，那为什么不用插入呢 快排可以做到稳定性，非常难不需要掌握，搜“01 stable sort”，做到的同时会让额外空间复杂度变成O(N)，那为什么不用归并呢 所有的改进都不重要 有一道题目，一个整形数组，请你做到奇数放到左边，偶数放到右边，还要求奇数之间的相对次序不变，偶数之间的相对次序不变，要求额外空间复杂度O(1),还做到时间复杂度O(N)。这是面试官在搞你。因为分奇偶相当于快排的partition，做不到稳定性。 综合排序 根据样本量 和 各自的排序算法的优势 选择不同的排序方式 工程上对排序的改进 充分利用O(N * logN)和O(N^2)排序各自的优势。如&lt;60用插入，&gt;&#x3D;60用归并 稳定性的考虑。如基础类型用快排，自定义类型用归并 哈希表、有序表哈希表 在C++中叫 : UnOrderedMap &#x2F; UnSortedMap 、 UnOrderedSet &#x2F; UnSortedSet 在Java中叫 : HashSet &#x2F; HashMap Map、Set Map : Key -&gt; Value Set : Value 唯一的区别是 有无伴随数据 Java示例： 哈希表在使用(增删改查)时，时间复杂度都认为是常数级别(比较大的常数)O(1)，且跟数据量无关 哈希表在使用层面上可以理解为一种集合结构 放入哈希表的东西，是基础类型(Java中包括String)，按值传递，一律拷贝一份放表里；不是基础类型，按引用传递，内存占用是这个东西内存地址大小，一律8字节 有序表 在C++中叫 : OrderedMap &#x2F; SortedMap 、 OrderedSet &#x2F; SortedSet 在Java中叫 : TreeSet &#x2F; TreeMap Java示例： 有序表把key按照顺序组织起来 性能上比哈希表差一点，所有操作都是O(logN)级别的 红黑树、AVL树、size-balance-tree和跳表等都属于有序表结构，只是底层具体实现不同 放入有序表的东西，如果是基础类型，内部按值传递，内存占用就是这个东西的大小如果不是基础类型，必须提供比较器，内部按引用传递，内存占用是内存地址大小 链表 单链表、双链表结构 题目 : 给定一个单链表的头节点head，请判断该链表是否为回文结构。例子 : 1-&gt;2-&gt;1，返回true; 1-&gt;2-&gt;2-&gt;1，返回true; 1-&gt;2-&gt;3，返回false。要求 : 如果链表长度为N，时间复杂度达到O(N)，额外空间复杂度达到O(1)。 方法一 : 方法二(快慢指针) : 将单向链表按某值划分成左边小、中间相等、右边大的形式 题目 : 给定一个单链表的头节点head，节点的值类型是整形，再给定一个整数pivot。实现一个调整链表的函数，将链表调整成左部分都是值小于pivot的节点，中间部分都是值等于pivot的节点，右部分都是值大于pivot的节点。 进阶要求 : 再实现原问题功能的基础上增加如下要求 调整后三部分里所有节点之间的相对顺序和调整前一样 时间复杂度达到O(N)，额外空间复杂度达到O(1) 笔试做法 : 申请一个Node类型数组，把每一个值放进去，在这个数组上patition(没稳定性) 面试做法 : 复制含有随机指针节点的链表 题目 : 一种特殊的单链表节点类描述如下class Node{ int value; Node next; Node rand; Node(int val) { value &#x3D; val; }}rand指针是单链表节点结构中新增的指针，rand可能指向链表中的任意一个节点，也可能指向null。给定一个由Node节点类型组成的无环单链表的头节点head，请实现一个函数完成这个链表的复制，并返回复制的新链表的头节点。 要求 : 时间复杂度O(N)，额外空间复杂度O(1)。 题目 :给定两个可能有环也可能无环的单链表，头节点head1和head2.请实现一个函数，如果两个链表相交，请返回相交的 第一个节点；如果不相交，返回null。要求 :如果两个链表长度之和为N，时间复杂度请达到O(N)，额外空间复杂度请达到O(1)。 法一 哈希表:使用一个哈希表(Set)，每往下走一个节点，查询一遍该节点是否已存在哈希表中，直到next走到null或相同为止 法二 快慢指针:如果快慢指针能相遇，则有环，这时让快指针回到head，两指针一起一步一步走，会在环的第一个节点相遇 "},{"title":"算法与数据结构_3_快排、堆、比较器","date":"2023-03-19T03:16:26.000Z","url":"/2023/03/19/LeetCode-3/","tags":[["算法与数据结构","/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 快排 额外空间复杂度：好情况O(logN),差情况O(N) 完全二叉树 左孩子 : 2 * i + 1右孩子 : 2 * i + 2父节点 : (i - 1) &#x2F; 2 有N个节点时，高度是logN级别 heapInsert时，只关心父节点的路径上走多少高度，所以用户新加一个数字时，调整的代价是O(logN)级别 用户想删掉一个数，并让剩下的数重新调整堆的代价也是O(logN)级别 堆 堆结构就是用数组实现的完全二叉树结构 完全二叉树分为大根堆、小根堆 大根堆 : 每个子树最大值都是头节点 小根堆 : 每个子树最小值都是头节点 堆结构的heapInsert和heapify操作 维持大根堆 : 将每次放进数组的值跟它的父节点的值做比较并调整，这个过程称为heapInsert heapInsert : 假设用户需要返回最大的数，这个数就是arr[0] 假设用户需要删除最大的数，做法是 :交换第一个和最后一个数，同时heapsize–，不断比较两个孩子中最大的一个与父节点的大小，并调整，这个过程称为heapify heapify : 堆结构的增大和减小 heapSort 用户加数O(NlogN),heapify时O(NlogN),整体O(NlogN),额外空间复杂度O(1) mergeSort额外空间复杂度O(N),快排O(logN) 如果用户一股脑给出所有数组，要求弄成大根堆，可以从后往前做heapify，从倒数第二层开始，都只用往下进行一次heapify 这时时间复杂度 :(如果数组中有N个数，想象成满二叉树，这时最底层节点N&#x2F;2个)T(N) &#x3D; N&#x2F;2 + N&#x2F;4 * 2 + N&#x2F;8 * 3 + N&#x2F;16 * 4 + …2T(N) &#x3D; N&#x2F;2 * 2 + N&#x2F;2 * 2 + N&#x2F;4 * 3 + …T(N) &#x3D; N + N&#x2F;2 + N&#x2F;4 + N&#x2F;8 + … &#x3D; O(N) 优先级队列结构，就是堆结构 堆排序扩展题目 已知一个几乎有序的数组，几乎有序是指，如果把数组排好顺序的话，每个元素移动的距离可以不超过k，并且k相对于数组来说比较小。请选择一个合适的排序算法针对这个数据进行排序 比较器 实现Comparator接口，重载int compare()方法，可写成内部类 对于sort排序如果返回负数，认为第一个参数应该放在前面如果返回正数，认为第二个参数应该放在前面如果返回0，认为谁在前面都行 对于new PriorityQueue&lt;&gt;(new AComp())的创建如果返回负数，认为第一个参数应该放在上面如果返回正数，认为第二个参数应该放在上面如果返回0，认为谁在上面都行 不基于比较的排序 不基于比较的排序 必须分析数据状况来定制 计数排序 员工的年龄，建一个数组age[200],遍历一般，将下标对应成年龄来计数，如 1岁 arg[1]++。O(N) 基数排序 [17 13 25 100 72]排序，先看最大的数字是几位按十进制数看[017 013 025 100 072]准备容器(可以是数组&#x2F;队列&#x2F;栈)，叫做桶这里假设桶是队列，准备10个桶先根据各位数字来 017放到7号桶 013放到3号桶 …把桶中的所有数字依次倒出来[100 072 013 025 017]再按十位数决定进哪个桶 100进0号桶 072进7号桶 …把桶中的所有数字依次倒出来[100 013 017 025 072]最后按百位数字决定进哪个桶 100进1号桶 013 017 025 072进0号桶把桶中的所有数字依次倒出来[013 017 025 072 100] 基数排序代码 "},{"title":"算法与数据结构_2_递归、master公式、归并排序、荷兰国旗问题、快排","date":"2023-03-18T02:08:32.000Z","url":"/2023/03/18/LeetCode-2/","tags":[["算法与数据结构","/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 递归 算中点距离： mid &#x3D; (L + R) &#x2F; 2 : L + R可能越界 mid &#x3D; L + (R - L) &#x2F; 2 : 更好 等同于 L + (R - L) &gt;&gt; 1 : 右移一位比&#x2F;2要快 递归求一个数组的最大值 master公式 T(N) &#x3D; a * T(N &#x2F; b) + O(N^d) T(N) : 母问题规模 T(N &#x2F; b) : 子问题的规模 a : 子问题的调用次数 O(N^d) : 除去调用之外，剩下的过程的时间复杂度 只要是满足子问题等规模的递归，都可以用master公式求解时间复杂度 logb^a &lt; d O(N^d)logb^a &gt; d O(N^logb^a)logb^a &#x3D;&#x3D; d O(N^d * logN) 归并排序 小和问题 荷兰国旗问题 给定一个整形数组和一个数，要求按这个数将数组分为3个区域，&gt; &#x3D;&#x3D; &lt;。 [i] &lt; num, [i] 和&lt; 区域下一个交换, &lt;区域右扩, i++ [i] &#x3D;&#x3D; num, i++ [i] &gt; num, [i] 和&gt; 区域前一个交换, &gt;区域左扩, i不变 快速排序 快排1.0 拿最后一个数num做划分 前面的数 &lt;&#x3D; num的放左边, &gt; num的放右边 大于区域的第一个数和num做交换 让左侧和右侧重复这个行为 快排2.0 利用荷兰国旗问题，一次搞定一批相等的数，比1.0快 用最后一个数num做划分 前面的数分成 &lt;num &#x3D;&#x3D;num &gt;num三个区域 把num和&gt;num区域第一个数交换 让左侧和右侧重复这个行为 快排3.0 随机选一个数，放在最后，拿它做划分值num 时间复杂度变成O(N * logN) "},{"title":"算法与数据结构_1_选择排序、冒泡排序、异或运算、插入排序、二分法","date":"2023-03-17T08:17:32.000Z","url":"/2023/03/17/LeetCode-1/","tags":[["算法与数据结构","/tags/%E7%AE%97%E6%B3%95%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 选择排序 冒泡排序 异或运算(^) 相同为0，不同为1 还可以理解成：无进位相加 性质： 面试题： 在一个整形数组int[] arr中，1）已知只有一种数出现了奇数次，其他的所有数都出现了偶数次怎么找到出现了奇数次的数2）已知有两种数出现了奇数次，其他的所有数都出现了偶数次怎么找到这两种数要求：时间复杂度O(N),额外空间复杂度O(1) key: 1) 2） 插入排序 时间复杂度O(N^2),额外空间复杂度O(1) 插入排序在某些数据状况下并不是严格的O(N^2)，会优于选择&#x2F;冒泡排序 时间复杂度 O是按算法最差情况下的时间复杂度， θ是平均状况下的时间复杂度， Ω是最好情况下的时间复杂度，后两个指标实际用处不大，可以不记，只用记O 二分法 在一个有序数组中，找某个数是否存在 遍历找一个数的方法，时间复杂度O(N) 二分法找，先找数组最中间的数，因为有序，所以可以砍掉一半，继续二分，时间复杂度O(log2^N)，默认都写成log(N) 8个 4个 2个 1个 log2^8 &#x3D; 砍3次 在一个有序数组中，找&gt;&#x3D;某个数最左侧的位置 做记号，二分到结束为止 局部最小值问题 数组无序，相邻数一定不相等 "},{"title":"Java笔记(3) —— 原码、反码、补码，位运算符","date":"2022-12-14T10:22:43.000Z","url":"/2022/12/14/JavaStudy-3/","tags":[["Java","/tags/Java/"]],"categories":[["undefined",""]],"content":"&nbsp; 二进制在运算中的说明 二进制是逢2进位的进位制，0、1是基本算符。数字1在不同的位上表示不同的值，按从右至左的次序，这个值以二倍递增 现代的电子计算机技术全部采用的是二进制，因为它只使用0、1两个数字符号，非常简单方便，易于用电子方式实现。计算机内部处理的信息，都是用二进制数来表示的 对于有符号的而言： 二进制的最高位是符号位：0表示正数，1表示负数 (0 -&gt; 0, 1 -&gt; -) 正数的原码、反码、补码都一样 负数的反码 &#x3D; 它的原码符号位不变，其他位取反 负数的补码 &#x3D; 它的反码 + 1， 负数的反码 &#x3D; 负数的补码 - 1 0的反码、补码都是0 java没有无符号数，换言之，java中的数都是有符号的 在计算机运算的时候，都是以补码的方式来运算的 当我们看运算结果的时候，要看它的原码 位运算符java中有7个位运算符(&amp;、|、^、 ～、&gt;&gt;、&lt;&lt;、&gt;&gt;&gt;): &amp;：按位与两位全为1，结果为1，否则为0 |：按位或两位有一个为1，结果为1，否则为0 ^：按位异或两位有一个为0，一个为1，结果为1，否则为0 ～：按位取反0 -&gt; 1, 1 -&gt; 0 例： 2&amp;3 &#x3D; int是4个字节，1个字节8比特，最开头是符号位 2的补码 &#x3D; 2的原码 00000000 00000000 00000000 00000010 3的补码 &#x3D; 3的原码 00000000 00000000 00000000 00000011 2&amp;3运算后的原码：00000000 00000000 00000000 00000010 结果为2 ～-2 &#x3D; -2的原码 10000000 00000000 00000000 00000010 -2的反码 11111111 11111111 11111111 11111101 -2的补码 11111111 11111111 11111111 11111110 取反操作 00000000 00000000 00000000 00000001 得到的是补码 取反后的原码 &#x3D; 它的补码 结果为 1 ～2 &#x3D; 2的原码 00000000 00000000 00000000 00000010 2的补码 00000000 00000000 00000000 00000010 取反操作 11111111 11111111 11111111 11111101 反码 11111111 11111111 11111111 11111100 原码 10000000 00000000 00000000 00000011 结果为 -3 **&gt;&gt;**：算术右移 低位溢出，符号位不变，并用符号位补溢出的高位 **&lt;&lt;**：算术左移 符号位不变，低位补0 **&gt;&gt;&gt;**：逻辑右移&#x2F;无符号右移 低位溢出，高位补0 无”&lt;&lt;&lt;”符号 例： int a &#x3D; 1&gt;&gt;2; 1 &#x3D; 00000000 00000000 00000000 00000001 右移2位 1 &#x3D; 00000000 00000000 00000000 00000000 (01) &#x3D; 0 本质相当于 1 &#x2F; 2 &#x2F; 2 &#x3D; 0 int a &#x3D; 1&lt;&lt;2; 1 &#x3D; 00000000 00000000 00000000 00000001 左移2位 1 &#x3D; 00000000 00000000 00000000 00000100 &#x3D; 4 本质相当于 1 * 2 * 2 &#x3D; 4 "},{"title":"Java笔记(2) —— 进制转换","date":"2022-12-12T14:21:58.000Z","url":"/2022/12/12/JavaStudy-2-DecimalConversion2-8-10-16/","tags":[["Java","/tags/Java/"]],"categories":[["undefined",""]],"content":"&nbsp; 进制介绍 对于整数，有四种表示方式： 二进制： 0、1 满2进1 以0b或0B开头表示 八进制： 0-7 满8进1 以数字0开头表示 十进制： 0-9 满10进1 十六进制： 0-9及A(10)-F(15) 满16进1 以0x或0X开头表示 (A-F不区分大小写) 例： 2、8、16 ——&gt; 10 从最低位开始，将每个位上的数提取出来，乘以进制数的**(位数 - 1)**次方，然后求和 例： 0b1011 &#x3D; 1 * 2^0 + 1 * 2^1 + 0 * 2^2 + 1 * 2^3 &#x3D; 11 01010 &#x3D; 0 * 8^0 + 1 * 8^1 + 0 * 8^2 + 1 * 8^3 &#x3D; 520 0x10101 &#x3D; 1 * 16^0 + 0 * 16^1 + 1 * 16^2 + 0 * 16^3 + 1 * 16^4 &#x3D; 65793 10 ——&gt; 2、8、16 将该数不断除以进制数，直到商为0为止，然后将每步得到的余数倒过来，就是对应的进制 例： 34&#x2F;2 &#x3D; 17 ··· 017&#x2F;2 &#x3D; 8 ··· 18 &#x2F; 2 &#x3D; 4 ··· 04 &#x2F; 2 &#x3D; 2 ··· 02 &#x2F; 2 &#x3D; 1 ··· 0 34(十进制) &#x3D; 0b00100010(二进制) 2 ——&gt; 8 从低位开始，将二进制数每三位一组，转成对应的八进制数即可 例： 0b11010101 &#x3D;0b11(3)010(2)101(5) &#x3D; 0325 2 ——&gt; 16 从低位开始，将二进制数每四位一组，转成对应的十六进制数即可 例： 0b11010101 &#x3D;0b1101(13-&gt;D)0101(5) &#x3D; 0xD5 8 ——&gt; 2 将八进制数每一位，转成对应的一个3位的二进制数即可 例： 0237 &#x3D;02(010)3(011)7(111) &#x3D; 0b010011111 16 ——&gt; 2 将十六进制数每一位，转成对应的一个4位的二进制数即可 例： 0x23B &#x3D;0x2(0010)3(0011)B(1011) &#x3D; 0b001000111011 "},{"title":"性能优化(40)——发布优化——打包优化","date":"2022-11-25T05:04:28.000Z","url":"/2022/11/25/performanceOptimization-35/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; AssetBundle AssetBundle是一个存档文件，包含运行时加载的特定平台的非代码资源，与彼此之间的依赖关系 AssetBundle可以用于资源更新，减少安装大小，针对平台加载优化资源，减轻运行时内存压力 AssetBundle是一个容器，包含存档文件包头、以及序列化类型文件与资源文件 构建AssetBundle参考策略 根据对象的修改频率差异拆分不同的AssetBundle 具有相同生命周期的资源打成一个AssetBundle，如果一个AB中只有不到50%的资源经常加载，可以考虑拆到不同的AssetBundle中 不可能同时加载的高低配置资源拆分到不同的AssetBundle 如果多个对象依赖于某个AssetBundle中的单个资源，这类单个资源可以单独打包或者根据生命周期将这类被多个对象依赖的资源打成共享AssetBundle 如果一组对象只是一个对象的不同版本，可以考虑使用AB变体（注意Addressable不支持AB变体） 构建AssetBundle值得注意的点 AB包体不能因为避免重复引用，拆得过于细碎，2M-5M的包体是一个合理的参考值（移动平台下）。过小的包体，包头占用内存压力会比较大。一些操作系统，如IOS，也会有同时开启多个文件具体的数量限制，很容易就超过系统限制上限了；另外资源加载与销毁，反复创建销毁文件句柄，会造成系统资源开销大，电量消耗也会加大 LZMA格式压缩的AB包较小，但需要完全解压后再加载，加载时间更长，LZ4格式压缩的AB包按块加载，加载时间较快，但包体大小较大，移动平台建议使用LZ4压缩格式 如果确定使用相同版本Unity发布打包，后续开发不会升级Unity版本，AB包体不做Unity版本兼容时可以尝试开启打包选项BuildAssetBundleOption.DisableWriteTypeTree选项，这样TypeTree信息不会被打到AB中，可以极大减小包体大小及运行加载时的内存开销 避免同一个资源被打入多个AB中，会增加运行时内存开销，可以使用UPR Assets Checker工具来做检查。某些情况下，Unity创建资源时，会默认引用一些Unity内置资源，打包时不注意的情况下，这份内置资源会被打到多个AB包中。如创建默认粒子时，默认引用Unity内置资源DefaultParticle.png,如果要避免这种情况，可以用自定义资源替换默认引用资源 不要使用AB包文件的MD5值作为更新包依据，因为可能包内资源没有变化的情况下，生成的AB包MD5值也会发生变化，一般可以选择计算包内原始资源的MD5值和路径变化作为AB包变化的依据 "},{"title":"性能优化(39)——发布优化——启动时间优化","date":"2022-11-23T10:22:45.000Z","url":"/2022/11/23/performanceOptimization-34/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 可分为两部分：启动到LOGO出现（Unity Pro版可以理解为自定义的Splash界面），LOGO出现到场景出现 在移动平台上，IOS和安卓平台的启动流程是有差异的 IOS平台启动时间优化 Pre main过程：是通过一系列镜像二进制文件操作加载可执行文件、加载动态链接器、dyld（the dynamic link editor）、通过dyld递归加载所有动态链接库（dyLib）的过程，按苹果官方说法，就是分析镜像文件、映射镜像文件、设定并绑定镜像文件、镜像文件初始化这几个过程 Main()函数执行过程：主要包括UnityInitTrampoline、UnityInitRuntime，以及通过UIApplicationMain启动UnityAppController，并带动ios相应的controller、view之间的调用与回调，并在didFinishLaunchingWithOptions回调函数中做UnityInitApplicationNoGraphics初始化。其中UnityInitTrampoline函数中主要是crash reporter的初始化与新iosAPI对应的替换工作。而UnityInitRuntime主要做各种配置的读取，设置各种运行时参数，解析gfx设备相关参数与初始化Unity Player，并在此阶段初始化文件系统与各个运行时模块初始化和clear up的注册工作。而UnityInitApplicationNoGraphics主要是做mono或il2cpp以及虚拟机的初始化，PlayerInitEngineNoGraphics过程与创建UI闪屏，并做UIStatusBar初始化工作。 到此为止，黑屏阶段结束，进入startUnity过程 ios main函数执行过程，可以通过查看导出的ios工程学习。但UnityInitRuntime以及UnityInitApplicationNoGraphics过程则需要有Unity引擎代码才能知道其中的细节 以上三个ios启动的过程，Pre main与start Unity这两块是我们可以通过一些手段来优化的，而ios main函数执行过程与回调过程需要有引擎源码才能做深入优化 IOS平台程序启动需要注意的点 不同的ios系统程序启动的时间会因ios版本的不同而略有差异 ios程序启动分为安装后首次启动、冷启动、热启动 冷启动：杀掉程序后重新启动 热启动：程序进入后台后再切回前台，一些资源和设备状态恢复的过程 一般我们所说的启动优化是指优化冷启动 启动时间超过20秒的程序会被系统自动杀掉 Unity默认竖屏程序比横屏程序启动时间略长，但这个差异一般情况下不明显 推荐Pre main过程耗费的时间最好不要超过400ms 这个过程在IOS14之前的版本，可以通过开启DYLD_PRINT_STATISTICS或DYLD_PRINT_STATISTICS_DETAIL到环境变量，然后在控制台输出信息中查看 但在IOS15版本以后，这个环境变量不起作用了，但可以借助XCode的Instruments Time Profiler查看整体的启动流程和时间消耗 IOS Pre Main阶段优化建议 要做镜像文件的瘦身动作，合并重复或删除用不到的一些代码 针对Unity引擎，在IOS Player Setting下开启Strip Engine Code来减少Unity引擎库大小，如果是一些第三方库，可以通过App Code检测当前没有使用到的类和代码并删除 减少不必要的Framework与引用的动态链接库的加载 使用Static Archives链接dyLib C++代码中减少全局静态变量的使用，以及过度抽象，注意虚函数表的开销（一般超过10000个的虚函数库会有明显的加载开销） OC对象将在+load方法中要做的事延迟到+initialize方法中 减少OC对象的metadata。比如减少OC的Class、Selector以及Category的数量 在运行initializers中尽量不要调用dlopen，不要创建线程 注意一些第三方库与平台SDK。它们经常是造成黑屏时间长的主要问题 Andorid平台启动时间优化 Andorid平台程序启动需要注意的点 不同版本的Andorid系统程序启动时间略有差异 Android启动分为首次启动、冷启动、热启动，一般我们所说的优化是指冷启动 App进入后台可能会被系统自动杀掉，恢复也算冷启动 Unity中Activity的andorid:launchMode属性一定要保证是SingleTask的，否则原生界面调出，或切到后台等都可能发生崩溃 通过adb logcat查看日志中Displayed标签来查看程序启动到显示前时间 通过Android Studio的Android CPU profiler工具来定位启动时瓶颈 通过GooglePlay的Android vitals来发现启动异常问题 一些三方库与平台SDK对启动时间的影响 Andorid启动优化建议 减少Activity onCreate函数中复杂的逻辑工作 将所有的资源初始化做Lazy Load放到不同的线程中，不要全部放到主线程中 ios下的start unity过程与Andorid下的start up过程的优化建议 这个过程的优化完全可以在unity编辑器下完成 "},{"title":"性能优化(38)——发布优化——耗电量与发热量优化","date":"2022-11-21T02:09:34.000Z","url":"/2022/11/21/performanceOptimization-33/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 准备 测试手机的耗电量与发热量前，需要检测手机电池是否健康。健康度是否良好，是优化的前提 除了一些手机自带的电池健康度、温度接口外，还可通过第三方工具进行检测，如XCode的耗电量分析、UPR的耗电与电池温度监测等 功耗与发热量优化 功耗与手机发热的本质依旧是性能优化问题，现代手机芯片都会设定一个手机临界温度，在手机触发这个温度墙时，系统为了保护硬件，会对芯片做降频处理，这直接会导致手机运行游戏时出现掉帧的情况。一般来说，一些大型3D手游都会遇到这个温度墙。降频后，随着硬件温度的下降，系统还会让芯片恢复正常的频率。我们的优化主要是推迟触碰到温度墙后的降频发生时间，以及让这个降频时间缩短 温度过高是导致系统降频的直接原因，导致温度升高的原因有： 抛开我们控制不了的部分，针对于手机发热问题，我们只能从CPU、GPU负载、显示、GPS、网络通讯与IO、屏幕亮度方面去优化了 常规负载优化 CPU负载 GPU负载 性能优化都可以理解为是CPU负载、GPU负载的优化 当游戏锁60帧时，CPU开销控制在 10-12ms GPU开销控制在 6-8ms 当游戏锁30帧时，CPU开销控制在 18-20ms GPU开销控制在 8-10ms几乎是不会遇到温度墙的 即使你的开销超过个推荐数值，也要尽量控制不让GPU的负载超出太多，CPU可以适当放宽，更高的开销带来的发热量一般GPU比CPU大 非常规优化 网络与IO 发包频率 需要通过端口和IP区分哪些是真正意义上的网络通讯开销 频繁IO读写 一些网络游戏本身通讯量不高，或根本就是单机游戏，但由于使用第三方的广告平台或信息收集平台的SDK后，也会开启一些网络线程，并进行非常频繁且大量的数据通讯，这块带来的发热问题也不容小觑，需要额外关注有没有一些设置来调整这些SDK 显示亮度与FPS 现在大多数高端手机都以拥有高亮度的手机屏幕为追求，其实在绝大多数手机游戏运行时，完全没有必要开启最高亮度，甚至为了减少屏幕发热，需要在开启游戏后，将屏幕亮度控制在一定范围内。在一段时间待机的情况下，甚至要大幅度调低手机屏幕亮度以节省电量、减少屏幕与电池的发热量 针对手机游戏显示帧率的问题，一定要按需控制帧率，有些没有必要锁60帧的游戏类型，完全可以采用锁30帧的方式 在全屏UI或模态对话框覆盖屏幕时，可以将原来30帧的显示帧率调整为一半，将60帧的显示帧率调整为原来的1&#x2F;4 甚至在待机状态，屏幕亮度调暗的情况下，可以调整到个位数的帧率，更激进一点的做法，可以同时调低显示分辨率。这一方式对于一些发热严重的手机及其有效 调整显示帧率不要通过Application.targetFrameRate来进行调整，而是通过Unity提供的OnDemandRendering接口的renderFrameInterval来调整，因为Application.targetFrameRate调整后会导致显示频率与输入频率一起下降，一些更新逻辑也会变慢，而OnDemandRendering接口只会调整显示频率，你的输入不会感觉到有任何延迟 三方库 Wwise 目前很多移动平台游戏都会选择Wwise作为音乐解决方案，这套库本身就很重，后台回开启多个长度线程进行解码与异步操作，并且该库在默认设置下并不会控制多音源混合个数，当混合个数较多时，开销呈指数增长，对CPU压力较大，建议将混合的音源个数控制在4个以内，基本上可以满足绝大多数的移动游戏了 CRIWARE 经常用到的处理视频的解决方案库 这是一个更恐怖的库，默认带CAk开头的线程都是它开启的，并且每个线程的开销都很高，而且一直很高，视频播放完负载也不会降低。一般情况下，同时只开启一个视频时，可能感受还好 总结 功耗和发热问题，不仅仅需要对游戏本身做常规优化，还要关注这些三方SDK，使用时，不要用无脑的默认设置进行集成，一定要看看有没有提供优化的设置或接口，否则这些三方库和SDK也会成为一个个耗电发热的小能手，最好分别做裸包与平台包的耗电量与发热测试 "},{"title":"性能优化(37)——渲染优化——Shader指令优化","date":"2022-11-19T04:15:43.000Z","url":"/2022/11/19/performanceOptimization-32/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; Shader数据类型精度 Float(32bit)：位置与纹理坐标信息 Half(16bit)：纹理坐标与颜色信息 Fixed(11bit)：颜色信息。只针对一些老旧的CPU设计所保留，只在BuildIn管线下适用，SRP下已不支持 尽量使用内置函数 pow normalize dot inversesqrt … 超越函数 一些变量之间关系不能用有限次加、减、乘、除、乘方、开方运算表示的函数，在数学上称为超越函数。这些函数在芯片指令上实现都属于资源密集型函数，在一些低端设备上要慎用、少用，带来的指令开销会比较高 exp log sin、cos、tan… asin、acos、atan、atan2… sincos … 指令周期与阶段 一条指令从取指、译码、执行、存储等一系列过程称为一个指令周期，可以理解为图中的cycle 但某些简单指令与复杂指令的cycle周期并不一定一样长 由于现代GPU Core内核是SIMP为架构的，长度一致的指令cycle更有利于单指令多线程的并行计算 因此，为了避免浪费，GPU设计时又将cycle中设计成了多个阶段，也就是多个Phase 如果一条简单指令在一个Phase内可以完成，那么在一个cycle内可以合并多条简单指令成一个稍微复杂的指令，如MAD指令以及现在常在XCode中抓取看到的，具有更高精度的FMA指令 指令优化 mul + add &#x3D;&gt; mad：mad指令就是一个乘法指令加上一个加法指令 (x - 0.5) * 1.5 ——&gt; x * 1.5 + (-0.75) 这样之前的一个减法指令和一个乘法指令会被优化成一个mad指令，指令周期也从两个cycle优化成一个cycle 除法 &#x3D;&gt; 乘以倒数(rcp) (t.x * t.y + t.z) &#x2F; t.x ——&gt; t.y + t.z * (1.0 &#x2F; t.x) 对齐 float3 * float * float * float3 ——&gt; (float * float) * (float3 * float3) abs或neg指令输出 &#x3D;&gt; 输入 abs(a.x * a.y) ——&gt; abs(a.x) * abs(a.y) -(a.x * a.y) ——&gt; -a.x * a.y saturate指令输入 &#x3D;&gt; 输出 1.0 - saturate(a) ——&gt; saturate(1.0 - a) min或max &#x3D;&gt; saturate(某些平台) max(x,0.0) &#x3D; min(x,1.0) ——&gt; saturate(x) sqrt(x) &#x3D;&gt; rcp(rsqrt(x)) :sqrt改成rsqrt的倒数 if0 &#x3D;&gt; sign(x)：用sign指令代替含零的判断分支语句 if&#x2F;else &#x3D;&gt; step(x) lerp(a,b,step(cx,cy))：用step + lerp代替非零的判断分支语句 sin&#x2F;cos&#x2F;sincos &lt;&lt; asin&#x2F;acos&#x2F;atan&#x2F;atan2&#x2F;degrees&#x2F;radians MUL &#x3D;&gt; MAD-MAD-MAD向量乘法指令优化成多个mad指令 mul(v,m) &#x3D;&gt; v.x * m[0] + v.y * m[1] + v.z * m[2] + v.w * m[3] mul(float4(v.xyz,1)) ——&gt; v.x * m[0] + v.y * m[1] + v.z * m[2] + m[3] v.x * m[0] + (v.y * m[1] + (v.z * m[2] + m[3])) normalize&#x2F;length&#x2F;distance都包含一个dot，可以共享 length(a - b)与distance(a,b)可共享，但与distance(b,a)不共享 normalize(vec) &#x3D;&gt; vec * rsqrt(dot(vec,vec)) 50 * normalize(vec) ——&gt; vec(50 * rsqrt(vec,vec)) 自表达式不共享指令 v &#x3D; normalize(v) return v mul &#x3D;&gt; mul24：在高版本的shader mode下，乘法指令也有专门用于向量前三个元素相乘的mul24指令进行优化 fma注重精度的mad texture.Load VS texure.Sample：texture.Load在(0,1)的寻址区间会比texure.Sample采样更高效。但Load(tc,offset)&gt;Sample(tc,offset) 其他 FS &#x3D;&gt; VS 避免隐式类型转换，如vector4隐式转成vector3 Varying数据尽可能组织成向量形式而非标量形式，这样可能会减少一些寄存器的miss catch，而将像素阶段的shader中的逻辑尽可能转到顶点阶段处理，也是均衡vs与ps阶段的gpu负载的一个好手段 以上shader指令的优化有个印象就好，不同平台或shader mode的版本差异，可能编译以后的汇编指令条数也有所不同，要看实际汇编条数是否真的减少了，才能确定我们的写法是否能达到优化的效果，这需要在特定的平台上经过长时间的经验积累才能做到如此指令级的优化 其他指令优化 针对于分支或循环语句优化的命令 如果分支判断的两个分支语句足够简单，我们可以将分支语句展开两个分支同时处理，并选择一个正确结果，我们可以用UNITY_FLATTEN标记分支语句是否展开，用UNITY_BRANCH标记是否真分支需要动态判断 一般来说我们可以按照分支语句是否超过六个指令来判断是否展开，如果两个分支语句中指令都小于六个，可以进行展开；如果分支语句大于六个，并且判断结果大多数都走一个分支，那我们可以用UNITY_BRANCH进行标记；如果两个分支走得比较平均，并且两个分支复杂度相同的情况下，在Unity2022下，我们可以充分利用dynamic branch声明shader关键字做运行时动态分支处理 循环语句不展开，可以用UNITY_LOOP标记为真循环，如果需要展开，可以用UNITY_UNROLL标记 明确需要展开到第几层时，可以用UNITY_UNROLL(_x)带层数参数来标记 Unity Shader中可能导致Early-z失效的操作 Shader中开启了Alpha Test 像素着色时调用了Clip()或Discard指令 Shader中开启了Alpha Coverage功能 在光栅化后修改了像素深度 手动关闭了Shader中的Depth Test标记 Early-z失效的像素过多，带来的后果就是处理像素过多，导致渲染性能下降，因此做一些功能取舍的时候，这个指标是一个关键的参考点 某些平台慎用或推荐用某些内置功能 Alpha Test Color Mask sRGB硬件解压 是否使用Alpha Blend代替Alpha Test，或关闭Color Mask功能，都需要在真机上测试才知道，因此移动平台上优化的最大工作量是要考虑多平台、多硬件、多API的兼容，而且是优化手段的兼容 大多数平台目前都支持sRGB格式的硬件解码，所以建议纹理资源导入设置时，勾选使用sRGB格式 "},{"title":"性能优化(36)——Shader与托管内存优化","date":"2022-11-18T04:25:12.000Z","url":"/2022/11/18/performanceOptimization-31/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; Shdaer的内存问题 引起Shader内存的主要原因是Shader的关键字过多，导致Shader的变体过多，打包时如果变体剔除做得不好的话，就会导致Shader的内存过高。因此做好Shader变体的剔除是控制Shader内存占用量的关键 变体剔除与变体收集 是为了让运行时Shader的内存占用更少，剔除掉不会被使用的Shader变体 变体收集是为了做Shader的WarmUp，目的是为了避免运行时Shader加载编译导致的性能问题 变体收集可以用来辅助变体剔除工作，可以作为不被剔除的Shader的参考 对于Shader变体非常多的情况下，做到变体完全剔除干净或变体完全收集完整是个很难做到的工作。这种情况下，我们只需要保证变体剔除尽量干净、收集尽量完整即可。中间一部分冗余占用的内存在可接受范围内时是可以被忽略的 查看具体Shader会产生多少个Shader变体 一般我们是通过Shader的Inspector面板来查看的 但由于平台不同，不同的平台或图形API需要切换到对应平台或API上才能统计正确。而且每个Shader都要做统计，一些Unity内置的Shader也难以统计。这样就有些麻烦了 这时我们可以通过打包后的Editor.log来查看Shader变体个数与Shader变体剔除的统计结果 在文件中搜索Compiling shader字段，这时会列出每个Shader的变体个数和实际打包到包里的变体个数 具体Shader在实际平台占用的内存还需要在移动设备上运行时通过Memory Profiler进行抓取查看 托管内存优化 具体会与用户脚本、开发者编码习惯直接相关 C#语言层面： Boxing Allocation装箱操作：值类型转换到引用类型的转换，会造成额外的内存开销。使用Lua等脚本语言做热更新逻辑的开发者，在封装交互接口时，尽量不要传递Unity引擎里定义的对象，尽量保证调用的函数接口传递或返回基础类型值对象 String字符串拼接：做字符串拼接应尽量使用StringBuilder进行 闭包分配：一般是指代码段中使用了代码段之外定义的变量，如匿名函数或Lambda表达式，当调用这一类代码段时，托管堆中会生成一个类来保存这些代码段中引用到的外部变量，会有额外的内存开销 避免使用Linq库写任何游戏内的代码：它们会生成大量托管堆上的垃圾内存 Unity相关代码调用 Unity中提供了很多NonAlloc函数（无托管内存开销的函数），与之对应的是有托管内存开销的函数 如：Physics.RayCastAll对应的无托管内存开销的函数是Physics.RayCastAllNonAlloc Unity下一些返回对象列表的函数都是有托管内存开销的。如： Unity.Object.FindObjectsOfType UnityEngine.Component.GetComponentsInParent UnityEngine.Component.GetComponentsInChild等 一些Unity类成员变量访问的方式：如直接通过”.”调用的成员变量，应尽量采用”.Get”的方式去调用。如： UnityEngine.Mesh.vertices &#x3D;&gt; UnityEngine.Mesh.GetVertices, UnityEngine.Mesh.uv &#x3D;&gt; UnityEngine.Mesh.GetUV, UnityEngine.Renderer.sharedMaterials &#x3D;&gt; UnityEngine.Renderer.GetSharedMaterials, Unity.Input.touches &#x3D;&gt; Unity.Input.GetTouches等 无论是C#还是Unity相关的代码调用，如果发生在循环或者每帧更新的函数里，造成的托管内存开销会更大 我们尽量还需要注意，不要在循环或每帧更新的逻辑中反复去Instance对象，应尽量在初始化时利用内存池预先分配好，避免在运行过程中的GC开销 当你发现你的游戏每帧GC开销变化过大时，可以开启BuildSetting-Player中的增量GC选项，它可以将一帧中的GCCollect调用分摊到多帧进行，可以有效地平滑你的游戏帧率 BuildSetting中的关于程序集优化的配置：在Optimization标签下，默认会勾选Strip Engine Code选项，开启这个选项后，如果backend是IL2CPP的情况下，Unity会删除项目不使用的Unity引擎的代码，强烈建议开启，不仅会对包体大小有优化，对应用程序内存的占用也可以减小 这个选项下面的Managed Stripping Level，可以根据包体和内存的需求进行配置，它会根据不同的选项自动删除托管dll中的不使用的代码，同样也可以减小包体的同时减少内存的占用，不过当设置的级别过高时会导致误删某些C#接口导致编译出错，这时你可以为误删除的接口打上Preserve的属性标签以防止这个接口被删除。也可以使用linker.xml文件进行更详细的配置，不过这个选项只针对需要极限优化的项目，如果嫌配置麻烦，默认选项就好 "},{"title":"Java笔记(1)","date":"2022-11-16T14:14:15.000Z","url":"/2022/11/16/JavaStudy-1/","tags":[["Java","/tags/Java/"]],"categories":[["undefined",""]],"content":"&nbsp; 常用转义字符 \\t ：一个制表位，实现对齐的功能 \\n ：换行符 \\ ：一个\\ \\“ ：一个” \\‘ ：一个’ \\r ：一个回车 注释 单行注释 多行注释 文档注释(类、方法) javadoc解析 javadoc标签：author、version、link等 "},{"title":"性能优化(35)——项目设置与内存优化","date":"2022-10-29T04:49:14.000Z","url":"/2022/10/29/performanceOptimization-30/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; Texture2D纹理资源类型进一步优化 当场景中所有使用的纹理都开启了MipMap模式，这样我们可以通过Quality Setting中的Texture Quality选项来强制使用某一级别的MipMap Level Texture进行渲染，这样实际被加载到显存中的纹理，只有这一级Mipmap及其以下级别的纹理，占用的显存也会相对更少 目前Unity只提供第0、1、2、3级的Mipmap设置，实际对应原尺寸、1&#x2F;2、大小、1&#x2F;4大小、1&#x2F;8大小的纹理 但这种方式需要在纹理加载前确定设置，因此每次修改想要设置生效，只有重启游戏才能生效 比较适合高中低端机型比较明确的情况 我们还可以利用Unity提供的Mipmap Streaming功能来做运行时动态调整 除需要对应纹理开启Mipmap导入设置的同时，还需要将纹理导入设置的Streaming Mipmap功能选项打开，同时开启Quality Settings中的Texture Streaming功能选项 该功能会强制Unity仅加载渲染当前相机所需级别的Mipmap层级，使用少量CPU资源来节省大量GPU上的内存 和Texture Quality功能类似，但这个功能是运行时进行的， Unity提供了该功能一系列API，让你可以为应用程序的纹理设置总内存限制，这样Unity会自动降低纹理的Mip级别，来保证纹理内存开销在预算范围内 不过这个功能需要开发者非常了解其实现原理，如果只是傻瓜式开启，往往达不到优化效果，甚至设置不合理会导致画面损失较大，甚至负优化的产生 Mipmap Streaming的参数设置 Memory Budget：为加载纹理的总内存预算，如果大于该预算时，后续加载的纹理会采用更低级别的Mip Level。这里如果内存预算设置的太高，则起不到太多内存节省优化的作用，甚至可能造成浪费；如果设置过低，画面损失可能会比较大 Renderers Per Frame：为每帧CPU为Mipmap Streaming功能要处理多少个网格渲染器，虽然降低该值会减少CPU处理开销，但可能会增加加载Mipmap的延迟开销，因此需要测试平衡该值的设置 Max Level Reduction：代表当纹理内存达到内存预算上限时，最大可以跳过加载的Mipmap级别数，同样，设置低了会造成Mipmap加载延迟开销，设置高了会造成画面损失较大 Max IO Requests：是用于加载Mipmap Streaming流的最大IO请求数，如果设置得足够高，可以防止异步纹理上传阻塞。但某些系统会本身设有IO请求上限；同时设置太大，本身也会有系统的开销 另外，关于相机的Mipmap Streaming设置，可以通过Streaming Controller脚本为每个相机设置不同的Mipmap级别的偏移 通过给每一个纹理导入设置Mipmap Streaming优先级别，可以强制在预算内存范围内优先加载哪些纹理，以弥补整体设置激进的情况下造成的视觉损失 总之，Mipmap Streaming功能几乎所有参数设置是一套多元多次多项式，随着项目规模、场景复杂度、摄像机角度变化、Mipmap纹理个数等等因素的不同，很难找到一个最优化的设置 最让人难受的是，在SRP下，没有像Build-In管线下的Mipmap调试模式，这样就更难找到符合你的项目的一套最优化参数 如果在SRP下使用该功能，建议为这个功能开发一套调试UI，将所有参数变量暴露到UI上，并可动态调整，然后去为你的项目每一个场景做测试调整，在视觉可接受的前提下找到一套正优化的参数，不要期望找到最优解，可以根据你具体优化的目的找到一套相对优化解就可以了 "},{"title":"性能优化(34)——内存优化(3)——内存指标术语与进程内存介绍","date":"2022-10-29T03:55:03.000Z","url":"/2022/10/29/performanceOptimization-29/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 几乎在所有操作系统上，虚拟内存与物理内存都是以Page来组织的 Page是操作系统管理内存的最小基础单元，通常为4k大小，但在不同的操作系统和平台上可能有不同，比如在比较新的IOS或Mac操作系统上是16k大小 一般，电脑中的CPU会有一个内存管理单元，MMU，它会维护一张Page的表，并将虚拟地址映射到物理内存地址上。当用户访问虚拟地址时，会自动被MMU转换为物理地址。但当CPU访问虚拟地址并没有找到映射的物理内存地址时，CPU会触发Page fault中断当前程序执行，然后再分配一块干净的物理内存，并从磁盘中加载所需的一页数据到该物理地址，同时更新列表并继续执行程序 当一个进程向系统申请内存时，系统并不会返回物理内存地址，而是返回一个虚拟内存地址，仅当CPU需要访问该虚拟内存地址时，系统才会分配并映射到物理内存上 每个Page可能有不同的状态，用来描述该内存页处理的不同事务状态 Used代表Page正在被进程使用，而内存页也已经被映射到了物理内存中 Free代表该Page页可用，并且该内存页还没有被映射到物理内存中 Cache状态代表该页被操作系统用于缓存的可用内存，虽然内存页已经被映射到物理内存中，但该页可能近期没有被访问 如果Free Page数量低于一个阈值时，操作系统会从Cache的页中去获取内存，并将Cache页上的数据交换到磁盘，然后对Cache的页进行清理，并将其标记为Free Page 在内存管理的更高级别上，操作系统的虚拟内存还会将Page组织成区域。可能在不同的操作系统中使用不同的名称来定义这个概念，这里统称为Region，它是一块共享内存状态和保护级别的连续地址空间。它可以由具有不同的页面状态的多个Page组成 当然Region也有不同的状态： Resident：代表其中的配置页已经在物理内存中 Dirty：代表配置已修改，但未写入磁盘 Wired：代表永远不会交换到辅助存储的固定配置段 Committed：代表已分配的内存区域，其地址不能被其他分配使用，是由RAM磁盘上的分页文件或其他资源来支持的，访问权限由内存的保护级别控制 Reserved：该状态的Region保留地址空间，供将来使用，地址不会被其他分配使用，也不可访问，如果尝试从Reserved的内存读写，都会导致访问冲突异常，并且它没有与之关联的物理存储支持 Free：是空闲内存区，既不会Committed，也不会Reserved，并且进程无法访问，同样任何尝试读写Free状态的Region也会导致访问冲突异常 Region的类型： Anonymous：是匿名的，这类Region上的内存页，与文件系统上的文件并没有关联。例如，C++使用malloc的任何分配，或mono上的分配都是匿名的 Mapped：映射类型，这类Region包含的内存页，是以文件系统设备节点关联的，文件与内存将做直接映射 一个进程的内存结构 Committed Memory 是一个进程分配虚拟内存的总量 从纵向看，包括物理内存、Mapped Files、Swapped Files、Compressed Memory四部分 从横向看，包括当前进程私有占用的内存，和与其他进程共享的内存 Resident Memory 已经被映射到虚拟内存中的物理内存 同样包括当前进程占用的内存，和与其他进程共享的内存 其中存在一些非代码执行的开销，如系统或应用的二进制加载所占用的内存 进程的内存结构（进一步细分） 可分为： VSS：即总共Commit提交的Regions内存总和 RSS：进程可访问的Resident常驻内存总和 PSS：当前内存常驻内存与其他进程共享的Resident内存总和 USS：为当前进程私有的Resident内存总和 Unity下提供的Memory Profiler工具，总体内存是对Commited Memory即VSS进行衡量的，而并不涉及是否为Resident Memory Windows平台下，Windows任务管理器中的Memory指标是针对于USS来衡量的 Mac与IOS下，XCode显示的内存衡量的是RSS加上压缩后的内存交换页的大小 如果大于此经验值，也不一定完全不行。游戏类型不同，各类资源占用也会有所差异 另外，System.XXX总和这一项的内存开销基本来自于用户的配置数据表，与C#层的基础类型变量的定义。一些开发者习惯把所有配置数据全部缓存进来，会导致此项内存开销过高，尤其是一些纯文本数据，如果真的需要，也建议采用二进制方式分级缓存读取 还有其他各类对象单选这条，是指一些C#层的对象，主要会是一些Component与GameObject派生出来的对象，我们不仅需要关注这些对象所占用的内存大小，还需要关注对象个数 "},{"title":"性能优化(33)——内存优化(2)——NATIVE内存分配器详解","date":"2022-10-09T01:56:57.000Z","url":"/2022/10/09/performanceOptimization-28/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 我们都知道，Unity底层是C++实现的，游戏引擎都不会直接通过malloc与new直接分配内存，至少都要在其上封装一层来做内存管理、统计与检查等工作 Unity引擎中，C++层会根据内存用途不同，抽象成不同的allocator进行内存分配，通过不同的Memory Lable标签与OwnerShape的设置进行标记与追踪，通过MemoryManager进行整体的管理 这几块都在Unity源码中，购买过源码的可以在源码中看，没有购买过的，只有Allocator可以在Unity2021以上版本中的ProjectSetting-Memory Setting中窥得一些端倪 Unity Native层会根据分配算法的不同以及用途的不同定义非常多类型的内存分配器。今天，我们只需要关注MemorySetting中，我们可以自定义并且比较典型的几类 分配器Allocator的分类 Main Allocators：绝大多数内存分配使用的分配器，包括主线程、渲染资源相关、文件cache、typetree等不同用途下的分配器 Fast Per Thread Temporary Allocators：线程上使用的临时分配器，包括各工作线程的栈分配器，比如音乐、渲染、预加载、烘焙等工作线程上的分配器 Fast Thread Shared Temporary Allocators：线程间共享的临时分配器 这四种大的分类与其中的小类，都是用途抽象意义上的分配器，在Unity引擎代码中并没有一一对应的分配器的类，而在Unity代码中则是根据分配算法分类的分配器 包括Unity默认分配器、桶分配器、动态堆分配器、双线程分配器、线程本地存储分配器、栈分配器、线程安全线性分配器以及用于各个平台特性的分配器与调试分配器太多太多 它们与按用途分配的分配器是一对多的关系。也就是按用途分类的分配器底层都是以按算法分类的分配器实现的 它们只是底层分配器抽象的一层皮，而MemorySetting自定义设置中既是把这层皮暴露到编辑器中了。我们需要了解它们具体对应关系才能真正了解如何下手去自定义内存分配器 以下图表大致描述了底层按算法分类的几大类分配器，与按用途划分的分配器的关系 主要的底层分配器桶分配器 在Unity Player下，默认的粒度大小为16个字节，用于分配16、32、48、64等等字节的内存 该分配器默认分配保留1个内存块Block，每个块会被划分为16kb的子段，并且这个大小不可配置。如果需要调整Block块，则Block块只能增长，并且需要是固定16kb大小的整数倍 这个分配器的粒度大小与Bucket的个数是需要根据游戏内情况来配置的，默认粒度是16个字节，默认的Bucket是8个，这样在Release版Player下，1个16kb子段下最多可以容纳1024个Bucket；而如果将Bucket的粒度调整为64个字节，则1个子段只能容下256个了 动态堆分配器 TLSF算法：你可以理解为——它是两层链表管理的内存块，第一层以2的幂次方划分，当第一层的内存块分配有剩余时，引入第二层链表，将第一层中使用的内存块剩余部分用更精细的粒度进行划分。在保证分配效率的同时提高内存利用率 双线程分配器 两个线程上使用的分配器TLS Stack Allocator 如果发生溢出回退情况，则会回退到Thread Safe Linear Allocator Thread Safe Linear Allocator 如果发生了溢出，需要判断该溢出是否发生在资源加载期，还是正常的帧渲染期 如果加载期溢出，帧渲染期平稳，我们可以不用理会；如果正常的帧渲染期溢出数量增加，我们需要调高该Allocator的Block Size大小 不过如果你有足够的内存预算，无论是在加载期还是在正常帧渲染期发生溢出的情况下你都可以调高 Unity2021版本上已经有文档可以学习了 2021以下版本想要自定义内存分配器，只能通过修改源码的方式进行了 "},{"title":"性能优化(32)——内存优化(1)——Unity中的内存概述与工具方法","date":"2022-09-30T02:04:43.000Z","url":"/2022/09/30/performanceOptimization-27/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; Unity引擎中的内存 托管内存：包括托管堆内存、脚本堆栈内存与虚拟机内存三部分。其中托管堆内存是优化的主要部分。托管内存使用方便，但释放与内存分配方式不可预期。另外，Unity使用的是保守的贝姆垃圾回收器(Boehm–Demers–Weiser garbage collector)，在内存的管理与分配上并不会太激进，因此一些使用不当会造成内存的浪费，也可能会有性能的问题 C#非托管内存：是指在C#层不使用垃圾回收器管理的内存部分，它允许访问Native内存层，可以进行内存分配的微调，一般在C#下使用Unity Collection名字空间与包结合使用，也是将来使用DOTS程序加速准备的数据结构访问的内存.所以如果你的项目刚立项，如果使用数据结构，不建议使用System下Collection的数据结构，而推荐使用Unity Collection下的数据结构进行开发 除红色Unity中的内存之外，Unity的应用程序还包括青色部分渲染资源占用的显存，如果是移动平台，该显存是与内存共享的；还包括蓝色部分应用程序框架所需要的内存、一些第三方库占用的内存以及操作系统为应用分配的内存。蓝色部分是不能通过Unity引擎提供的工具获取的，不过我们可以借助一些操作系统工具、编译工具或第三方工具进行抓取 Unity引擎提供的内存方面的工具Unity提供的 Unity Profiler Unity Profiler下的Memory标签，这里列举了Unity当下内存使用的追踪状态，包括各类内存的分配与使用情况，以及当前Unity下分配的对象与资源占用的内存情况 注意：Unity2021以后的版本，Profiler不再提供对象抓取快照功能了，而是使用Memory Profiler直接抓取内存快照了 此外，Profiler的Menory标签下默认提供的指标并不全，如果希望得到更详细的信息，可以通过添加自定义Profiler Modules加入更多的Memory Counter指标，也可以扩展Profiler Modules，通过对应的系统接口，提供更详细的内存指标加载到Profiler中 Unity Memory Profiler 可以通过它抓取内存快照，也可以对比两个内存快照下，Unity对象与资源的差异 通过Tree Map查看内存分配的视图 通过Object and Allocations标签查看具体对象内存快照，并可以通过链接直接找到原工程中对应的资源或对象 通过Fragmentation标签，可以查看内存片段。Unity2022以后，Memory Profiler变得更加简洁易用了，针对Native内存，甚至可以查看到具体是分配到哪个Allocate中的 内存相关设置 自Unity2021后，Unity开放了针对于Native层的内存分配自定义设置功能，用户可以针对自己项目的特定，自定义相关内存的Allocate分配块大小.大家现在可以在权衡时间与空间维度上的性能指标做更精准的设置了 此外，与内存相关的设置还有一些在工程设置中和图像设置中 UPR中的内存快照与对象快照功能 主要是针对于移动设备，当你使用UPR做性能调试时会经常用到 它可以脱离Unity编辑器，在运行时抓取内存信息与对象分配信息，并可以做到多帧对比比较 具体使用方法都是通过快捷键完成的，可以参阅UPR手册 Unity外的工具 Mac或IOS上可以选择XCode提供的Instruments下的Allocations工具 安卓上可以使用安卓相关的系统命令，或安卓Studio的Profiler工具，或者一些第三方工具，但一般不太好用 一般我们还是先在IOS上进行内存优化 Allocations工具： 使用profiling运行XCode工程，当编译完成后，在profiling模板界面选择Allocations工具，并启动录制，也可以直接启用Instruments工具 直接选择Allocations工具，并挂载手机上要测试的项目的进程，你也可以长按录制功能键修改录制选项，一般情况下需要在启动前选择下VM Tracker标签，选择完成后，XCode下会出现一个Snapshots按钮，在其中勾选Automatic Snapshotting选项，只有勾选了这个选项，才能看到VM Tracker下的信息 点击录制按钮拉起我们的应用程序，这时会看到Allocations与VM Tracker中会有曲线变化，这代表我们正在录制中 我们可以多测试下游戏中各个场景间的切换，观察曲线变化 完成后可以选择停止选项，这时录制信息并不会丢失，但其信息内容会非常多，这里只挑我们最需要关注的指标进行说明： VM Tracker下的Dirty Size、Swapped Size、Resident Size Resident Size代表使用的物理内存量 Swapped Size代表不活跃的内存，可以被交换到磁盘上的大小。可以理解为可卸载的大小。在IOS中，只有非Dirty的内存页才可以被交换或卸载 Dirty Size代表物理内存中不能被复用或者被卸载的内存块。这个数值非常重要，一旦超过一定大小，IOS程序就会自动退出，这个大小在1G内存的手机上大概是700MB，2G内存的手机上大概是1.4G，这个数值直接关乎我们的应用程序在长期运行时会不会崩溃，所以需要关注它的峰值是否超过警戒线，并且有没有下降的过程 接下来我们可以将Statistics标签切换成Call Trees，并在下面CallTree按钮中选择按线程分类，这样会方便我们查看具体那些线程做了哪些分配情况。如果发现线程堆栈是16进制地址，这可能是苹果系统或XCode版本造成的，只需要点击Date Mining中的Restore即可恢复 完成这些后，我们可以看到渲染线程、主线程、Unity的加载线程的内存排在前三，可以在时间轴框选我们需要采样、查看内存分配情况的时间段来进一步看这个时间段各个线程的分配情况 "},{"title":"性能优化(31)——级联阴影优化","date":"2022-09-28T02:15:34.000Z","url":"/2022/09/28/performanceOptimization-26/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 记得关闭地形投影 既然我们做场景LOD时，远处的模型被替换成低模，动画看上去也不会动了，那么阴影贴图渲染其实每帧变化并不大，也会随着级联阴影层级的提高变化越来越小 那么我们有没有办法在远距离的级联阴影级别下，可以不用对每个物体阴影做重新绘制呢 我们应该可以想象的，如果将阴影贴图进行cache缓存，并对级联阴影的每个级别的阴影贴图块，按不同的刷新率去更新，这样就可以降低每帧投影体绘制的次数了。也就是将LOD思想应用到了级联阴影上 首先想到的还是从URP源码入手 在URP下，主光源投影是通过MainLightShadowCasterPass.cs完成的，我们只需将其拷贝一份出来，并重新命名为MainLightShadowCasterCachedPass.cs，并将对应的Pass类名修改为MainLightShadowCasterCachedPass，同时修改UniversalRenderer.cs文件，将创建MainLightShadowCasterPass的地方替换成为MainLightShadowCasterPass对象 接下来看对MainLightShadowCasterPass做哪些修改 首先，我们既然要缓存生成的Shadowmap，那么我们的级联阴影的Texture创建就不能每帧创建了。我们需要移除OnCameraCleanup函数下的MainLightShadowmapTexture的释放逻辑，同时添加一个Cleanup接口，将其释放逻辑放到UniversalRenderer下的MainLightShadowCasterPass的释放逻辑 这样就变相延长了MainLightShadowmapTexture的资源生命周期 同时修改Setup函数下的MainLightShadowmapTexture创建逻辑，只有这个对象为空，或者Shadowmap大小发生改变时，才重新创建 同时添加一个判断是否为第一帧的bool变量，方便后面只处理创建后第一帧逻辑使用 然后需要添加一个针对于Shadowmap的更新数组 这里的1，2，4，8分别对应级联阴影的第1，2，3，4四个级别 这个数组有几个元素就代表了做几帧的更新循环 如：这里创建了第一帧更新是第一个级别与第三个级别的级联阴影块；第二帧更新是第一个级别与第四个级别的阴影块；第三帧更新的是第二个级别与第四个级别的阴影块。相当于每3帧更新2次第一个级别的级联阴影块，更新1次第二个级别的级联阴影块。这样就变相的相当于第一个级别的渲染频率降低到用来的2&#x2F;3，而第二个级别的渲染降低到原来的1&#x2F;3 同时需要定义一个int变量，用来记录当前总共进行了多少帧，方便取模后，按3帧一个循环来更新阴影贴图 我们还需要移除Configure中的ConfigureClear逻辑，这样就不需要每帧clear整体的Shadowmap了。若远处的级联阴影在远距离级别上会出现闪烁，就是没有移除该逻辑的后果 这些都准备好后，就可以修改阴影的渲染逻辑了 将RendererMainLightCascadeShadowmap中的每帧渲染逻辑替换为按更新数组3帧一循环的渲染逻辑，同时将ShadowUtils、RenderShadowSlice替换成我们自己写的RenderShadowSlice逻辑，主要是控制Shadowmap中不同级别阴影块的单独绘制，而不是更新整个Shadowmap了 同时你也可以修改SetupMainLightShadowReceiverConstants中的级联阴影各个级别矩阵的更新频率，降低一点CPU开销。不过不修改也没有关系，差异并不大 到此，按级联阴影的级别，通过更新频率控制每个阴影块渲染的优化的代码修改基本上完成了 但到我们捎入到手机上运行会出现崩溃，主要会发生在Matal的SetScissorRect函数里，其原因是MainLightShadowCasterCache的Path默认设置了NativevRenderPass导致生成的Shadowmap的临时RenderTarget的LoadAction与StoreAction都是DontCare，不做存储与加载操作。但由于我们的优化是跨帧修改了Shadowmap，因此需要Load与Store操作。这里最简单的修改方式就是将MainLightShadowCasterCache的Path不使用NativeRenderPass，将useNativeRenderPass变量设置为false "},{"title":"性能优化(30)——Terrain地形优化","date":"2022-09-27T02:02:45.000Z","url":"/2022/09/27/performanceOptimization-25/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&emsp; Unity的地形工具在移动端的效率不高，尤其是Terrain Shader不够轻量 一般都是用地形Mesh替代它，最好的方式是自己写一套地形烘焙的工具，根据Terrain Date将Mesh信息与混合后的地形纹理烘焙出来，并通过Prefab生成地形块 如资源商店Terrain To Mesh 2021，但它还有一些缺点： 它烘焙使用的Sprite Shader并不支持SRP Batcher，主要是太多的材质属性没有定义到const buffer中；而且由于Shader使用大量关键字来定义材质属性，导致改起来很麻烦 它的地形分块并不能对应多张地表diffuse map，这会导致如果原地形较大的情况下，一张diffuse map即使再大的分辨率，清晰度也是不够的，所以还是要用Sprite Shader来做，这就导致地表Mesh的Shader还是不够简单，纹理采样开销并不比Unity Terrain方式轻多少 "},{"title":"性能优化(27、28、29)——渲染管线精简与优化","date":"2022-09-25T06:24:15.000Z","url":"/2022/09/25/performanceOptimization-24/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; Shader方面 在URP延时管线下，所有Unlit类型的对象都会被强制使用前向渲染管线渲染，所以这些对象不会有Gbuffer阶段，如果后续还需要使用Normal与Depth信息，只能通过Prepass的方式获取了 ASE生成的shader的指令集精度过高，导致渲染性能下降。我们可以利用half去替代一些float变量以提高渲染效率，这里有个原则： 如果变量是表示位置与空间信息的，不要用half去替换 如果变量是表示颜色与UV信息的，可以用half去替换 ASE生成的Shader无法符合Native RenderPass下的正确渲染表现 ASE生成的Shader并不匹配impostors插件的某些规则 URP中的Settings 强烈建议使用URP做项目的时候不要在URP Render Pipeline Asset中开启这两个Pass： 如果真的需要这两个Pass，可以选择在对应需要的Camera相机上对起进行复写设置。这样做的好处是，可以将两个Pass的生命周期与特定需要这些效果的相机进行绑定，并可以通过脚本在运行时控制其开启与关闭，这样在某些不需要的场景或相机上可以剔除掉这两个Pass，以节省GPG负载开销 "},{"title":"性能优化(26)——遮挡剔除与灯光剔除","date":"2022-09-25T05:55:36.000Z","url":"/2022/09/25/performanceOptimization-23/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"（不全） 地形较平坦时，地形对象上的投影体属性可以关闭.更多的是接受其他物体在地形上的投影，而不是自投影 对多实时投影的点光源的剔除优化： SRP下的Light Layers功能来做光影剔除 通过脚本逻辑控制光影剔除 通过脚本判断灯光与摄像机的距离来控制灯光组件的开启&#x2F;关闭 同时控制同一室内场景中只有一盏点光源做室内区域投影的主光源 会有一定的CPU开销，当CPU是性能瓶颈的时候，这种方法就不太适合了 项目设置中Quality标签下对渲染管线设置 主光源依旧采用4096阴影贴图大小，以保证室外的阴影质量 对于室外的额外灯光，可调整每个对象最多能接受几盏灯光的影响(Per Object Limit) 额外光源投影的Shadow Atlas Resolution可调小到2048，因为室内距离较小，稍微调低了阴影贴图的Atlas与Shadow Resolution Tiers并不影响太大的视觉表现 由于所有开启额外灯光投影都会被打到同一个Shadow Atlas中，合适的Shadow Atlas Resolution与Shadow Resolution Tiers的设置才能保障视觉表现与是否所有额外灯光投影都能在同一张Shadow Atlas中容得下，如果容不下会出现以下警告提示 这种情况下一定会有额外光源的投影没有被显示，可能造成视觉上的错误。这时我们就要重新调整Atlas与Tiers的尺寸以进行修正 "},{"title":"性能优化(25)——中景简化与LOD策略","date":"2022-09-22T06:22:45.000Z","url":"/2022/09/22/performanceOptimization-22/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 传统的远景、中景、近景的概念 是指视距上的划分 远景：视距较远。主要用于表现一些开阔景物，为了渲染总体气氛和空间感，配合景深的表现可以让画面层次感更丰富，增加整体的意境。因此远景渲染我们不需要做具体的细节表现 中景：是指画面视觉中心的部分。一般用于进一步烘托整体场景气氛，需要一定的视觉和细节表现，但不需要过分强调，更多的是通过材质的颜色、质地、大范围的光影明暗来呈现 近景：是视距最近的画面部分。一般突出表现在具体某个物体或角色上，需要突出表现材质的细节，比如凹凸、光影细节、反射、折射、透视等高级效果，并且通过近景占屏幕比例多少，来与中景、远景形成更好的透视感 随着摄像机的移动，可能定义会出现一些重叠，近景的定义会更宽泛 如果对于需要在远景、中景、近景都需要出现的物体，可以将其LOD分为4级 0 —— 近景 1 —— 中景 2 —— 远景 3 —— 剔除 只需要出现在近景和中景中的物体，可以设置LOD为3级，2级为剔除 只需要在近景出现的物体，可以设置为2级，0级为近景，1级为简化模型或剔除 一般情况下，LOD级别设置最好不要超过5级 5级情况下 0 —— 原始模型 1 —— 1级简化模型 2 —— 2级简化模型 3 —— 替代体 4 —— 剔除 如果不需要使用替代体技术的话，我们可以选择不超过4级的LOD设置 减小阴影绘制阶段的压力：对场景中一些不必要的LOD级别上的模型不显示投影，只在LOD0级别原始模型下显示投影，其他LOD层级下的模型不显示投影 还有一些静态光照下的对象，已经在阴影体内了，也不需要渲染投影，毕竟还可以通过SSAO来显示接触面的暗部 替代体方案 首先，替代体方案不是没有开销的 虽然替代体方案比较适合第一视角，并且摄像机变化较慢的场景类型 但是选择目前Unity商店中任何一个插件实现，都必须要做一些资源和Shader上的调整，并且会带来一些未来插件更新的风险 因此该方案先搁置 毕竟优化是一个迭代的过程，先把一些风险小、开发工作不高，但收益大的优化方案优先来做。如果将常规手段用完后，性能还不能达到要求的，再上替代体方案 LOD Bias 这个参数主要是为了多平台LOD设置分级而使用的 值正好是1时，为工程内真实的设置 例： LOD0：100% —— 60% LOD1：60% —— 10% Culled：10% 当LOD Bias为0.7时， LOD0：100% —— 42% LOD1：42% —— 7% Culled：7% 当LOD Bias为2时， LOD0：100% —— 100% LOD1：100% —— 20% Culled：20% 也就是向更多的细节进行适配 "},{"title":"性能优化(24)——远景简化","date":"2022-09-17T03:09:09.000Z","url":"/2022/09/17/performanceOptimization-21/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"远景简化 一般情况下，我们通过传送就能走到的远景，一般都会选用模型；而不能走到的远景，一般都是使用天空盒完成的 做法 只需将场景中除远景外的对象先隐藏 然后在场景中添加一个反射探针烘焙Cubemap即可 注意要选择反射探针的类型为Baked，当然Custom也可以，选择后需要开启Static选项中的Reflection Probe Static选项 之后取消Windows-Rendering-Lighting下面的Auto Generate的复选框 这时会发现添加的反射探针Inspector面板中会出现Bake按钮 接下来要根据实际远景裁剪距离设置裁剪平面 同时可以提高渲染分辨率，这个大小与实际模型表现的质量最为接近 如果不需要HDR的Cube Map还可以取消HDR选项，这样烘焙出的非HDR的PNG格式Cubemap会更小 之后点击烘焙按钮，会烘焙出对应的Cubemap 接下来，创建天空盒材质 首先创建一个新材质(Material)，选择它的Shader为Skybox&#x2F;Cubemapm，并在贴图中指定刚刚生成的Cubemap 之后我们需要替换Windows-Rendering-Lighting中的Environment标签下的天空盒材质为我们刚才创建的材质 这样就将远景模型替换成天空盒的简化做好了 我们可以调整天空盒材质的曝光系数开控制远景天空盒的明暗，来模拟天空的变化；也可以通过旋转系数控制远景贴图的旋转显示角度 另外：Unity下生成Cubemap并不是只有反射探针这一种方式，还有两种常用方式： 通过Assets-Create-Legacy-Cubemap来创建Cubemap资源。 这种格式未来Unity可能不太支持了 还有一种是利用Camera.RenderToCubemap接口来进行创建 可通过官方文档学习 官方文档给出了三种案例的代码，如果你需要通过脚本创建，或者在运行时创建，设置是创建stereo Cubemap都可以 "},{"title":"性能优化(23)——Unity中的Batching(下)","date":"2022-09-12T08:44:58.000Z","url":"/2022/09/12/performanceOptimization-20/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; Batching的使用限制Static Batching限制（较少） 额外内存开销 64000个顶点限制：Unity下，一旦静态合批后的对象网格顶点数超过64000个，就会自动开启下一个静态合批 可能影响Culling剔除的结果 Dynamic Batching限制 合批后的对象不能超过900个顶点属性 顶点属性，而不是900个顶点。如：你的基础顶点有位置、颜色、法线、UV坐标四个属性时，那么最大的顶点数就不超过900&#x2F;4&#x3D;225个顶点 除了渲染阴影对象外，相同材质，不同材质实例也不能合并 就是说，即使你复制了两个一模一样的材质赋给两个对象，即使材质属性内容一模一样，也不能进行动态合批 具有光照贴图的游戏对象如果有附加渲染器参数时，如果需要动态合批这些对象，它们必须指向相同的光照贴图位置 也就是要有相同的光照贴图UV才能进行动态合批 这个要求非常苛刻，所以大部分具有光照贴图的游戏对象很难做到动态合批 着色器具有多Pass的材质对象无法动态合批 受多个光照影响的游戏对象，即使满足动态合批条件合批后，也只会受到一个光源影响 延迟渲染下不支持动态合批 CPU开销可能会增大，需要测试开启使用 GPU Instancing限制 需要图形API版本与Shader版本的支持 移动设备上需要OpenGL es3.0以上版本的支持 GPU Instancing与SRPBatcher不兼容 不同绘制API的参数与绘制个数不同 渲染顶点数较少的网格时，效率可能会较差（测试使用） SRP Batching限制 需要图形API对Const Buffer的支持 必须是SRP渲染管线 Shader必须是compatible时才能生效 粒子对象不能做SRP Batching合批 使用MaterialPropertyBlocks的游戏对象不能合批 合批失败的原因汇总（Unity2022版本上最全最新） 这些原因一般都会显示在Frame Debug中抓取的管线信息，如下图所示的位置 补充： 1.由于要走多个灯光Pass所以不能合批 2.即使材质的属性数值完全相同也不行 3.这里的不能合批是指在Shadow Pass中的合批 2.对象不能进行GPU Instancing合批 4.这种情况主要是由于静态批次合并的网格顶点数达到64000时，即使两个对象一样，距离也临近，但还是会拆到两个批次中去 2.这种情况一般发生在粒子对象定义了Additional Vertex Stream时 5.因为这种情况它也没有对象可以合 4.也就是一个SRP Batcher Const Buffer内容达到最大时，会进行Flush操作，这时会自动开启下一个SRP Batcher 6.节点材质需要改变渲染设备状态时，会切换SRP Batcher。因为所有渲染器状态切换都会进行一个新的Set Pass Call 7.因为这时前面也没有任何对象进行渲染 8.这种情况一般是你修改了管线中默认的顶点数据结构，两个不同顶点结构的网格对象是不能进行合批的 "},{"title":"性能优化(22)——Unity中的Batching(上)","date":"2022-09-12T07:13:28.000Z","url":"/2022/09/12/performanceOptimization-19/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"Unity中的合批 类比将桃子装卸发货的过程。其本质就是按需求组织数据从CPU发给GPU的过程，这些数据包括网格、纹理、Shader变量、材质属性等等。那么这些数据怎么组织、以什么结构组织、以什么频率发送、每次发送多少就是我们Batching要研究的问题了 哪些内容需要Batchaing 广义上讲： 资源Batching(Mesh、Texture、Shader参数、材质属性)：这些资源的合批是做后续某些Batching优化的前提 Draw call Batching(Static Batching、Dynamic Batching)：主要是为了降低GPU的DP操作，能更少地调用绘制命令接口，Unity在这里为我们提供了Static Batching与Dynamic Batching功能 GPU Instancing(直接渲染、间接渲染、程序化间接渲染)：这也是一种绘制优化的手段，用于绘制多个副本网格对象。Unity提供了直接渲染、间接渲染、程序化间接渲染的三种方法接口 Set Pass call Batching(SRP Batching)：之前Draw call Batching是为了减少渲染操作调用次数，而Set Pass call Batching是为了减少渲染状态切换的次数。Unity下为我们提供了减少Set Pass call次数的SRP Batching的功能 资源的Batching Mesh： 我们可以将临近且不移动的网格对象通过Mesh.CombineMesh合并到一起，合并后用一次网格的渲染调用代替每个网格的渲染调用。但这种方案也有一定的弊端，一旦合并的网格对象较大时，可能造成摄像机剔除不掉的问题以及OverDraw的问题，另外在内存上也会增加一定的开销。CombineMesh主要是针对于静态网格对象 如果是动态SkinMesh对象，往往由于美术为了材质表现效果，会通过Material id标记多维子材质，这样导入后会形成多个Submesh，每个不同材质的Submesh会增加一次DrawCall，我们在做平台移植或低端设备兼容时，可以合并多个材质与贴图，并通过通道图方式标记模型不同部位的材质变化 Texture： Unity默认提供了Sprite Atlas贴图，开发者也可以自己通过dcc合并同一模型上多张贴图到一张贴图上以达到纹理合并的方式 另外还可以通过TextureArray纹理数组方式向GPU同时传递多张设置相同的贴图资源 关于模型、贴图、材质这些资源的Batching，除了Unity官方提供的接口外，资源商店中也有很多资源可以使用 Shader变量与材质属性 在Build In管线下，Unity是通过Material Property Block完成合批的 而在SRP管线下则是通过Const buffer来实现的，并且通过定义不同的Const buffer，来控制提交到GPU上的频率，比如PerFrame、PerDraw、PerMaterial等Const buffer标签 Draw Call Batching 主要讲Static Batching与Dynamic Batching 与手动CombineMesh合并静态网格不同，Static Batching是引擎在构建时，自动将临近可合并的静态网格对象合并到一起，并将合并后的网格转换到世界空间下，并用它们的顶点信息构建一个共享的顶点缓冲与索引缓冲区，然后对可见网格进行简单的绘制调用。 值得注意的是：无论是CombineMesh还是Static Batching都不是在运行时合批的，如果你需要在运行时合批，可以通过Unity提供的StaticBatchingUtility.Combine的方法进行运行时合批，这对于一些运行时动态生成网格的对象特别有效，如需要动态关卡生成的Roguelike游戏。运行时合批时，你就不需要勾选BuildSetting中的Static Batching了 此外Static Batching功能依旧会有额外的内存开销，所有合批的网格对象都会在内存中保留一份额外的拷贝，是一个典型的空间换时间的优化方案 Dynamic Batching是对移动的游戏对象进行绘制批处理的手段，以减少绘制调用。Unity在运行时动态网格与动态生成几何体上的动态合批处理方式不同，Unity会将可动态合批的对象构建到一块大的顶点缓冲区中，并根据合批后的数据设置渲染器材质状态，然后将缓冲区绑定到GPU上，对于每个MeshRender是通过缓冲区偏移量来更新提交绘制内容的。做个类比，可以把静态网格对象理解成硬桃子，动态网格对象或动态生成几何体理解成软桃子，硬桃子量大、储存期长，你可以用火车起运，运输目的地可以较远，用途也更广一些；而软桃子为了避免腐烂，只可以做短距离小范围运输，甚至要就地加工，用途上会有更多限制。Dynamic Batching主要是为了一些低端、旧设备性能优化考虑的，在现代消费级硬件上，Dynamic Batching在CPU上的调用开销可能会更大，因此是否开启动态合批选项还需要在目标设备上测试使用，并不是无脑开启的 总之，无论是Static Batching还是Dynamic Batching，在使用上都有一些使用限制，稍不注意就会造成无法合批的现象 GPU Instancing GPU实例化也是一种Batching，用于渲染网格的多个副本。它是将基础网格对象传递给GPU后充分利用Instancing Buffer的方法，传递多个网格实例位置、朝向、颜色等其他属性构成的Instancing Buffer到GPU，避免了反复传递多个基础网格对象在世界空间下变换后的各种顶点数据和其他额外数据，所有的实例都会引用同一个基础网格对象，非常适合创建植被、石头等场景中大量重复的网格对象 GPU Instancing在Unity Build In管线与SRP管线下都支持，只不过在SRP管线中无法与SRP Batcher兼容，二者只能选择一个开启 需要开启GPU Instancing时，我们需要保障对应网格对象的材质中Enable GPU Instancing选项的开启 如果是自定义Shader，我们还需要定义Instancing Buffer的结构 值得注意的是，如果基础网格对象顶点数较少时，由于无法充分利用GPU资源，可能会导致性能不够理想，因此，对于顶点数较少的网格，我们需要反复测试，一般情况下不建议使用GPU Instancing Unity可以在脚本中通过直接（DrawMeshInstanced）、间接（DrawMeshInstancedIndirect）、间接程序化（DrawMeshInstancedProcedural）三个接口自定义绘制Instancing 其中第一个接口DrawMeshInstanced使用简单，但有实例化数量的限制；第二、三个更灵活一些，但实现相对复杂，可以在Unity文档中学习使用 Set Pass Call Batching 只有一类：SRP Batcher。顾名思义其仅能在SRP管线下开启 它可以显著减少Unity为使用相同着色器材质，准备和调度绘制的CPU时间开销 类比桃子运输装卸场景就是，使用什么交通工具、多少频率发一次货性价比最高 其核心是需要图形API支持的Const Buffer。这个Const Buffer中放什么、每个元素大小、Const Buffer总体大小以及什么时机以什么频率将Const Buffer中的内容提交给GPU，都是会影响最终性能的 好在Unity已经为我们定义好了一些Const Buffer类型，如 UnityPerCamera UnityPerFrame UnityPerPass UnityPerDraw UnityPerDrawRare UnityPerMaterial 上面几类SRP已经定义好的Const Buffer包含了引擎内置的一些Shader变量与属性，同时也指定了提交到GPU上的频率 而需要开发者定义的只有UnityPerMaterial这类的Const Buffer，这类Const Buffer只有在其定义属性发生变化时才会被提交到GPU上 我们需要将自定义的着色器变量与材质属性添加到这类的Const Buffer中，不能有在Const Buffer之外定义的其他属性或Uniform变量，确保SRP Batcher字段是compatible的，这一点非常重要 在SRP管线下强烈建议开启SRP Batcher功能，如果不使用此功能，个人觉得完全没必要升级到URP或HDRP管线 在URP管线中，自带的某些Const Buffer在定义上可以做一些精度上的优化，以提高Shader的指令效率 Batching优化顺序及优先级 资源Batching &gt; SRP Batching &#x3D; Static Batching &gt; GPU Instancing &gt; Dynamic Batching "},{"title":"性能优化(21)——Unity中的Simplization","date":"2022-09-12T06:30:01.000Z","url":"/2022/09/12/performanceOptimization-18/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"Unity中的简化 Simplization就像桃子分类，将不同的桃子按不同品质大小分类装箱，以满足不同桃子产品的需求 类比到性能优化中，就是将各类资源、功能分类简化，以满足不同平台、不同设备、不同类型的产品需要 以URP为例，如何在Unity下做Simplization 哪些是需要简化的内容 广义上将： 运行效率较重的资源。如运行时内存占用较高，或处理耗时较长的资源 低效、不合适功能。某些低端设备或平台不能一味地去堆砌功能，更应该去考虑平台的兼容性和此功能的通用性，做到最好的性价比 这里的简化操作不能简单地理解为重新制作资源，应当理解成是基于现有的资源进行简化操作 通常情况下，我们最常用的简化手段就是分级配置，各种LOD结合一些场景数据结构做简化。当然还有一些替代体的方案 Unity下的简化手段(比较常用的手段) Quality Settings：通过这个设置，你可以自定义在不同平台、设备下，Unity现有的一些功能的设置分级。你可以预先设置在哪些平台下开启或不开启某些功能，包括分辨率、贴图分辨率、阴影质量等的一系列设置 通过烘焙光照简化实时光照：在静态灯光场景下，可以使用烘焙的方案替代实时光照方案 通过BoundingBox或替代体碰撞代替Mesh碰撞 用Local Volume代替Global Volume来做特效与后效的区分 用多条RayCast射线检测方式代替开销比较高的SphereCast、CapsuleCast等 用纹理字体代替系统文字 Mesh LOD：根据距离采用不同复杂度级别的Mesh进行渲染，以达到不影响视觉表现，同时带来更小的开销 Shader LOD：来做多平台或低端设备上的兼容性，尤其是一些Shader效果需要图形API版本要求时 HLOD：是Unity针对于大世界提出的一种简化方案。它可以在长视距下用单个静态网格组合替代多个静态网格对象，有助于减少场景渲染对象的个数，同时减少DrawCall调用次数来做场景渲染优化。这个方案会有一定的CPU与内存开销，要看具体项目类型测试后采用。Unity将例子与库都放在官方GitHub上了 通过Camera Override代替URP管线中的一些通用设置：避免了在管线中创建一些长时间无用的渲染资源，比如Copy Depth、Copy Color等这些创建的RP资源 各种OnDemand更新或分级设置接口：如OnDemandRendring … 用户也可以通过脚本或插件做一些自定义的简化操作 场景简化数据结构：如上一章Culling中提到过的场景数据结构，这类结构不仅可用作Culling，还可以做Simplization与Batching。其中如果是PC端做ReTracing的话，一定要用到场景数据结构来简化，要不纯像素的话，效率上根本达不到实时渲染。此外，SDF体素化、点云等都是做简化渲染的重要手段 第三方LOD方案：如Automatic LOD、Poly Few|Mesh Simplifier and Auto LOD Generator、Mesh Simplify、Amplify Impostors等，在资源商店搜索LOD或Simplify可以找到很多插件 Mesh Impostor Animation LOD：不光模型，动画方面也可以尝试做LOD。比如做动画频率的LOD，可以根据视距降低远处角色的动画频率，或使用骨骼LOD为远距角色采用另一套骨骼较少的骨骼框架 2D寻路代替Navigation Mesh 扩展类似OnDemand接口：实现按需创建或按需更新的逻辑，对于一些复杂的游戏资源或逻辑也是非常必要的 总之除了利用好Unity本身的Simplization操作功能外，我们在写功能时也要有多级可配置简化的思想，这样会让你最后优化产品时，不至于由于无法简化而不得不更换方案或重新开发 "},{"title":"性能优化(20)——渲染提前期优化——Culling、Simplization、Batching","date":"2022-09-09T04:56:53.000Z","url":"/2022/09/09/performanceOptimization-17/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":" Culling（剔除）、Simplization（简化）、Batching（合批） 这些优化都是为了缩短渲染提前期，是为了进GPU管线渲染前所做的优化。将这三个过程类比桃子食品加工生产销售前的过程：将Culling剔除理解为摘桃子阶段，去除不适合的树枝和叶子、腐烂的桃子等，因为它们不适合生产；Simplization理解为为桃子分类，将不同的桃子按不同品质大小分类装箱，为了生产不同的桃子产品，或满足不同的销售渠道；Batching合批可以理解为将桃子装载发货的过程，近距离的放普通的货车，有保险需求的上冷藏车，大量需求的上火车，时间需求的上飞机，有的地方一天一发货要怎么安排运力，有的地方一周一发货要怎么安排运力，总之要保证下游能源源不断地得到桃子供应，而不会中断生产加工或销售的流程。而这些过程一般都发生在生产之前，类比于进入GPU管线之前，通常情况下这些工作都由CPU端负责，但一些特殊的生产流程可以利用生产流水线的特殊功能对桃子进行分类、清洗、剔除残次品，这个过程可以理解为做了GPU加速，将本该属于CPU端的工作放到了GPU流水线中进行了。其实总体而言，Culling剔除、Simplization简化、Batching合批三者在实际应用中并不孤立，相反是要紧密结合使用的，它们对渲染前的优化是非常重要且必要的 Culling剔除 哪些是需要剔除的内容 广义上讲： 看不见的像素、网格和对象 重复的、用不到的资源 不需要、不执行的代码 其中，剔除看不见的像素、网格和对象的方法： 像素剔除：摄像机平截头剔除、Back-face Culling（背面剔除）、Early-Z、Pre-Z Pass。其中摄像机剔除、背面剔除与Early-Z都是渲染库或硬件直接支持的部分，而Pre-Z Pass是针对于前向渲染下Early-Z失效的情况下，通过Pre-Z Pass方式提前获取场景深度，后续绘制像素时，根据场景深度外壳进行像素着色计算的剔除。是Unity2021URP下直接提供的新功能 网格对象级别的剔除：Unity提供了Layer Mask、可视距离对象剔除与Occlusion Culling的方案，前两种都可以通过简单的设置完成，而Occlusion Culling是一种CPU+烘焙的方案，在某些OverDraw严重而又存在大面积建筑或遮挡体类型的游戏中，可以起到加速的效果，但Occlusion Culling本身是一把双刃剑，由于烘焙会有额外的内存开销，而所有关于遮挡剔除的计算又在CPU端，会由额外的CPU开销。如果剔除给GPU端的优化弥补不了CPU端的开销时，这种方案可能是一种负优化，需要测试使用 灯光剔除：这部分需要依赖特殊的图形库和硬件的架构完成，比如Tile-Based Deferred Rendering，也就是通常所说的TBDR管线和Forward+渲染管线，针对于多实时光源在游戏项目上的光源剔除优化，在灯光处理上会为每个Tile建立可用的灯光列表，这时不能影响该Tile内像素的灯光将会被剔除在列表之外，这样在计算该Tile中的像素着色时可以大大节省像素光照着色的开销。目前URP下的Tile-Based延迟渲染在Unity2021中已经支持。URP Forward+管线目前仍在实验阶段，但仍可在Unity2021URP下通过定义URP_ENABLE_CLUSTERED_UI的宏来开启，从宏定义中我们也可以看出URPForward+采用的加速结构是基于Clustered的。对比而言，即使Tile-Based延迟渲染在带宽与内存上做了优化，但仍会比Forward+要高，而Forward+的性能瓶颈依然在场景对象复杂度上。因此如何选择管线要根据自己的游戏类型和目标设备来进行选择 场景剔除：是针对于大场景、多场景拼接的地图，这时我们可以通过Unity Additive的场景根据逻辑来做异步的加载和卸载，以实现场景的动态剔除，这也算是另类的Culling的一种了 除Unity提供的一些Culling的优化方案外，用户也可以扩展自己的Culling优化方案。如默认Unity下没有场景数据结构管理，可以通过添加各种场景结构来对场景中的对象进行管理，如Octree、BSP Tree、Portal等，还有对整个场景进行体素化（Voxelization），或者计算场景的SDF，这些数据结构都是为了做Culling加速或其他功能的必要数据。另外还有一些利用GPU加速的算法，如通过Hi-Z Pass利用上一帧的深度图和摄像机矩阵；利用Temporal Reprojection Culling算法来对当前这个场景做剔除；另外还有Cluster、Tile-based Visible Buffer算法，这些都可以在Unity的管线中进行扩展集成。 一般而言，基于GPU的Culling方案在移动端都会面临兼容性的问题；而基于CPU的方案往往都会存在可能变成负优化的双刃剑。其实没有任何一种Culling方案能适用于所有游戏项目，如果想扩展自己的Culling方案，往往需要代码实现的功能能力要大于理解算法本身的能力，所以不是优化到极致或者超大规模商业项目，一般很少有团队会去尝试 "},{"title":"性能优化(19)——Postprocess后处理优化","date":"2022-09-08T13:42:18.000Z","url":"/2022/09/08/performanceOptimization-16/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; Unity URP下支持的后处理效果分类 色彩校正与增强：我们做游戏依旧是在原始美术贴图、材质光照上做调整，不能完全依靠后期色彩校正来处理。换句话说不是不能用，而是不能胡乱堆砌 画面增强类：这类后处理效果一般需要额外的Render Pass处理，涉及RP的切换与与采样开销都比较高，因此整体性能开销也比较大，所以尽量不要叠加使用。如果非要使用，建议不要采用Global Volume方式一直开启，而是采用Local Volume方式在不同逻辑下进行开启，比如色散分离只在受伤类情况下开启，景深只在过场动画开启等 镜头效果：这类效果一般是Shader计算量比较大，也有一些纹理采样的开销，总体开销介于前两类之间，使用这类镜头特效应与第二类特效一样，建议通过Local Volume设置或通过逻辑开启 Unity URP下支持的后处理效果列表 Bloom：这是一个全屏泛光的效果，还可以通过指定污垢贴图形成泛光与镜头污垢结合的效果，但更常用的是泛光效果，这也是在移动平台中最常用的后处理效果，但在一些低端移动设备上的开销还是较重的 Channel Mixer：是通道混合器，可以通过修改每个颜色通道的输出，调整整体效果。除一些特殊表现外，我们更习惯通过HUE去调整，所以平时使用到它的几率也很小 Chromatic Aberration：能在图像敏感分界边界产生RGB散射的彩色条纹，用来模拟相机的镜头无法将颜色聚合到一起的颜色失真效果，一般也可以用来表现机器人视觉或屏幕破碎导致的屏幕失真效果。除特殊需求外也很少用到。由于它会对原屏幕贴图进行重复的三次采样去乘以位移uv，所以有一定的纹理采样开销 Color Adjustment：用来调整最终画面整体的色调、曝光度、HUE、亮度和对比度，用来增强画面的颜色效果，还是算比较常用的。它的处理根据ColorGradingMode模式的不同分为HDR与LDR模式 Color Curves：主要是在特定的范围内调整色调、饱和度、亮度和对比度，可以实现特定的色调替换和某些亮度降低的效果。可以作为Color Adjustment的进一步调整，但我们一般通过Color Adjustment调整基本已经满足绝大多数需求，因此此效果使用也很少 Depth Of Field：景深。由于其在移动设备上开销还是很大，因此在游戏过程中很少直接开启，一般作为实时渲染过场动画时，可以通过节省逻辑开销来换取景深的开销，以此来提升过场动画的表现。它分为高斯与散景两种景深模式，一般散景模式下，既可以使用近场景深也可以使用远场景深，性能开销会比较大；高斯模式一般是用作表现远场景深，效果相对较差，但开销也相对较小。如果是移动设备，建议使用高斯模式的景深 Film Graim：用来模拟胶片的随机光学纹理造成的胶片颗粒感效果，一般在特殊表现下使用，性能也会随着颗粒感强度与噪点响应曲线的降低而增加。另外，它需要采样多张预制的Lookup纹理，因此它也存在一些纹理采样开销 Lens Disortion：镜头失真效果，通过扭曲最终渲染图片来模拟真实的镜头效果，开销较小但应用场景不多 Lift,Gamma,Gain：是通过三个在轨迹球上的点的位置，在给定的颜色范围内，将图像色调移向该颜色，也是属于图像颜色校正的一类，应用并不多 Motion Blur：是模拟真实摄像机在拍摄移动问题，或者摄像机本身快速移动导致图像画面模糊的效果。目前URP还没有完全结合MotionVector，因此只能实现摄像机本身的移动模糊。Motion Blur的优化可以依据其本身的质量分级、设置模糊强度、摄像机旋转产生的速度具有最大长度这几个参数来优化。但在移动端仍建议不要一直开启，在一些过场动画和局部逻辑中使用尚可。建议将质量设置为Low的同时，将Intensity与Clamp值在不影响效果的情况下设置得越小越好 Panini Projection：帕尼尼投影，可以帮助你在很大视野的场景中渲染透视图、阴影、中调、高光，这个效果是用来重新定义阴影、中间调和高光的色调范围，而Split Toning会根据亮度值对图形的不同区域进行着色，以获得具有特色的表现。这几个效果使用率都较低，也没有什么可优化空间，只做简单介绍 - Tonemapping：是将HDR值重新映射到新的颜色范围内的过程，最常用的就是ACES Tonemapping，即使在移动设备上还是有机会用到- Vignette：渐晕效果，说白了就是四边暗角的效果。它有一定的计算开销。在游戏中由于UI的存在，使用的话会很奇怪。一般用于无UI过场动画或截图的时候- White Balance：白平衡主要是用来消除不真实的偏色，以白色作为参考色，在最终图像中创建偏冷或偏暖的感觉。在游戏中应用的机会不多- Lens Flare：镜头光晕特效，是为了一些特殊画面增强设计的，如太空、林间阳光、镜头光晕效果等。开销与其组件Occlusion设置和光晕数量有关，建议只在有需求时开启 值得注意的是，尽量将不需要的效果直接删除，而不是通过复选框禁用。因为有些效果即使你禁用了，它的一些渲染资源依旧会被预先绑定，会导致内存的浪费 Color Adjustments优化选项来自URPAssets中对Post-processing字段的设置 Crading Mode中的High Dynamic Range（HDR）模式更适合电影制作工作流中的高精度分级，如果我们是游戏，也可以采用Low Dynamic Range（LDR）模式 另外，LookUpTexture的纹理大小（LUT size）可以调整，HDR模式下默认是32，在平衡效率与质量时，我们还可以在LDR模式下使用16位模式 还有sRGB与线性空间转换（Fast sRGB&#x2F;Linear conversions），使用速度较快但精度较低的近似函数选项。在优化时我们评估低端设备上画面损失与性能提升的性价比，可以参考勾选此选项。但要说明一点的是，如果支持浮点精度纹理的平台或设备，Color Grading的HDR模式效率会更高 "},{"title":"性能优化(15-18)","date":"2022-09-08T08:25:25.000Z","url":"/2022/09/08/performanceOptimization-15/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 移动平台优化顺序 先优化ios，再优化android 苹果在ios平台上有比较强大的性能分析工具 ios平台的设备较少，不像android那样硬件千差万别，各家的操作系统也五花八门 先共性性能优化，再兼容性方面的性能优化 一般共性的性能问题，ios优化好了，android平台也就差不多了，只需要对特殊的硬件和系统做兼容性优化处理即可 Unity下常见的等待函数（Profiler下） URP下SSAO的优化 通过开关SSAO，可以看到画面中一些模型的拐角处和连接处的明暗对比会更明显，画面的立体感和层次感会更丰富 Downsample选项：选择这个选项可以降低生成中间纹理的分辨率，以降低纹理采样数，这对SSAO整体效率提升是非常明显的 默认在URP下只提供降低1&#x2F;2分辨率的设置，我们可以尝试修改为原始分辨率的1&#x2F;4大小，这样整体纹理采样率就会降低到原来的1&#x2F;16 此外URP中只对AO第一张中间纹理做了降采样处理 我们还可以对其他模糊过程中的中间纹理进行降采样，以降低纹理采样的开销，当然这样降采样会带来视觉表现上的损失 你可以通过扩展SSAO的参数，为每张生成的中间纹理指定降采样系数，并将其暴露到编辑器上，这样通过可视化调整，达到既保障效率又满足视觉表现的平衡 After Opaque选项是将计算和应用SSAO放到不透明物体渲染之后，以改善在tiled-based架构的GPU上的效率。考虑到是移动端的优化，虽然它会造成物理理论上的一些不精确，但还是建议开启 当Source选项是灰的时，是因为工程是延迟渲染的，所以默认就会生成Depth和Normal的信息，用这两个信息可以生成更精确的AO。将Rendering Path改成前向渲染时，我们可以使用Depth生成Normal并计算AO信息，这时我们可以调整生成AO的精度质量 Intensity：是AO强度的设置，这个参数是影响混合系数，通过混合系数调整最终AO的混合强度。这个值一般不会影响效率，但我们可以通过它和其他选项配合一起做优化 Radius：AO信息计算的采样半径，这个值越大，GPU开销也就越大，一般我们要在可接受的视觉效果范围内，通过调低采样半径，调大AO强度来优化AO显示效果 Direct Lighting Strength：直接光影响的强度，这部分一般是指受直接光照的像素，来混合这个影响AO的系数，以此来调整表现效果，这个参数并不影响渲染效率，可以采用默认值 Sample Count：采样次数，这个值直接影响采样的循环次数，值越大性能开销也越大，虽然表现效果越好，但性能上是得不偿失的，一般在移动设备上应尽量保障最小采样次数下来调整AO的效果 SSAO进一步优化 使用HBAO(horizon-based ambient occlusion)或基于HBAO魔改的采样更少但AO效果更好的GTAO（Ground Truth Ambient Occlusion）方案替代SSAO 针对SSAO的Shader指令做进一步优化 可以采用烘焙AO到光照贴图的方案替换SSAO方案 反走样方案的发展 反走样主要是为了解决采样不足导致的问题，一般方案选择需要兼顾画面质量与渲染效率权衡的前提下对图像进行增强 反走样方案经过了从第一代SSAA到第二代MSAA、FXAA、SMAA，目前逐步被第三代的TAA以及未来的第四代DLSS所取代 目前Unity的URP下，AA的方案主要还停留在第二代 URP中的AA方案 效率：FXAA &gt; SMAA &gt; TAA &gt; MSAA 质量：MSAA &gt; SMAA &gt; TAA &gt; FXAA "},{"title":"性能优化(14)特别篇——性能优化之道","date":"2022-09-08T04:27:36.000Z","url":"/2022/09/08/performanceOptimization-14/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&emsp; 性能优化问题的本质 慢与快的问题 前提： 稳定性：不能因优化造成稳定性变差 兼容性：不能因优化导致兼容性变差 性价比：优化要有度，考虑成本与复杂度 性能优化的流程 影响性能的四大类问题 CPU GPU 带宽 内存 可以把GPU、CPU分别理解为生产相关产品的两个工厂；内存和其他存储视为仓库；带宽视为运输路线 性能的瓶颈可能会发生在两个工厂的生产能力、仓库的存储能力、工厂与工厂以及工厂与仓库之间的道路是否畅通、运输工具和运输能力是否跟得上 工厂内（CPU、GPU）也像整个工厂系统，它们内部也分为车间，也就是芯片内的逻辑处理单元（ALU）与工厂内的仓库比如L1、L2、L3级的缓存，以及它们之间的通讯总线。它们像车间与车间之间、车间与厂内仓库之间的道路等工厂系统。所以一旦定位到CPU与GPU上的问题时，我们还要再去看这个工厂内的系统优化。整个过程像套娃，优化也需要迭代进行 隐藏的几类小问题 功耗比 填充率 发热量 功耗比：可以理解为工厂生产相同数量的产品所需要耗费的能源。对比设备上，就是达到相同计算能力的耗电量。这对一些用电池的设备也是个性能指标。同样，功耗比越高，发热量也就会越大 填充率：可以理解为工厂运输道路使用50t&#x2F;车的运输载具，载具每小时出发，但是你的工厂每小时只能生产30t的产品；或者说运输载具只有20t，你一车装不完，两车又浪费的情况。换到实际渲染中，纹理或资源很大，带宽一次传不过去，两次又浪费的情况。这时需要修改资源大小来匹配设备的带宽，避免填充率不足或带宽阻塞问题 发热量：比如你的芯片主频很高，但功耗比很差，那么发热量也一定会升高。另外还有一些移动设备不仅芯片发热，显示屏幕的功耗高也会造成发热。这些问题都会带来整体硬件环境温度高，一些操作系统会防止硬件温度过高而自动采取硬件降频的方式，这同样会带来一些性能问题 性能问题可能的情况（选择性采纳） 瓶颈可能性按由高到低的顺序排列（个人经验总结）： CPU利用率 带宽利用率 CPU&#x2F;GPU强制同步导致的阻塞问题 片元着色器复杂 顶点Buffer可读写造成的CPU到GPU之间的传输问题 可读写的纹理CPU到GPU之间的传输问题 顶点着色器复杂 由于三角形数过多导致的几何复杂度过高 瓶颈检查优先检查CPU所带来的情况。而GPU端的瓶颈往往大概率是片元着色器的问题，这点瓶颈也很好确认，我们只需要改变显示分辨率即可快速确认是不是由于片元着色器所带来的问题 经常用的优化思路 升维与降维 一般来说，升维是用来优化性能，但从算法方面来说可能不太容易理解；而降维是为了方便理解算法，但性能往往会比较差。比如多线程并行程序往往会比单线程串行的更高效，当然前提是并行的优化要大于创建多线程资源的开销。 高维度也可以降低低维度上无法解决的问题，比如变换矩阵的齐次坐标、四元数解决万向节锁的问题等 维度转换，空间与时间，量纲转换 做优化要有维度转换的概念，如空间维度与时间维度的转化，面向对象设计的ASO到面向数据设计的SOA的转化，量纲的转化，积分变换等。这些都可以理解为维度的转换。 其中，以空间换时间是大多数算法优化最直接的方式，如通过缓存池避免每次分配带来的开销，TAA和DLSS都是通过时间维度上的卷积来实现优化的 你将一张2K大小的图弄成四帧1K大小的图哪里有省？处理的像素不是一样多吗？——有时间维度参与计算的话，上一帧处理的像素在下一帧可能没有发生变化，这样就不用重新计算，不就节省了吗 "},{"title":"性能优化(13)编辑器创建资源优化(5)——动画","date":"2022-09-07T13:47:04.000Z","url":"/2022/09/07/performanceOptimization-13/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"编辑器内创建动画资源的优化 &emsp; Unity动画系统回顾 Animation中的Animation Clip Animator中的Animator Controller Graph Playable API中的Playable Assets 其中Animation Clip主要是动画曲线资源。Unity的Legacy动画系统主要依赖于此类资源 Legacy动画系统主要是对应Unity4之前的动画系统，Unity4后Unity的动画系统改为Mecanim。这套系统中以上三类资源都会用到，其核心是Playable API。在Playable API基础上支持Animation C# Jobs、Timeline等。其中Animation C# Jobs主要是为了Animation Rigging与Kinematica高级动画提供高效的并行基础 上述三类动画资源的使用细节Animation 通过Animation窗口，我们可以创建与编辑游戏对象的各种属性的动画曲线 这些属性包括对象的Transform、材质颜色、光照亮度、声音音量以及我们在脚本中自定义的各种值 在使用上，Animation也最为简单，但我们需要注意一些性能的细节： 播放单个AnimationClip速度，Legacy Animation系统更快，因为老系统是直接采样曲线并直接写入对象的各种属性；而新的Mecanim系统，则具有用于混合的临时缓冲区，并会对采样曲线和其他数据进行额外的复制。请注意，这里的高效是指播放单个Animation Clip，而并不是整体的动画性能老的系统一定比新的系统高，后续会详细说明 针对动画的缩放曲线，比位移、旋转矩阵开销更大。因此我们尽量不要做对对象的缩放动画 常数曲线不会每帧写入场景，更高效 Animator Animator中的Controller对应Animation Controller Graph资源；Avatar是我们在导入时生成设置的 Animator动画系统更新的主要流程 其中白色的步骤是动画系统中各个时段的回调，灰色的步骤则是动画系统更新的关键步骤 最开始的是Animation Controller Graph中的动画状态机更新 接下来的ProcessGraph是对需要评估的所有Animation Clip进行采样，以及计算根骨动画（RootMotion） 再接下来的ProcessAnimation是计算动画图混合结果 WriteTransform是将所有动画变换从工作线程写入场景对象的Transform 最后的WriteProperties是从主线程中将其他动画属性写入到场景对象中 了解完新动画系统的更新流程，还需要注意Animator的一些细节： 不要使用字符串来查询Animator 使用曲线标记来处理动画事件 使用Target Marching函数来协助处理动画 将Animator的CullingMode（裁剪模式）设置成Based On Renderers来优化动画，并禁用SkinMesh Renderer的Update When Offscreen属性来让角色不可见时动画不更新 对比Animator与Animation Animation适合简单动画和较少动画组件的情况，而Animator更适合处理高动画曲线条数和更复杂的动画组件情况 Animator的弊端可以用Playable API来解决 Playable API Playable API是以一套树形结构来组织数据源，并允许用户通过脚本来创建和播放自定义的行为，支持与动画系统、音频系统等其他系统交互，是一套通用的接口 换句话说，在Unity中，所有带时间轴的资源，都可以用Playable API来播放 Unity中还提供了一套可视化PlayableGraph的工具：PlayableGraph Visualizer 对比Playable API与Animator PlayableDirector与Timeline Asset的关系 可以通过自定义的Track来扩展Timeline的轨道 并可以在Timeline轨道上通过Signal或Mark添加自定义的回调事件，这样Timeline工具可作为角色技能编辑器、过场动画编辑器的工具了 总结：解决方案选择 一些简单、少量曲线动画可以使用Animation或动画区间库如Dotween\\iTween等完成，如UI动画、Transform动画等 角色骨骼蒙皮动画如果骨骼较少，Animation Clip资源不多，对动画混合表现要求不高的项目（如开关门、车辆、简单角色）可以采用Legacy Animation。要非常注意控制总体曲线数量 一些角色动画要求与逻辑有较高的交互、并且动画资源不多的项目可以直接用Animator Graph完成。这种情况要非常注意动画状态机中的状态机节点个数，避免使用过多的动画状态机节点与层 对于动作游戏，对动画混合要求较高、有一些高级动画效果要求、动画资源庞大的项目，建议采用Animator+Playable API扩展Timeline的方式完成（这时状态机中一般只有一个基础节点-走跑跳，而一些特殊的如技能、持不同武器的动画状态模组以及过场动画的表现都使用Playable API去扩展Timeline完成）。 "},{"title":"Unity Shader入门精要 第九章","date":"2022-09-04T09:09:04.000Z","url":"/2022/09/04/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-8/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"中级篇 更复杂的光照 9.1 Unity的渲染路径9.1.0 在Unity里，渲染路径（Rendering Path）决定了光照是如何应用到Unity Shader中的 因此如果和光源打交道，就需要为每个Pass指定它所使用的渲染路径 使用摄像机组件里的Rendering Path可以覆盖Project Setting里的设置 前向渲染路径的原理 Important：告诉Unity这个光源很重要，会被当成逐像素的光源使用 Not Important：告诉Unity这个光源不重要，会被当成逐顶点或SH的光源使用 9.1.1 内置的光照变量和函数 前向渲染可以使用的内置光照变量 前向渲染可以使用的内置光照函数 9.1.2 顶点照明渲染路径 Unity中的顶点照明渲染 可访问的内置变量和函数 9.1.3 延迟渲染路径 延迟渲染的原理 Unity中的延迟渲染 可访问的内置变量和函数 9.1.4 选择哪种渲染路径 9.4 Unity的阴影9.4.1 阴影是如何实现的"},{"title":"性能优化(12)编辑器创建资源优化(4)——物理","date":"2022-09-03T01:37:25.000Z","url":"/2022/09/03/performanceOptimization-12/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&emsp; Unity中的物理 Box2D Nvidia PhysX Unity Physics Havok Physics for Unity Unity中的默认2D物理解决方案是使用的开源Box2D库完成的，它是一套高效的2D刚体物理的C++代码库，也是在做2D物理游戏开发时经常选择的解决方案。 而Unity中的3D物理默认解决方案是使用的Nvidia的PhysX库。这套库一直有一个比较大的问题，它是一套非确定性物理模拟库，也就是说，即使你两次输入相同的物理条件，依然会在后续模拟表现上呈现出不同的物理表现效果，这也让它在一些状态同步的网络游戏中无法做逻辑处理，而帧同步的网络游戏中又因其更新频率与渲染频率的不同，以及服务器演算物理时负载过重的问题，只能在一些客户端上做物理表现渲染 为了物理模拟的确定性，Unity还推出了一套符合DOTS设计理念的新的物理库——Unity Physics。但它无法像英伟达的Physics那样提供完整的全套的物理模拟。只能在保证高性能的基础上实现一套更简单的功能子集。但它可以在单帧内完成多次物理模拟，以显示未来的预测，比较适合做网络游戏中的物理。虽然它无法做到基于显卡的硬件加速，但由于DOTS的存在它依然可以在一些多核CPU上做到比较高效的表现 此外unity还提供了一套基于Havok物理库的物理解决方案，同样是符合DOTS的设计理念，数据也可以与Unity Physics通用，它可以用来增强Unity Physics包的功能，不过除需要安装额外的Pacage外，还需要在使用前得到微软Havok的授权 Unity下如何对默认物理部分进行优化工程设置与编辑器设置方面 如果是2D物理，通过Physics 2D标签设置；如果是3D物理，通过Physics标签设置 这个界面最重要的是图形碰撞矩阵的设置。在默认没有配置的情况下，所有图层上的游戏对象都会默认创建与其他图层上所有对象的碰撞，这是相当低效的，所以我们需要为每种类型的对象定义不同的层，对于每个新图层，通过设置碰撞矩阵中与其他图层是否有碰撞关系来避免不必要的碰撞，以及在碰撞监听器上的检测。 除碰撞矩阵外，Physics标签下还有许多选项，大部分情况下我们不需要修改，除非有一些特殊需求 Auto Sync Transform选项：这个选项是在Transform组件发生变化时，强制进行物理系统同步，相当于在修改Transform后立即强制执行一次对物理对象的模拟更新，这样会增加物理运算负担，一般不开启。不开启的情况下不是说不更新，而是要等到FixedUpdate过程再去对对象进行物理更新。大多数情况下不开启也能满足视觉表现效果 Reuse Collision Callbacks选项：这个选项应尽量保持开启，这样在物理引擎对所有碰撞回调时会重用之前的Coliision碰撞结果的实例，而不会为每个碰撞回调重新创建一个碰撞结果的实例。由于大多数情况下碰撞结果实例只是数值上的变化，重用已经创建好的碰撞结果实例可以降低托管堆上的GC开销 物理解算器迭代次数的两个设置 Default Solver Iterations、Default Solver Velocity Iterations选项：分别与物理碰撞精度、与碰撞后物理模拟精度有关。迭代次数越高，模拟越精确。实际使用时可以根据自己项目上的物理模拟表现的精度来调整迭代次数，一般情况下选择默认设置就好，因为迭代次数越高，物理模拟计算开销越大 Broadphase Type选项：由于3D物理使用的时Physics SDK，在其中物理模拟扫描场景时有粗筛和细筛的阶段算法，相当于用场景划分来对物理场景进行查找加速。我们可以根据自己的场景物理物体的复杂度与场景特点去选择不同的算法，一般默认就好。如果你的场景真的过于复杂，再去根据实际情况选择另外两个选项 在工程设置的Time标签下，对于FixedUpdate更新频率的设置。我们都知道，Unity默认情况下物理的更新都是在FixedUpdate中完成的。 这里默认设置的0.02ms代表每秒更新50次，这个更新频率越高，物理计算开销越大 对于一些低端手机如果帧率较低的情况下，50帧每秒的更新相当于每个渲染帧物理更新快2次了。可以适当降低一点物理的更新频率。但这个物理更新频率的降低也会带来一些副作用，比如对于一些高速运动的物理物体，如子弹，穿越比较窄的物理物体（如较薄的墙）时，当物理模拟更新频率不够高时，可能不会发生物理碰撞的回调，这时我们可以有两种方式来改善： 利用射线作为类似高速子弹的碰撞检测 利用两个渲染帧子弹的位置拉出一个包裹盒，再用这个包裹盒去与墙做碰撞检测 我们如果在Physics标签下禁用了Auto Simulation选项后，我们可以在C#代码中通过调用Physics Simulate接口来手动在任何逻辑位置更新物理系统 Time标签下的Maximum Allowed Timestep选项：限制了物理计算FixedUpdate事件在帧率下降时允许更新的最大步长，如果大于这个时间会出现一些奇怪的物理行为。因此合理的阈值可以避免物理模拟的错误，一般这个值推荐在8-10个FPS之间，大概是0.1-0.16ms之间 Collider与Rigidbody组件Collider 物理模拟与物理碰撞不是一码事。物理碰撞只是物理对象之间发生的Collision与Overlap的回调，并不会对后续的物理反馈做模拟，因此我们需要检查我们的对象是否同时需要Collider与Rigidbody组件。如果只需要触发回调并不需要添加Rigidbody组件 Trigger与Collider Unity Collider对象有很多种，如果能用简单的Collider替代复杂的对象的MeshCollider的话，尽量用简单的Collider。即使用多个简单的Collider代替一个复杂的MeshCollider也是值得的 Rigidbody Kinematic与Rigidbody 当有物体需要按固定的方式去运动，并且能触发碰撞，同时能对其他刚体造成影响时，勾选isKinematic选项，它比rigidbody的物理开销小 在Unity Profiler的物理模块中，勾选了is Kinematic选项的对象不会增加Rigidbody的数量 Unity中的RayCast与Overlap部分的优化 柔体、流体部分的物理并不常用"},{"title":"性能优化(11)编辑器创建资源优化(3)——UGUI（下）","date":"2022-09-03T01:37:21.000Z","url":"/2022/09/03/performanceOptimization-11/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&emsp; UI字体 避免字体框重叠，造成合批打断 字体网格重建 UIText组件发生变化时 父级对象发生变化时 UI组件或其父对象enable&#x2F;disable时 UI字体 资源导入时的设置 TrueTypeFontImporter 支持TTF和OTF字体文件格式导入 Font Size：字体大小，是基于文字处理程序设置的大小 Rendering Mode：使用哪种字体渲染的平滑模式。默认使用Smooth就好，这种是在动态字体上最快的一种模式 Character：导入字体文件选择哪个字符集 Dynamic：在运行时渲染字体字形 Unicode：代表选择Unicode字符集 ASCII default set：代表选择ASCII码字符集 ASCII Upper Case：代表选择ASCII码中的大写字符集 ASCII Lower Case：代表选择ASCII码中的小写字符集 Custom Set：代表自定义选择字符集，选择这个选项时，我们可以从导入的字体文件中选择我们想要的字符 除第一种Dynamic外，其他5种都是静态字符集 接下来的几个选项都是字符边界的选项，一般默认就好 Include Font Data： 勾选时一般适合动态字体属性一起使用。 当选中复选框后，导入的TTF或OTF文件会随APP文件构建一起输出；如果没有勾上该选项则不会随APP一起输出。 如果使用的是对应操作系统中已有的字体，不勾此选项则可以节省内存与输出包大小；如果目标文件中没有该字体，则会在下面Font Name选项列表中选择一种后备字体使用。 也可以使用References to other fonts in project选项中指定的其他项目内的字体作为后备字体 当然我们还可以使用Unity编辑器中的Custom Font或通过TextMeshPro中的Font Asset Creator工具创建自定义式样的静态字体资源 选择Dynamic字符集后使用动态字体或字体图集需要了解的一些细节： 字体图集会按2的幂次大小进行扩大，图集大小只增不减（512x512 -&gt; 512x1024）,运行时，这会对我们的效率产生一定影响，所以在预加载或启动时，我们可以通过Font。RequestCharacterInTexture接口将运行时需要的字体提前加入到图集中，这样可以有效地减少启动时间或运行时字体图集动态扩展的时间 建议将TextMeshPro作为Unity文字处理的最佳方案 TMP使用有向距离场（Signed Distance Field 简称SDF）作为文本的渲染管道，可以以任意点大小和分辨率清晰地渲染文本，并在一些视觉特效上使用材质预设来处理，如轮廓、阴影、倒角、光晕等效果，而且效率更高 超采样：加大FontSize，减小Scale 简单地说：TMP记录的是一个字体的矢量形状，渲染时通过矢量方式来进行渲染，因此无论如何放大缩小它的清晰度都是不会改变的。这也就是TMP最大的优点 将Scene视图中的显示模式改为Overdraw（显示当前图像在屏幕中的填充率）后如下图所示： 在同样的屏幕范围内渲染多次就会产生overdraw，可以发现TMP基本不会出现重叠部分。在一般渲染情况之下已经比Text有一定的优势了 假如在Text上面添加一个描边组件如下图所示： 因为描边，它渲染了四次，对于屏幕填充率的占用，它的性能非常差 而使用TMP，只需对材质上的描边厚度进行添加，就完成了描边 因为本身TMP使用SDF有向距离场的方式来进行渲染的时候，它在渲染之前就已经把这个描边给计算出来了 因此TMP组件在性能上远远超过Text组件 缺点： 选中对应的材质。我们每次使用TMP，都会对现有的资源里的贴图进行修改，而这个贴图所占的空间是比较大的 在贴图被填满后假如不勾选Multi Atlas Textures（使用多张贴图）的话，新的字会显示不出来（显示口字）。为了避免这个问题，一般会选到4096x4096,并且勾选Multi Atlas Textures，同时减小Sampling Point Size到60、Padding到6（取样大小） UI控件优化的注意事项首先，不需要交互的UI元素，一定要关闭Raycast Target选项一定要使用OnDemandRendering接口降频，而不是直接调整TargetFPS。两者的区别是，OnDemandRendering接口只会降渲染频率不会降输入频率，而TargetFPS接口会渲染和输入一起降 滚动视图Scroll View 首先，它是个容器，需要大量实例化子对象控件，子对象控件简单点还好，如果过于复杂会有效率问题。不光对象大量实例化开销，由于视图滚动还要触发UI的Rebuild开销。这时我们需要做两个工作来进行优化： 使用RectMask2d组件裁剪，通过模板缓冲剔除不必要的渲染。注意不要使用不规则的滚动视图，因为RectMask2d没有使用模板缓冲，而直接使用Rect相交检测去裁剪，如果是不规则形状则需要PixelMask写额外的Shader来做剔除，这样会有额外的渲染开销 可以通过可视化位置构建子元素对象池，以减小内存与实例化的开销。这里的内存池是根据子对象的渲染位置来做的内存池，而不是对所有子对象做的内存池 "},{"title":"Unity Shader入门精要 第八章","date":"2022-08-31T04:16:48.000Z","url":"/2022/08/31/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-7/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"8.透明效果 8.0 深度缓冲：在实时渲染中，深度缓冲是用于解决可见性问题的，它可以决定哪个物体的哪个部分会被渲染在前面，哪些物体会被遮挡。它的基本思想是，根据深度缓冲的值来判断该片元距离摄像机的距离，当渲染一个片元时，需要把它的深度值和已经存储在深度缓冲中的值进行比较（开启深度测试的前提下），如果它的值距离摄像机更远，说明这个片元不应该被渲染到屏幕上，因为有物体遮挡住了它；否则这个片元应该覆盖掉颜色缓冲中的像素值，并把它的深度值更新到深度缓冲中 8.1 8.2 Unity Shader的渲染顺序 8.3 透明度测试 8.4 透明度混合 8.5 开启深度写入的半透明效果 ColorMask 0：该Pass不写入任何颜色通道，即不会输出任何颜色 8.6 ShaderLab的混合命令8.6.0 8.6.1 混合等式和参数 8.6.2 混合操作 8.7 双面渲染的透明效果"},{"title":"性能优化(10)编辑器创建资源优化(3)——UGUI（上）","date":"2022-08-30T06:50:50.000Z","url":"/2022/08/30/performanceOptimization-10/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&emsp; Unity UI性能的四类问题 Canvas Re-batch时间过长 Canvas Over-dirty，Re-batch次数过多 生成网格顶点时间过长 Fill-rate overutilization （UIshader中GPU片元着色器的利用率过高） Canvas画布 Canvas负责管理UGUI元素，负责UI渲染网格的生成与更新，并向GPU发送DrawCall指令 这些工作全是在引擎native层，由C++负责完成的。 对于每个Canvas对象，在绘制之前，都要进行一个合批的过程。 如果Canvas底下的所有UI元素，每一帧都保持不变，那么只需在绘制前合批一次，并保存下结果，并在之后的每帧渲染中继续使用这个保存的结果；如果UI元素发生了变化，这时画布需要重新匹配几何体，而画布被标记成dirty，这时被标记成dirty的Canvas会触发Re-batch，也就是重新需要合批 Canvas Re-batch（合批）的过程 1.根据UI元素深度关系进行排序 2.检查UI元素的覆盖关系 3.检查UI元素材质并进行合批 UGUI渲染细节 Re-Build过程 Re-Build是Re-batch过程中完成的，主要逻辑在C#层，用来重新计算Layout布局与渲染网格重建，每当Canvas组件调用WillRenderCanvases事件时，都会调用CanvasUpdateRegistry中的PerformUpdate方法，这个方法主要完成三个工作 通过ICCanvasElement.Rebuild方法重新构建Dirty的Layout组件 通过ClippingRegistry.Cullf方法，对任何已注册的裁剪组件Clipping Components的对象进行裁剪剔除操作，如已注册了Mask的UI元素 任何Dirty的Graphics Components都会被要求重新生成图形元素 Layout组件和Graphics组件什么时候被标记成dirty： Layout Rebuild UI元素位置、大小、颜色发生变化时 优先计算靠近Root节点，并根据层级深度排序的transform操作时会被标记成dirty并触发Layout Rebuild过程 Graphic Rebuild 顶点数据被标记成Dirty时 材质或贴图数据被标记成Dirty时会触发Rebuild过程 UGUI性能优化 使用Canvas的基本准则： 默认情况下，UGUI是通过Canvas的Graphic Raycaster组件来处理输入、触摸以及鼠标悬停事件。每个Canvas都会绑定一个Graphic Raycaster组件，并每帧检测鼠标鼠标的位置。Unity5.4之后，对于没有鼠标的设备不会进行每帧检测。如果不需要交互的Canvas对象可以禁用Graphic Raycaster组件 "},{"title":"性能优化(9)编辑器创建资源优化(2)——预制体","date":"2022-08-30T06:15:52.000Z","url":"/2022/08/30/performanceOptimization-9/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&emsp; 预制体 Unity中的预制体是用来存储游戏对象、子对象及其所需组件的可重用资源，一般来说预制体资源可充当资源模板，在此模板基础上可以在场景中创建新的预制体实例 使用预制体的好处 由于预制体系统可以自动保持所有实例副本同步，因此可以比单纯地简单复制粘贴游戏对象做到更好的对象管理 此外通过预制体嵌套（Nested Prefabs）可以将一个预制体嵌套到另一个预制体中，从而创建多个易于编辑的复杂游戏对象层级视图 可以通过覆盖各个预制体实例的设置来创建预制体变体（Prefabs Variant），从而可以将一系列覆盖组合在一起形成有意义预制体的变化 嵌套预制体与单预制体相比的优点与缺点 预制体变体 使用Prefab变体的一些限制 "},{"title":"Unity Shader入门精要 第七章","date":"2022-08-26T05:10:43.000Z","url":"/2022/08/26/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-6/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&nbsp; 基础纹理的介绍 纹理的最初目的：使用一张图片来控制模型的外观 使用纹理映射技术，我们可以把一张图贴在模型的表面，逐像素地控制模型的颜色 通常在美术人员建模的过程中，会在建模软件中利用纹理展开技术把纹理映射坐标存储在每个顶点上面，纹理映射坐标定义了该顶点在纹理中对应的2D坐标。通常这些坐标用一个二维变量：UV来表示，其中U是横向坐标，V是纵向坐标，因此纹理映射坐标也被称为UV坐标 尽管纹理的大小可以是多种多样的（256x256 1024x1024），但顶点UV坐标的范围通常会被归一化到0-1之间 纹理采样时使用的纹理坐标不一定是0-1范围内的 在OpenGL原点位于左下角，DirectX原点位于左上角，Unity符合OpenGL的传统 7.1 单张纹理 其中_MainTex_ST不是随意起的，而是主纹理”_MainTex” + “ST” 其中”ST”是缩放和平移的缩写，可以得到模型的缩放和平移值，通过.xy存储缩放值，.zw存储偏移值 在a2v里订阅了TEXCOORD0的语义，来声明一个新的变量TEXCOORD，Unity会将该模型的第一组纹理坐标存储到该变量中 在v2f结构体中添加了用于存储纹理坐标的变量”uv”，以便在片元着色器中来使用该坐标进行纹理采样 核心代码在片元着色器，在顶点着色器中只做一些简单的转换 &#x2F;&#x2F; 声明一个v2f变量&#x2F;&#x2F; 将模型空间顶点位置转换成裁剪空间&#x2F;&#x2F; 模型顶点的法向量转换成世界空间下的法向量&#x2F;&#x2F; 顶点空间下的顶点坐标转化成世界空间下的顶点坐标&#x2F;&#x2F; 纹理坐标的变量uv：获取纹理坐标v.texcoord.xy,先缩放再偏移&#x2F;&#x2F; 内置的宏，功能一样 参数：顶点纹理坐标，纹理名 核心的渲染代码，逐像素渲染 &#x2F;&#x2F; 先计算世界空间下的法线方向 和 光照方向&#x2F;&#x2F; 用cg的函数tex2D进行纹理采样 参数：被采样的纹理、纹理坐标&#x2F;&#x2F; 计算环境光部分 ambient&#x2F;&#x2F; 计算漫反射 diffuse&#x2F;&#x2F; 计算高光反射 speoular 7.2 凹凸映射 目的：使用一张纹理来修改模型表面的法线，以便为模型提供更多的细节。这种方法不会真的改变模型顶点位置，只是让模型看起来好像是凹凸不平的，在模型的轮廓处可以看出破绽 第一种方法：使用一张高度纹理来模拟表面的位移，得到一个修改后的法线值，这种方法也被称为高度映射 另一种方法：使用一张法线纹理，来直接存储表面法线，这种方法也被称为法线映射 第一张方法中，使用一张高度图进行凹凸映射，高度图中存储强度值，用于表示模型表面局部的海拔高度，颜色越浅表明该位置的表面越向外凸起，颜色越深表明该位置的表面越向里凹。· 这种方法的好处是很直观，问题在于计算得更加复杂，在实时计算时不能直接得到表面法线，而是需要由像素的灰度值计算得到，因此也会消耗更多性能。· 高度图通常会和法线映射一起使用，用于给出表面凹凸的额外信息，也就是我们通常会使用法线映射来修改光照：nor &#x3D; 2pi - 1 （需要模型空间一致）· 根据变换空间的不同，分为两种：· Bump是Unity内置的法线纹理，当我们没有提供任何的法线纹理时，Bump就对应模型自带的法线信息，而BumpScale则是用来控制凹凸的程度，当它为0时代表该法线纹理不会对光照产生任何的影响· 多了tangent语义，它告诉Unity把顶点的切线方向填充到这里，和法线方向的normal不同，tangent是float4类型而非float3，因为我们需要使用tangent.w的分量来决定切线空间中的第三个坐标轴，负切线的方向· v2f需要在顶点着色器中计算切线空间下的光照和视角方向，因此添加了lightDir和viewDir存储变化后的光照和视角方向· &#x2F;&#x2F; uv的xy分量来保存纹理坐标，zw保存高度纹理坐标,减少了插值寄存器的使用，这样我们只计算和存储一个纹理坐标就可以了&#x2F;&#x2F; 法线、切线坐标变换&#x2F;&#x2F; 计算负切线时使用w。因为与切线和法线都垂直的方向有两个，w决定了用哪个方向· TANGENT_SPACE_ROTATION;加在o.lightDir&#x3D;……上&#x2F;&#x2F; 借助变换矩阵计算得到模型空间下的光照和视角方向，再借助该矩阵变换到切线空间中的光照和视角方向· 在片元着色器中得到切线空间下的法线方向和视角方向· 再借助tex2D对BumpMap采样· 在法线纹理中存储的是 把法线经过映射后得到的像素值· &#x2F;&#x2F; 做反映射&#x2F;&#x2F; 控制凹凸得到实际的xy分量&#x2F;&#x2F; 由于法线是单位矢量，所以z分离可以用xy得到，因为x^2+y^2+z^2&#x3D;1&#x2F;&#x2F; 贴图部分 得到纹素值 albedo、ambient&#x2F;&#x2F; 之后得到漫反射、高光反射 第二种方法：在世界空间下计算，需要在片元着色器中把法线方向从切线空间变换到世界空间下· 要使v2f中包含从切线空间到世界空间的变换矩阵，在一个插值寄存器最多只能储存float4大小的变量，对于矩阵这样的变量可以按行拆成多个变量进行存储· Bumpiness控制凹凸程度· Filtering哪种方式计算凹凸程度 渐变纹理 遮罩纹理"},{"title":"在Unity中制作MMD舞蹈视频","date":"2022-08-20T09:43:43.000Z","url":"/2022/08/20/UnityMMDCreateTutorial/","tags":[["Unity","/tags/Unity/"],["文档","/tags/%E6%96%87%E6%A1%A3/"]],"categories":[["教程文档","/categories/%E6%95%99%E7%A8%8B%E6%96%87%E6%A1%A3/"]],"content":"&emsp;准备工作 创建工程。这里我用的是2019.4.31f1c1版本，有较好的插件兼容性 导入自己的场景和人物模型 导入插件包： Dynamic Bone 1.2.0即动骨插件，建议使用高版本，方便后续替换成PhysBone VRCSDK3-AVATAR-2021.11.24.16.20_PublicVRC官网下，建议使用高版本，方便后续替换成PhysBone VRC工具箱v1.2.5_by如梦来自B站 ，必须最后导入否则报错 布置场景 处理MMD文件 导入vmd模型动作文件 导入vmd镜头动作文件，并在文件名后面加上.bytes，即 xxx.vmd.bytes 导入音乐文件 使用菜单中的VRC工具箱 —— MMD动作转换 转换获得动作（不含表情） 复制一份动作出来方便修改k帧（不复制出来的是只读），取消勾选Bake Into Pose 创建 Animator Controller并给角色加上，增加一个Layer用来放表情动画，并加上Mask保险 导入MMD4UnityTools插件，用处是获得表情动画 下载地址： 导入完插件后修改MMDExtensionsEditor第300行附近的代码其中var chara &#x3D; GameObject.Find(“Body”); 是获取表情的形态键所在的游戏物体以下为我的目录结构，仅供参考 修改完后就能够右键vmd文件创建表情动作了 将表情动作加到Animator中，双击点开表情动作，再点击场景中的人物模型，再在左上角下拉框选择表情动作，会发现下面的Missing提示这时只需手动按形态键名字添加上再复制关键帧即可只有一帧的关键帧可以先删除批量添加操作为：Ctrl按住+左键加选，选完后右键Add添加完后删除最后一帧，Ctrl+C复制Missing的所有帧，选中新添加的所有第一帧，Ctrl+V粘贴即可 添加相机动画：只需一个脚本，视频教程：不想看可忽略，继续看下文以下为该脚本 说明：其中有部分内容是经过我修改过的，在此指出： 将该脚本添加到下图所示物体上，并按对应的命名来设置相机的目录结构，VMDCAM为空节点，Camera为正常的主相机并为脚本附上对应的物体：.bytes文件、节点、相机、人物模型16. 最后为相机加上Audio Source组件加上音乐就完成啦17. 最后的最后推荐一个AssetStore的资源，叫做Unity Recorder，它能在运行游戏时帮你录制Game窗口的画面，并能直接录制4K画质，使用方便教程： 注： PhysBone比Dynamic Bone的物理性能高10倍； 最终若想发布则不能使用PhysBone因为需配合VRCSDK一起使用，而VRCSDK无法导出； 可以移除VRCSDK后再导出，当然也只能使用Dynamic Bone了。 更新 2023&#x2F;11&#x2F;21更新 更新相机脚本，使相机不会离模型过远，完整脚本： 附加记录一个类似Scene窗口的相机控制脚本： 项目主要控制器脚本： "},{"title":"性能优化(8)编辑器创建资源优化(1)——场景","date":"2022-08-19T06:12:01.000Z","url":"/2022/08/19/performanceOptimization-8/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&emsp; "},{"title":"性能优化(7)Unity工作流(2)——资源导入工作流","date":"2022-08-19T04:22:23.000Z","url":"/2022/08/19/performanceOptimization-7/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&emsp; 资源导入工作流的三种方案 手动编写工具 利用Presets功能 利用AssetGraph工具 一、手动编写工具· 所有资源都有对应的OnPreprocessXXX接口，会在资源被导入时调用，也是我们修改资源导入设置的最佳时机· 在这个接口下我们会拿到导入资源的Importer接口，修改它的导入设置属性即可完成对导入设置的修改· 伪代码：· 虽然通过这个对象接口修改资源导入很直接简单，但还需要思考几个问题：· 1.同类型资源也有不同的设置，我们通过一套代码怎么能实现多套配置呢，显然我们不可能将所有配置通过代码分支判断来完成，这就要通过不同文件夹对不同配置的相同类型资源进行区分；或者通过文件名区分。这样我们的导入设置工具就还需要对路径进行管理，并要做表达式或通配符的资源搜索管理。· 还需要对导入资源设置做持久化，可以利用继承ScriptableObject对象来持久化设置完成。也可以通过Preset来完成· 2.即使完成了对资源的导入设置，后续在编辑过程中，仍可能对其进行修改，或者由于其他开发者误操作导致资源设置发生变化。这时该怎么办呢？· 大部分开发者是将导入工作流与打包发布工作流结合起来，就是在打包发布前对导入设置重新进行检查设置。但这样有一个弊端，就是：某些错误或性能问题只有到真包上才会发现，而我们希望在编辑器模式下能够立即处理来避免误操作修改。这就要引出一个新对象：AssetsModifiedProcessor 二、利用Preset· Presets的保存与应用：· 1. 在我们创建好一个游戏对象后，在其Inspector组件界面中，所有组件的右上角都有3个按钮· 2. 点击中间的按钮，我们可以将当前组件的属性通过Save current to…按钮序列化成Asset，并在下一次打开该按钮后应用此组件设置到游戏对象上· 同样资源的导入设置也可以持久化成Presets· 3. 我们还可以将Presets资源添加到资源设置中的Preset Manager中，这样在下次创建该对象组件或导入新资源时，都可以将该组件Presets或资源导入设置应用到新的对象或新资源上· 因此我们可以在Preset Manager中根据资源类型和不同的需求添加多个Preset来完成资源导入设置· 在Preset Manager中还可以为每一个Preset添加高级过滤搜索选项· 解决导入后的人为修改导入设置，或误操作导致设置变化的问题：· 利用之前提到的AssetsModifiedProcessor资源变化后调用的回调接口重新设置导入设置，只需将文档中提供的代码放到Editor文件夹下，同时删除Preset Manager中的默认预设，并将Presets放到对应资产文件夹中即可 三、AssetGraph工具· 从Unity Github官方仓库中搜索AssetGraph，并通过PakageManager下载安装· 并通过Unity下的Windows菜单 —— AssetGraph —— Open Graph Editor打开AssetGraph编辑器，并创建一个默认的AssetGraph资源· 这时我们可以向其中添加各种资源处理节点· 最常用的流程示例：加载资源目录节点 —— 过滤节点 —— 分组节点 —— （导入设置复写节点） —— 打包配置节点 —— 打包执行节点与输出节点· 可以勾选菜单中Use As Postprocessor来检测新资源导入的回调流程，并可以通过Execute按钮执行整个资源处置流程· 当然也可以删除后续节点，只运行到资源导入设置复写节点，来完成导入工作流 "},{"title":"Unity Shader入门精要 第六章","date":"2022-08-18T02:20:06.000Z","url":"/2022/08/18/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-5/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"Unity中的基础光照 6.1.1 光源 6.1.2 吸收和散射 光线由光源发射出来后，就会与一些物体相交。通常，相交的结果有两个：· 散射（scattering）· 吸收（absorption） 6.1.3 着色6.1.4 BRDF光照模型 6.2 标准光照模型 把进入到摄像机内的光线分为4个部分，每个部分使用一种方法来计算贡献度，分为 环境光、自发光、漫反射、高光反射 6.2.5 6.3 6.4 在Unity Shader中实现漫反射光照模型 6.5 实现高光反射光照模型 6.6使用Unity内置的函数"},{"title":"性能优化(6)Unity工作流(1)——工程目录与Assets目录设置","date":"2022-08-17T04:40:55.000Z","url":"/2022/08/17/performanceOptimization-6/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"Unity中的工作流优化 项目的工程结构 Asset文件夹 Library文件夹· 一般较大，主要是unity编辑器内部使用，不需要将此文件夹参与到代码托管中。每台机器在项目导入时生成的也有可能有差异，一般合作开发时，编辑器使用出现问题时，清理此文件夹并重新生成，可能会解决一些由于缓冲产生的问题。在以后你使用编辑器无法打开工程或打开工程出错时，不妨删除此文件夹重新生成看一看 Project Settings文件夹与UserSettings文件夹都建议托管到代码工程中 Temp文件夹与Logs文件夹都不需要进行代码托管 Unity Assets目录中的特殊文件夹及用途 Editor文件夹：主要用来存放编辑器下使用的一些脚本和资源，一般用来扩展Unity编辑器使用，不会发布到应用程序中，也不会在运行时运行 Editor Default Resources文件夹：用来存储编辑器下的一些默认资源，这些资源只能通过EditorGUIUtility.Load函数按需进行加载 Gizmos文件夹：用来存储编辑器中的特殊对象图标，用来标记特殊对象或位置，Gizmos允许将图形添加到Scene视图中，以帮助可视化不可见的设计细节。同样也不会发布到运行时 Plugins文件夹：用来存储扩展Unity功能的插件，包括C和C++编写的Native DLL Resources文件夹：· 用来存储一些原型设计时可以从脚本中按需加载的资源，通过Resource.Load接口加载此类资源，Assets文件夹中可以添加多个Resources文件夹。同样也可以是Editor文件夹的子文件夹，但其中的资源需要通过Editor脚本进行加载，并会从构建发布中剥离· 值得注意的是，Resources文件夹通常是Unity项目中性能问题的主要来源。使用不当很容易造成Unity项目构建出现膨胀，导致内存消耗过高、应用程序启动时间显著增加、应用程序包体过大等问题。强烈建议在正式项目中，不要使用Resources目录，应尽量使用AssetsBundle方式进行构建和加载资源 Standard Assets文件夹：用来存放导入的标准资源包，这个文件夹内的脚本编译优先级最高。一般情况下很少使用到此文件夹（根目录唯一） StreamingAssets文件夹：用来存放不随应用程序构建而希望独立于原始文件格式提供的资源，如单独的视频等流媒体文件。此文件夹内的文件可以按原样复制到目标计算机中，然后通过特定的文件夹单独访问该文件（根目录唯一） 补充: ScriptTemplates文件夹：脚本模板文件夹，与编辑器文件夹下Editor\\Data\\Resources\\ScriptTemplates文件夹同名，编辑器下的该文件夹内存放的是所有编辑器可调用的脚本模板 而编辑器下的该文件夹，会随unity编辑器的更新而重置，所以需要把自己的模板放在Asset下的ScriptTemplates文件夹内 Assets目录结构设计 合理的文件夹结构有助于资源分类、工作流优化与AssetsBundle资源的打包 根据项目大小不同、游戏类型的不同往往设计上也存在差异，并不能完全做到标准化。但在设计上还是有一些原则可以帮助搭建比较合理的目录结构 "},{"title":"性能优化(5)静态资源优化——动画导入设置","date":"2022-08-17T03:34:46.000Z","url":"/2022/08/17/performanceOptimization-5/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"&emsp; 模型导入设置中的Rig标签 在没有动画的模型导入时，在Animation Type使用None标签 在带动画的模型导入时： 骨骼框架优化的关键选项 Skin Weights 代表骨骼动画蒙皮顶点最多同时受几根骨骼影响 Optimize Bones Optimize Game Objects 模型导入设置中的Animation标签 这里的选项会随模型的动画文件类型有所不同，如Bake Animations选项，这个选项只对应于Maya、Max等DCC工具的原始文件格式，并且文件中使用了布料、流体等烘培动画时才有用。如果采用fbx格式，该选项会呈现禁用状态 Resmple Curves Anim.Compression 动画文件压缩的选项· 当使用动画压缩后三种选项时，在下边都会产生Rotation Error、Position Error、Scale Error选项，默认是0.5，代表变化小于这个误差的关键帧会被删除。值越小动画越精确 Animation Custom Properties 动画曲线数据信息 选中Animation Clip时，会有 这么 一段信息： 动画文件导入设置优化后 信息查看原则 看效果差异（与原始制作动画差异是否明显，以肉眼看不出明显差距为准） 看曲线数量（总曲线数量与各种曲线数量，总曲线数量越小越好，常量曲线比重越大越好） 看动画文件大小（在小几百k或更少合理，超过1M以上的动画文件考虑是否合理） "},{"title":"Unity Shader入门精要 第五章","date":"2022-08-16T06:46:21.000Z","url":"/2022/08/16/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-4/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":" 今天开始正式学习代码部分，将挑重要部分记录 初级篇大部分shader无法直接用在真实项目上，只是阐述原理的实现 创建一个最简单的shader 命名为5-2 修改代码为初始状态 写上Pass 模型的数据从哪里来 定义结构体 Unity提供的内置文件和变量 位置：…\\Editor\\Data\\CGIncludes CG&#x2F;HLSL语义 Debug与渲染平台的差异 Shader整洁之道 "},{"title":"性能优化(4)静态资源优化——纹理导入设置","date":"2022-08-15T05:20:58.000Z","url":"/2022/08/15/performanceOptimization-4/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"纹理设置 Texture Shape· 2D 最常用的2D纹理，默认选项· Cube —般用于天空和与反射探针，默认支持DefaultNormal Single Channel几种类型纹理，可以通过Assets &gt; Create &gt; Legacy &gt; Cubemap生成，也可以通过C#代码Camera.RenderToCubemap在脚本中生成· 2D Array 2D纹理数组，可以极大提高大量相同大小和格式的纹理访问效率，但需要特定平台支持，可以通过引擎Svstemlnfo.supports2DArrav Textures接口运行时查看是否支持· 3D 通过纹理位图方式存储或传递一些3D结构化数据，一般用于体积仿真，如雾效、噪声、体积数据、距离场、动画数据等信息，可以外部导入，也可运行时程序化创建 Alpha Source· 默认选择Input Texture Alpha就好，如果确定不使用原图中的Alpha通道，可以选择None。另外From Gray Scale我们一般不会选用 Alpha Is Transparency· 指定Alpha通道是否开启半透明，如果位图像素不关心是否要半透明可以不开启此选项。这样Alpha信息只需要占1bit。节省内存 Ignore Png file gamma· 是否忽略png文件中的gamma属性，这个选项是否忽略取决于png文件中设置不同gamma属性导致的显示不正常，一般原图制作流程没有特殊设置，这个选项一般默认就好 Advanced选项 Non-Power of 2· 非2的幂次方选项，与原始文件的纹理大小有关，保持默认就好 Read&#x2F;Write· 开启会导致纹理内存使用量增加一倍· 脚本逻辑中需要动态读写该纹理时，需要打开此选项 Streaming Mipmaps与Virtual Texture Only· 一般保持默认，以后再介绍 Generate Mip Maps· 什么时候不需要生成MipMaps：· 1. 2D场景· 2. 固定视角，摄像机无法缩放远近 Border Mip Maps 默认不开启，只有当纹理是Light Cookies类型时，开启此选项来避免colors bleedinq现象导致颜色滲透到较低级别的Mip Level纹理边缘上 Mip Map Filtering· Box 最简单，随尺寸减小，Mipmap纹理变得平滑模糊· Kaiser，避免平滑模糊的锐化过滤算法 Mip Maps Preserve Coverage 只有需要纹理在开启mipmap后也需要做Alpha Coverage时开启。默认不开启 Fadeout Mip Maps 纹理Mipmap随Mip层级淡化为灰色，一般不开启，只有在雾效较大时开启不影响视觉效果 Wrap Mode、Filter Mode、Aniso Level 选择合适纹理过滤的最佳经验：（放到导入设置）· 使用双线性过滤平衡性能和视觉质量· 有选择地使用三线性过滤，因为与双线性过滤相比，它需要更多的内存带宽· 使用双线性和 2x 各向异性过滤，而不是三线性和 1x 各向昇性过滤，因为这样做不仅视觉效果更好，而且性能也更高· 保持较低的各向异性级别。仅对关键游戏资源使用高于 2 的级别 Filter Mode· 从上往下性能消耗变大，质量变好· Point：使用最近的滤波，在放大缩小时，采样像素通常只有一个，因此图像看起来会有种像素的风格· Bilinear：使用了线性的滤波，对于每个目标像素，它会找到4个临近像素进行线性插值混合后得到最终的像素，从而导致最终图像看起来有点模糊了· Trilinear：几乎和Bilinear一样，只是Trilinear还会在多级渐远纹理之间进行一个混合，多级渐远纹理技术是将原纹理提前用滤波处理来得到很多更小的图像，形成一个图像金字塔，每一层都是对上一层的图像降采样的结果，需要在实时运行时快速得到像素，但也会额外多占用33%的内存。· 一般使用Bilinear模式 各平台的默认纹理压缩格式详细细节：官方文档"},{"title":"性能优化(3)静态资源优化——纹理基础概念","date":"2022-08-15T04:33:27.000Z","url":"/2022/08/15/performanceOptimization-3/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"纹理基础概念 纹理类型 Default：默认的纹理类型格式 Normal map：法线贴图，可将颜色通道转换为适合实时法线贴图格式 Editor GUI and Legacy GUI：在编辑器GUI控件上使用纹理请选择此类型 Sprite(2D and UI)：在2D游戏中使用的精灵（Sprite）或UGUI使用的纹理请选择此类型 Cursor：鼠标光标自定义纹理类型 Cookie：用于光照Cookie剪影类型的纹理 Lightmap：光照贴图类型的纹理，编码格式取决于不同的平台 Single Channel：如果原始图片文件只有一个通道，请选择此类型 纹理大小 纹理的大小直接影响内存与显存占用的大小，同时对GPU纹理采样、CPU加载和带宽造成影响 选择合适纹理大小应尽量遵循以下经验：· 不同平台、不同硬件配置选择不同的纹理大小，Unity下可以采用bundle变体设置多套资源、通过Mipmap限制不同平台加载不同level层级的贴图· 根据纹理用途的不同选择不同的纹理加载方式，如流式纹理加载Texture Streaming、稀疏纹理Sparse Texture、虚拟纹理VirtualTexture等方式· 不能让美术人员通过增加纹理大小的方式增加细节，可以选择细节贴图DetailMap或增加高反差保留的方式· 在不降低视觉效果的情况下尽量减小贴图大小，最好的方式是纹理映射的每一个纹素的大小正好符合屏幕上显示像素的大小，如果纹理小了会造成欠采样，纹理显示模糊；如果纹理大了会造成过采样，纹理显示噪点。这一点做到完美很难保障，充分利用SceneView -&gt; DrawMode -&gt; Mipmap来查看在游戏摄像机视角下哪些纹理过采样，哪些纹理欠采样来调整纹理大小· 现代显卡对纹理的支持为2的幂次方，如1024x1024、512x256,不要求长宽相等，只要求长宽大小为2的幂次即可。不符合大小的纹理，Unity在导入时会自动设置成最小符合2的幂次方的大小，但这样的设置一定会造成纹理大小的浪费 纹理颜色空间 只需了解一下，知道纹理导入选项中的sRGB选项什么时候开启什么时候关闭即可 默认大多数图像处理工具都会使用sRGB颜色空间处理和导出纹理。但如果你的纹理不是用作颜色信息的话，那就不要使用SRGB空间，如金属度贴图、粗糙度贴图或者法线贴图等。一旦这些纹理使用SRGB空间会造成视觉表现错误 纹理压缩 纹理压缩是指图像压缩算法，保持贴图视觉质量的同时，尽量减小纹理数据的大小。默认情况下我们的纹理原始格式采用PNG或TGA这类通用文件格式，但与专用图像格式相比他们访问和采样速度都比较慢，无法通用GPU硬件加速，同时纹理数据量大，占用内存较高。所以在渲染中我们会采用一些硬件支持的纹理压缩格式，如ASTC 、ETC、ETC2、DXT等 纹理图集 是一系列小纹理图像的集合 优点：· 一是采用共同纹理图集的多个静态网格资源可以进行静态合批处理，减少DrawCall调用次数· 二是纹理图集可以减少碎纹理过多，因为他们打包在一个图集里，通过压缩可以有效的利用压缩，隆低纹理的内存成本和冗余数据 缺点· 美术需要合理规划模型，并且要求模型有相同的材质着色器，或需要制作通道图去区分不同材质。制作和修改成本较高 纹理过滤 纹理的Mipmap 逐级减少分辨率来保存纹理副本，可以理解为纹理的LOD层级。渲染纹理时，将根据像素在屏幕中占据的纹理空间大小选择合适的Mipmap级别进行采样 优点：· GPU不需要在远距离上对对象进行全分辨率纹理采样，因此可以提高纹理采样性能· 同时也解决了远距离下的过采样导致的噪点问题，提高了纹理渲染质量 缺点：· 由于Mipmap纹理要生成低分辨率副本，会造成额外的内存开销 "},{"title":"Unity Shader入门精要 第四章","date":"2022-08-12T02:27:10.000Z","url":"/2022/08/12/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-3/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"4. 学习Shader所需的数学基础 4.1 背景：描述一个物体的位置4.2 笛卡尔坐标系 4.2.1 二维笛卡尔坐标系· 原点· x轴和y轴· OpenGGL原点在屏幕右下角，往上y+，往右x+· DX原点在左上角，往下y+，往右x+ 4.2.2 三维笛卡尔坐标系· 多一个z轴· 左手坐标系· 右手坐标系 4.2.3 左手坐标系和右手坐标系· 将其中一个轴反向，就可以相互转化 4.2.4 Unity使用的坐标系· 对于观察空间，使用的是右手坐标系· 以摄像机为原点，摄像机前进方向为z轴负方向· z轴的减少意味着场景深度的增加 4.3 点和矢量 4.3.1 点和矢量的区别· 点是n维空间中的一个位置，没有大小，宽度的概念· 矢量是为了和标量区分开，矢量指n维空间中包含了模和方向的有向线段· 通常，矢量用来表示相对于某个点的偏移 4.3.2 矢量运算· 矢量和标量的乘除法 （1，2）x 2 &#x3D;（2，4）· 矢量的加法和减法 （1，2）+（0，2）&#x3D;（1，4）· 矢量的模 （1，2）模为（1^2+2^2）开根号· 单位矢量&emsp;转成单位矢量的过程是归一化&emsp;零矢量· 矢量的点积 —— 投影 (x1,y1)·(x2,y2)&#x3D;x1x2+y1y2 &#x3D;|a||b|cosθ· 矢量的叉积 —— 右手法则判断发现：模长为ab构成的四边形对角&emsp;二维：a x b &#x3D; x1y2-x2y1&emsp;三维：a x b x c &#x3D; y1z2-z1y2-x1z2+z1x2+x1y2-y1x2 （同高数）AxB&#x3D;-(BxA) |AxB|&#x3D;|a||b|sinθ 4.4 矩阵 4.4.1 矩阵定义：由一组数的全体，在括号内排列成m行n列的一个数表，并称它为mxn阵 4.4.2 和矢量联系起来：矢量可以看做列矩阵或者行矩阵 4.4.3 矩阵运算· 矩阵和标量的乘法· 矩阵和矩阵的乘法 4.4.4 特殊的矩阵· 方块矩阵· 单位矩阵· 转置矩阵· 逆矩阵· 正交矩阵 4.4.5 行矩阵还是列矩阵· Unity多把矢量转化为列矩阵来使用 4.5 矩阵的几何意义：变换 4.5.1 什么是变换· 线性变换：保留矢量加和标量乘的变换· 仿射变换：合并线性变换和平移变换的变换类型 4.5.2 齐次坐标· 将三维矢量转换成四位变量· 就可以表示三维的平移操作了 4.5.3 分解基础变换矩阵· 分成四个部分· 左上角表示旋转和缩放· 右上角表示平移· 左下角为0矩阵· 右下角是标量1 4.5.4 平移矩阵· 单位矩阵，右边一列为移动矩阵 4.5.5 缩放矩阵· 先是单位矩阵，前三个为缩放系数值 4.5.6 旋转矩阵· 绕轴旋转 4.5.7 复合变换 4.6 坐标空间 4.6.1 为什么要使用那么多不同的坐标空间· 在顶点着色器流水线阶段，做的就是把模型顶点坐标从模型空间转换到齐次裁剪坐标空间· 一些概念只在特定的坐标空间才有意义 4.6.2 坐标空间的变换· 对坐标机进行平移变换· 平移变换的变换矩阵的前3行和前3列，可以用来对法线方向、光照方向进行空间变换 4.6.3 顶点的坐标空间变换过程· 一个顶点需要经过多个坐标空间才能最终被画在屏幕上，一个顶点最开始是在模型空间中定义的，最后它将会变换到屏幕空间中，得到真正的屏幕像素坐标 4.6.4 模型空间· 模型空间（model space），是和某个模型或者说是对象有关的。有时模型空间也被称为对象空间（object space）或局部空间（local space）。每个模型都有自己独立的坐标空间，当它移动或旋转的时候，模型空间也会跟着它移动和旋转· 在模型空间中，我们经常使用一些方向概念，例如”前（forward）””后（back）””左（left）””右（right）””上（up）””下（down）” 4.6.5 世界空间· 世界空间（world space）是一个特殊的坐标系，世界空间可以被用于描述绝对位置。在本书中，绝对位置指的就是在世界坐标系中的位置· 在Unity中，世界空间同样使用了左手坐标系· 但它的x轴、y轴、z轴是固定不变的。在Unity中，我们可以通过调整Transform组件中的Position属性来改变模型的位置，这里的位置指的是相对于这个Transform的父节点（parent）的模型坐标空间中的原点定义的，如果一个Transform没有任何父节点，那么这个位置就是在世界坐标系中的位置· 我们可以想象成还有一个虚拟的模型，这个根模型的模型空间就是世界空间，所有的游戏对象都附属于这个根模型。同样，Transform中的Rotation和Scale也是同样的道理· 顶点变换的第一步，就是将顶点坐标从模型空间变换到世界空间中。这个变换通常叫做模型变换（model transform） 4.6.6 观察空间· 观察空间（view space）也被称为摄像机空间（camera space）· 观察空间和屏幕空间是不同的。观察空间是一个三维空间，而屏幕空间是一个二维空间。从观察空间到屏幕空间的转换需要经过一个操作，那就是投影（projection）· 顶点变换的第二步，就是将顶点坐标从世界空间变换到观察空间中。这个变换通常叫做观察变换（view transform）· 1. 一种方法是计算观察空间的三个坐标轴在世界空间下的表示，然后构建出从观察空间变换到世界空间的变换矩阵，再对该矩阵求逆来得到从世界空间变换到观察空间的变换矩阵· 2. 另一种方法，即想象平移整个观察空间，让摄像机原点位于世界坐标的原点，坐标轴与世界空间中的坐标轴重合即可。这两种方法得到的变换矩阵都是一样的，不同的只是我们思考的方式 4.6.7 裁剪空间· 顶点接下来要从观察空间转换到裁剪空间（clip space，也被称为齐次裁剪空间）中，这个用于变换的矩阵叫做裁剪矩阵（clip matrix），也被称为投影矩阵（projection matrix）· 视锥体有两种类型，这涉及两种投影类型：· 1. 一种是正交投影（orthographic）：· 1.1 在透视投影中，地板上的平行线并不会保持平行，离摄像机越近网格越大，反之相反· 1.2 可以注意到，透视投影模拟了人眼看世界的方式· 1.3 因此，在追求真实感的3D游戏中我们往往会同透视投影· 2.一种是透视投影（perspective projection）· 2.1 而在正交投影中，所有的网格大小都一样，而且平行线会一直保持平行· 2.2 而正交投影则完全保留了物体的距离和角度· 2.3 而在一些2D游戏或渲染小地图等其他HUD元素时，我们会使用正交投影 透视投影· 在视锥体的6块裁剪平面中，有2块比较特殊，分别为近裁剪平面（near clip plane）和远裁剪平面（far clip plane）—— 通过一个投影矩阵把顶点转换到一个裁剪空间中 —— 首先是为投影做准备、齐次是对x、y、z分量进行缩放· 我们可以通过Camera组件的Field of View（简称FOV）属性来改变视锥体竖直方向的张开角度，而Clipping Planes中的Near和Far参数可以控制视锥体的近裁剪平面和远裁剪平面距离摄像机的远近· 在Unity中，一个摄像机的横纵比由Game视图的横纵比和Viewport Rect中的W和H属性共同决定· 根据已知的Near、Far、FOV、和Aspect的值来确定透视投影的投影矩阵 正交矩阵· 首先看一下正交投影中的6个裁剪平面是如何定义的· 正交投影的视锥体是一个长方体· 可以通过Camera组件的Size属性来改变视锥体竖直方向上高度的一半，而Clipping Planes中的Near和Far参数可以控制视锥体的近裁剪平面和远裁剪平面距离摄像机的近· 我们可以通过摄像机的横纵比得到横向信息Aspect 4.6.8 屏幕空间·屏幕空间是一个二维空间，因此我们必须把顶点从裁剪空间投影到屏幕空间中，来生成对应的2D坐标·首先，我们需要进行标准齐次除法（homogeneous division），也被称为透视除法（perspective division） —— 经过齐次除法后，透视投影和正交投影的视锥体都变换到一个相同的立方体内。在Unity中，从裁剪空间到屏幕空间的转换是由底层帮我们完成的。我们的顶点着色器只需要把顶点转换到裁剪空间即可· 根据变换后的x和y坐标来映射输出窗口的对应像素坐标 4.6.9 总结· 只有在观察空间中Unity使用了右手坐标系 4.7 法线变换 法线（normal），也被称为法矢量（normal vector） 切线（tangent），也被称为切矢量（tangent vector） 4.8 4.9 "},{"title":"性能优化(2)静态资源优化——模型","date":"2022-08-11T06:42:38.000Z","url":"/2022/08/11/performanceOptimization-2/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"模型的导入 尽可能使用fbx格式导入 优化原始导入模型文件。删除不需要的数据· 统一单位· 导出的网格必须是多边形拓扑，不能是贝塞尔曲线、样条曲线、细分曲面等，Unity不支持· 在导出之前确保所有Deformers都烘焙到网格模型上· 不建议模型使用的纹理随模型导出· 如果需要导入Blend shape normals时，必须指定光滑组Smooth groups· 建议导出时不携带如摄像机、灯光、材质等场景信息 原始模型对性能的影响点· 最小化面数，不需要微三角形面，三角面尽量分布均匀· 合理的拓扑结构与平滑组，尽可能是闭包· 尽量少的材质个数· 尽可能少的蒙皮网格· 尽可能少的骨骼数量· FK与IK节点分离，导出时删除IK骨骼节点 &emsp;以上主要是DDC模型导出需要注意的，美术人员需要注意的设置&emsp;下面为导入unity后的设置 在导入模型的Model选项卡下，Scene中，这些选项在没有特殊要求时可以不开启：Import BlendShaps、Import Visibility、Import Cameras、Import Lights Mesh Compression选项：· 默认为不开启· 在保证网格准确的情况下可以采用更激进的压缩方式· 可以时网格占用的磁盘空间更小，但运行时占用的内存不会变小· 开启后需要真正看一看模型有无问题，一般闭包的模型比开放式模型出现问题的概率更小 Read&#x2F;Write选项· 禁用与开启读写选项· 启用后会在内存中额外复制一份此网格，一个副本保存在内存中，另外一个会保存在GPU显存中· 只有在运行时需要修改网格数据时才开启此选项· SkinMesh需要开启此选项来做动画· 剩下绝大多数情况需要确保此选项关闭以节省内存 Optimize Mesh和Generate Colliders选项· 一般保持默认设置，除非需要禁止优化，或者确切得需要做网格体碰撞· 启用 Generate Colliders 后，Unity会在您将网格添加到场景中时自动添加一个网格碰撞体，以便物理系统将其视为实体· 如果游戏对象正在移动（例如汽车），则无法使用网格碰撞体。必须改用原始碰撞体。此情况下应禁用 Generate Colliders 设置 几何体信息设置（Geometry）： Index Format选项· 如果确认网格顶点数不超过65535可以使用16位索引 如果确认不使用法线或切线，可以尝试关闭 如果不需要光照烘焙，可以关闭光照贴图的第二套UV生成 另外，在Project Settings —— Player下，Optimization下： Vertex Compression选项：设置每个通道的顶点压缩，可为模型除位置、光照、贴图、UV之外所有内容启动压缩 Optimize Mesh Data选项：开启后可根据网格使用的材质删除不需要的数据，如材质中没有使用到的切线、法线、颜色、UV等 无动画的模型需要在导入设置中的Animation标签下的Import Animation选项设置为关闭，并将Materials标签下的Meterial Creation Mode设置为None "},{"title":"性能优化(1)静态资源优化——音频","date":"2022-08-11T04:57:40.000Z","url":"/2022/08/11/performanceOptimization-1/","tags":[["Unity","/tags/Unity/"],["性能优化","/tags/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"参考了B站up Metaverse大衍神君 的视频所做的记录 资源的优化 Assets工作流程：导入——创建——构建——分发——加载 关于资源的优化，也从这五步着手 外部导入资源：模型网格Mesh、纹理、音乐音效、字体动画、视频等。 内部创建资源：Prefab、Animation Controller、Timeline、RenderTexture、ParticleSystem、VFX等 无论哪种资源都需要涉及到Unity导入问题 在不同平台下，合理的资源导入设置与资源规格，可以给应用程序带来较高的效率 音频资源 Force To Mono选项：强制将双声道的音频改为单声道。当左右两声道音频完全相同时，开启此选项可以在内容不丢失的情况下，减小内存和大小，尤其是在移动平台 一般来说，尽可能得使用未压缩的wav文件作为音频源文件 在移动平台大多数采用Vorbis压缩方法 如果音乐不打算循环也可使用MP3格式 一些操作系统对特定的格式有额外优化，如IOS上可以使用MP3格式 对简短常用的音效可以使用ADPCM格式，这种格式可能压缩比不是最好的，但在播放过程中解码速度很快 还需要关注音频文件的采样率 · 一般移动平台建议设置为22050Hz · 通常我们在移动平台都会选择对音质影响最小的最低设置 可以通过Sample Rate Setting选项修改默认的采样频率 越低的采样频率生成的导入文件越小 Load Type加载类型 影响的是Unity工作流中的第五步：加载 · 默认是Decompress On Load，这个选项一般对应音频压缩后，大小小于200KB的音效文件 · 如果大于200KB，则推荐使用Compressed In Memory · 如果是背景音乐文件或者较长较大的文件，推荐使用Streaming，通过流式加载避免载入时卡顿 当游戏需要静音时，不要简单得将音量设置为0，应该销毁音频（Audio Source）文件，将其从内存中完全卸载 音乐音效一般不会成为优化的瓶颈，但可以减小内存的使用和安装文件的大小，使用第三方的和带有复杂逻辑的除外 "},{"title":"Unity Shader入门精要 第三章","date":"2022-08-09T13:37:57.000Z","url":"/2022/08/09/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-2/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"3. Unity Shader基础 3.1.1 材质和Unity Shader 在Unity中，需要配合使用材质Material和Unity Shader才能达到需要的效果 流程：1.创建一个材质2.创建一个Unity Shader，并把它赋给上一步创建的材质3.把材质赋给要渲染的对象4.在材质面板中调整Unity Shader的属性，以得到满意的效果 3.1.2 Unity中的材质 Unity中的材质需要结合一个GameObject的Mesh或者Particle System组件来工作，它决定了我们的游戏对象看起来是什么样子的 3.1.3 Unity中的Shader 为了和前面通用的Shader语义进行区分，这里把Unity中的Shader文件统称为Unity Shader Unity Shader和我们之前提及的渲染管线的Shader有很大不同 Unity中4种Shader模板：1.Standard Surface Shader：产生一个包含标准光照模型的表面着色器模板2.Unlit Shader：产生一个不包含光照的基本的顶点&#x2F;片元着色器3.Image Effect Shader：实现各种屏幕后处理效果4.Compute Shader：产生一个特殊的Shader文件，旨在利用GPU的并行性来进行一些与常规渲染流水线无关的计算（此书不讨论） Unity会显示Shader的相关信息：· 是否是一个表面着色器· 是否是一个固定函数着色器——Fixed Function Shader· 还有一些标签设置：是否会投射阴影、使用的渲染队列、LOD值 Show generated code· 打开一个新的文件，在该文件里面将显示Unity在背后为该表面着色器生成的顶点&#x2F;片元着色器· 方便对生成的代码进行研究，需要复制到新的Unity Shader中才可保存 Compile and show code· 可以让开发者检查该Unity Shader针对不同图像编程接口编译成的Shader代码 3.2 Unity Shader的基础：ShaderLab 在Unity Shader的帮助下，开发者只需要使用ShaderLab来编写Unity Shader文件就可以完成所有工作 3.3 Unity Shader的结构3.3.1 给我们的Shader起个名字 每一个Unity Shader文件的第一行都需要通过Shader语义来指定该Unity Shader的名字 这个名字由一个字符串来定义，例如”MyShader” 当为材质选择使用的Unity Shader时，这些名称就会出现在材质面板的下拉列表里 通过在字符串中添加斜杠（”&#x2F;“），可以控制Unity Shader在材质面板中出现的位置 3.3.2 材质和Unity Shader的桥梁：Properties Properties语义块中包含了一系列属性（property），这些属性将会出现在材质面板中 开发者们声明这些属性是为了在材质面板中能够方便地调整各种材质属性 Int —— number —— _Int (“Int”,Int) &#x3D; 2 Float —— number —— _Float (“Float”,Float) &#x3D; 1.5 Range(min,max) —— number —— _Range (“Range”,Range(0.0,5.0)) &#x3D; 3.0 Color —— (number,number,number,number) —— _Color (“Color”,Color) &#x3D; (1,1,1,1) Vector —— (number,number,number,number) —— _Vector (“Vecter”,Vector) &#x3D; (2,3,6,1) 2D —— “defaulttexture” {} —— _2D (“2D”,2D) &#x3D; “” {} Cube —— “defaulttexture” {} —— _Cube (“Cube”,Cube) &#x3D; “white” {} 3D —— “defaulttexture” {} —— _3D (“3D”,3D) &#x3D; “black” {} 3.3.3 重量级成员：SubShader 每一个Unity Shader文件可以包含多个SubShader语义块，但最少要有一个 当Unity需要加载这个Unity Shader时，Unity会扫描所有的SubShader语义块，然后选择第一个能够在目标平台上运行的SubShader 如果都不支持的话，Unity就会使用Fallback语义指定的Unity Shader Unity提供这种语义的原因在于，不同的显卡具有不同的能力 · SubShader中定义了一系列Pass以及可选的状态（[PenderSetup]）和标签（[Tag]）设置· 每个Pass定义了一次完整的渲染流程，但如果Pass的数目过多，往往会造成渲染性能的下降 常见的渲染状态设置选项：· Cull —— Cull Back | Front | Off —— 设置剔除模式：剔除背面&#x2F;正面&#x2F;关闭剔除· ZTest —— ZTest Less Greater | LEqual | GEqual | Equal | NotEqual | Always —— 设置深度测试时使用的函数· ZWrite —— ZWrite On | Off —— 开启&#x2F;关闭深度写入· Blend —— Blend SrcFactor DstFactor —— 开启并设置混合模式 SubShader的标签（Tags）是一个键值对（Key&#x2F;Value Pair），它的键和值都是字符串类型 SubShader的标签类型：· Queue —— 控制渲染顺序，指定该物体属于哪一个渲染队列，通过这种方式可以保证所有的透明物体可以在所有不透明物体后面被渲染（详见第8章），我们也可以自定义使用的渲染队列来控制物体的渲染顺序 · RenderType —— 对着色器进行分类，例如这是一个不透明的着色器，或是一个透明的着色器等。这可以被用于着色器替换（Shader Replacement）功能 · DisableBatching —— 一些SubShader在使用Unity的批处理功能时会出现问题，例如使用了模型空间下的坐标进行顶点动画（详见11.3节）。这时可以通过该标签来直接指明是否对该SubShader使用批处理 · ForceNoShadowCasting —— 控制使用该SubShader的物体是否会投射阴影（详见8.4节） · IgnoreProjector —— 如果该标签值为”True”，那么使用该SubShader的物体将不会受Projector的影响，通常用于半透明物体 · CanUseSpriteAtlas —— 当该SubShader是用于精灵（sprites）时，将该标签设为”False” · PreviewType —— 指明材质面板将如何预览该材质。默认情况下，材质将显示为一个球形，我们可以通过把该标签的值设为”Plane””SkyBox”来改变预览类型 Pass的标签类型· LightMode —— 定义该Pass在Unity的渲染流水线中的角色 · RequireOptions —— 用于指定当满足某些条件时才渲染该Pass，它的值是一个由空格分隔的字符串。目前，Unity支持的选项有：SoftVegetation。在后面的版本中，可能会增加更多的选项 特殊的Pass· UsePass：如我们之前提到的一样，可以使用该命令来复用其他Unity Shader中的Pass· GrabPass：该Pass负责抓取屏幕并将结果存储在一张纹理中，以用于后续的Pass处理（详见10.2.2节） 3.3.4 留一条后路：Fallback 紧跟在各个SubShader语义块后面的，可以是一个Fallback指令。它用于告诉Unity，”如果上面所有的SubShader在这块显卡上都不能运行，那么就使用这个最低级的Shader吧！” · 我们可以通过一个字符串来告诉Unity这个”最低级的Unity Shader”是谁· 也可以任性地关闭Fallback功能 Fallback还会影响阴影的投射 3.3.5 ShaderLab还有其他的语义吗 就可以使用CustomEditor语义来扩展编辑界面 还可以使用Category语义来对Unity Shader中的命令进行分组 这些命令很少用到，本书不进行深讲 3.4 Unity Shader的形式 3.4.1 Unity的宠儿：表面着色器 表面着色器（Surface Shader）是Unity自己创造的一种着色器代码类型 背后仍旧把它转换成对应的顶点&#x2F;片元着色器 Unity为我们处理了很多光照细节，使得我们不需要再操心这些 表面着色器被定义在SubShader语义块（而非Pass语义块）中的CGPROGRAM和ENDCG之间。原因是，表面着色器不需要开发者关心使用多少个Pass、每个Pass如何渲染等问题，Unity会在背后为我们做好这些事情 CGPROGRAM和ENDCG之间的代码是使用Cg&#x2F;HLSL编写的，也就是说，我们需要把Cg&#x2F;HLSL语言嵌套在ShaderLab语言中 3.4.2 最聪明的孩子：顶点&#x2F;片元着色器 在Unity中我们可以使用Cg&#x2F;HLSL语言来编写顶点&#x2F;片元着色器（Vertex&#x2F;Fragment Shader） 它们更加复杂，但灵活性也很高 和表面着色器类似，顶点&#x2F;片元着色器的代码也需要定义在CGPROGRAM和ENDCG之间，但不同的是，顶点&#x2F;片元着色器是写在Pass语义块内，而非SubShader内的 原因是，我们需要自己定义每个Pass需要使用的Shader代码 3.4.3 被抛弃的角落：固定函数着色器 而对于一些较旧的设备，它们不支持可编程管线着色器，因此，这时候我们就需要使用固定函数着色器（Fixed Function Shader）来完成渲染 可以看出，固定函数着色器的代码被定义在Pass语义中，这些代码相当于pass中的一些渲染设置 对于固定函数着色器来说，我们需要完全使用ShaderLab的语法（即使用ShaderLab的渲染设置命令）来编写，而非使用Cg&#x2F;HLSL 由于现在绝大多数GPU都支持可编程的渲染管线，这种固定管线的编程方式已经逐渐被抛弃 实际上，在Unity5.2中，所有固定函数着色器都会在背后被Unity编译成对应的顶点&#x2F;片元着色器，因此真正意义上的固定函数着色器已经不存在了 3.4.4 选择哪种Unity Shader形式 除非你有非常明确的需求必须要使用固定函数着色器，例如需要在非常旧的设备上运行你的游戏（这些设备非常少见），否则请使用可编程管线的着色器，即表面着色器或顶点&#x2F;片元着色器 如果你想和各种光源打交道，你可能更喜欢使用表面着色器，但需要小心它在移动平台的性能表现 如果你需要使用的光照数目非常少，例如只有一个平行光，那么使用顶点&#x2F;片元着色器是一个更好的选择 最重要的是，如果你有很多自定义的渲染效果，那么请选择顶点&#x2F;片元着色器 3.5 本书使用的Unity Shader形式 本书的目的不仅在于教给读者如何使用Unity Shader，更重要的是想要让读者掌握渲染背后的原理，仅仅了解高层抽象虽然可能会暂时使工作简化，但从长久来看”知其然而不知其所以然”所带来的影响更加深远 因此，在本书接下来的内容中，将着重使用顶点&#x2F;片元着色器来进行Unity Shader的编写 3.6 答疑解惑3.6.1 Unity Shader !&#x3D; 真正的Shader Unity Shader并不等同于第2章中所讲的Shader，尽管Unity Shader翻译过来就是Unity着色器。在Unity里，Unity Shader实际上指的就是一个ShaderLab文件——硬盘上以shader作为文件后缀的一种文件 在传统的Shader中，我们仅可以编写特定类型的Shader，例如顶点着色器、片元着色器等。而在Unity Shader中，我们可以在同一个文件里同时包含需要的顶点着色器和片元着色器代码 在传统的Shader中，我们无法设置一些渲染设置，例如是否开启混合、深度测试等，这些是开发者在另外的代码中自行设置的。而在Unity Shader中，我们通过一行特定的指令就可以完成这些设置 在传统的Shader中，我们需要编写冗长的代码来设置着色器的输入和输出，要小心地处理这些输入输出的位置和对应关系等。而在Unity Shader中，我们只需要在特定语句块中声明一些属性，就可以依靠材质来方便地改变这些属性。而且对于模型自带的数据（如顶点位置、纹理坐标、法线等）Unity Shader也提供了直接访问的方法，不需要开发者自行编码来传给着色器 由于Unity Shader的高度封装性，我们可以编写的Shader类型和语法都被限制了。对于一些类型的Shader，例如曲面细分着色器（Tessellation Shader）、几何着色器（Geometry Shader）等，Unity的支持就相对差一些 3.6.2 Unity Shader和CG&#x2F;HLSL之间的关系 正如之前所讲，Unity Shader是用ShaderLab语言编写的，但对于表面着色器和顶点&#x2F;片元着色器，我们可以在ShaderLab内部嵌套Cg&#x2F;HLSL语言来编写这些着色器代码 这些Cg&#x2F;HLSL代码是嵌套在CGPROGRAM和ENDCG之间的，如下图所示： 从本质上来说Unity中只存在顶点&#x2F;片元着色器 "},{"title":"Unity Shader入门精要 第一、二章","date":"2022-08-08T04:57:32.000Z","url":"/2022/08/08/Shader%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1/","tags":[["Unity","/tags/Unity/"],["Shader","/tags/Shader/"],["计算机图形学","/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2%E5%AD%A6/"]],"categories":[["学习记录","/categories/%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/"]],"content":"1.1 Shader是什么 shader就是着色器 2.1 渲染流水线(概念上)渲染流水线的工作任务在于由一个三维场景出发，生成(渲染)一张二维图像。一般分为三个阶段： 应用阶段：输出渲染图元(点、线、三角面等) 开发者任务： 准备好场景数据(摄像机位置、视锥体、场景中包含的模型、光源)； 做一个粗粒度剔除工作，把不可见的物体剔除，不交给几何阶段处理； 设置好每个模型的渲染状态(材质、纹理、shader)。 几何阶段：输出屏幕的顶点信息 开发者任务：1.处理所有和我们要绘制的几何相关的事物(决定需要绘制的图元是什么、怎样绘制它们、在哪里绘制) 光栅化阶段：使用上一阶段的数据来阐述屏幕上的像素。并渲染出最终的图像 2.2 CPU和GPU之间的通信2.2.1 把数据加载到显存中 从硬盘加载到内存-然后网格和纹理等数据又被加载到显卡上的存储空间–显存 2.2.2 设置渲染状态 定义场景中的网格是怎样被渲染的 2.2.3 调用Draw Call 是一个命令，发起方是CPU，接收方是GPU，仅仅指向一个需要被渲染的图元列表，不会包含任何材质信息 2.3 GPU流水线2.3.1 概述 几何阶段和光栅化阶段可以分成若干个更小的流水线阶段，这些流水线阶段由GPU来实现，每个阶段GPU提供了不同的可配置性和可编程性 顶点数据：输入 顶点着色器：实现顶点的空间变换、顶点着色等功能 曲面细分着色器：用于细分图元 几何着色器：用于执行逐图元的着色操作，或用于产生更多图元 裁剪：将不在摄像机视野内的顶点裁剪掉，并剔除某些三角图元的面片 屏幕映射：负责把每个图元的坐标转换到屏幕坐标系中 三角形设置：固定函数阶段 三角形遍历：固定函数阶段 片元着色器：实现逐片元的着色操作 逐片元操作：修改颜色、深度缓冲、进行混合等 屏幕图像 2.3.2 顶点着色器（几何阶段） 输入进来的每个顶点都会调用一次顶点着色器 工作：坐标变换、逐顶点光照 把顶点坐标从模型空间转换到齐次裁剪空间（如(5,10,8)-&gt;(.6,.4,.2) 0-1之间） 2.3.3 裁剪（几何阶段） 不处理不在相机范围内的物体 三种关系： 完全在视野内 – 将图元传递给下一流水线 部分在视野内 – 在视野交界处用新的顶点代替 完全在视野外 – 不会传递图元 2.3.4 屏幕映射（几何阶段） 把每个图元的x和y坐标转换到屏幕坐标系下 屏幕坐标系和z坐标一起构成了一个坐标系，叫做窗口坐标系 2.3.5 三角形设置（光栅化阶段） 计算光栅化一个三角网格所需的信息 2.3.6 三角形遍历（光栅化阶段） 检查每个像素是否被一个三角网格所覆盖 是的话就生成一个片元 2.3.7 片元着色器（光栅化阶段） 也被称为像素着色器 将上一个片元数据处理为颜色值 2.3.8 逐片元操作（光栅化阶段） 也被称为输出合并阶段 1.决定每个片元的可见性：· 模板测试：将模板缓冲区中该片元的值和参考值进行比较；限制渲染区域· 深度测试：将该片元的深度值和已经存在于缓冲区中的深度值进行比较 2.混合颜色——混合：· 关闭-就会直接覆盖· 开启：就会对片元颜色和缓冲区颜色进行混合 双重缓冲：交换后置缓冲和前置缓冲的内容；后置缓冲进行光栅化；前置缓冲进行显示 2.4 一些容易困惑的地方2.4.1 什么是OpenGL&#x2F;DirectX 显卡驱动把OpenGL和DX的函数调用翻译成GPU执行命令 应用程序通过调用OpenGL和DX的图形接口将渲染所需的数据，如顶点数据、纹理数据、材质参数等数据存储在显存的特定区域 2.4.2 什么是HLSL、GLSL、CG HLSL： · DX的着色语言，着色语言是专门用来编写着色器的 · 微软的 GLSL： · OpenGL的着色语言 · 跨平台 CG： · 英伟达的C for graphic · 跨平台 2.4.3 什么是Draw Call CPU调用图像编程接口，以命令GPU进行渲染的操作 通过命令缓冲区来并行工作 Draw Call多了会影响帧率 使用批处理可以有效较少Draw Call数量（类比多个小文件打成压缩包复制到别处会快很多） 2.4.3 什么是固定管线渲染 只提供配置操作 没有对流水线阶段的完全控制权 2.5 那么，你明白什么是Shader了吗 GPU流水线上一些可高度编程的阶段，而由着色器编译出来的最终代码会在GPU上运行 有一些特定类别的着色器，比如顶点着色器、片元着色器 依靠着着色器，我们可以控制流水线中的渲染细节，例如用顶点着色器进行顶点变换以及传递数据，用片元着色器来逐像素的渲染 操作包括：设置适当的渲染状态，使用合适的混合函数，开启还是关闭深度测试&#x2F;深度写入 "},{"title":"从零搭建V2Ray翻墙服务器及维护事项","date":"2022-03-16T13:53:41.000Z","url":"/2022/03/16/vpn-create/","tags":[["文档","/tags/%E6%96%87%E6%A1%A3/"]],"categories":[["教程文档","/categories/%E6%95%99%E7%A8%8B%E6%96%87%E6%A1%A3/"]],"content":"前言 这是一条个人在网上搜集资料总结的blog 已按步骤顺序排列~ 月费5＄左右（一直不关服务器的情况下） 教程中使用的案例服务器已经删除，因此IP地址等基本未打码 - 第一步、VPS VPS介绍 虚拟专用服务器（Virtual Private Server，简称VPS）技术，是将一台服务器分割成多个虚拟专享服务器的优质服务。实现VPS的技术分为容器技术，和虚拟化技术。在容器或虚拟机中，每个VPS都可选配独立公网IP地址、独立操作系统、实现不同VPS间磁盘空间、内存、CPU资源、进程和系统配置的隔离，为用户和应用程序模拟出“独占”使用计算资源的体验。VPS可以像独立服务器一样，重装操作系统，安装程序，单独重启服务器。VPS为使用者提供了管理配置的自由，可用于企业虚拟化，也可以用于IDC资源租用。 这里以Vultr为例，前往Vultr首页 -&gt; 注册一个账号系统会寄一封验证邮件，激活它 Products -&gt; 右侧加号选择服务器 选择Cloud Compute CPU &amp; Storage Technology选便宜的Regular Performance就行 （后来出的选项，做教程时才发现的） Server Location 用过日本、洛杉矶、New Jersey(新泽西州)的伺服器，体验还不错，其他地区可自行测试 伺服器类型选CentOS 7x64 Server Size选最便宜的可获得每月2TB的流量，当然这个无所谓，因为用不完，就算用完了可以重新搭建，流量会清零，所以不用管 Add Auto Backups关掉，因为收费也是后来出的功能，咱也不造有啥用qwq 其他选项默认就行，然后点击右下角 Deploy Now 等待创建完成 完成后进入界面，注意IP Address、Username、Password一会要用到 用cmd先ping以下该IP地址，若ping得通、延迟较小则可下一步若ping不通或者丢包率高，则点击加号重复创建步骤 注意:ping不通时先创建，得到满意的服务器后，再Destory掉不要的服务器否则你创建的IP还会是你Destory前的IP - 第二步、安装V2Ray 什么是V2Ray 你可以把V2Ray理解成为一套专有的工具，它可以帮助你在互联网上建立属于自己的私有网络，以实现受保护的通信，避免信息遭受恶意窃取或攻击。V2Ray属于一个大的技术项目，名为Project V。V2Ray主要负责处理网络协议和通信，它可以独立使用，也可与其他工具组合使用。从安装和使用的角度看，V2Ray分为服务器端、客户端，需要分别安装在不同的设备之上。 通过上图Server Information页面中右上角进入控制台(View Console)或下载Xshell连接终端机 由于View Console中不显示中文，这里将演示Xshell中的操作方法 新建会话 复制IP地址到名称，软件将自动填写主机，当然名称可以取别的 左侧选择用户身份验证复制进去账号密码 -&gt; 确定 进入会话，弹出SSH安全警告时选择接受并保存 接下来依次输入以下指令安装V2Ray 注意Xshell中的复制粘贴不是Ctrl + C&#x2F;V 安装时一直回车，保持默认就行，接下来会讲解有用的部分 安装完后是这样的： 需要注意的有：IP、端口、ID、传输协议类型 这里推荐将传输协议改成kcp （因为前段时间换端口tcp会秒被墙，好像叫tcp阻断来着） 输入 ： 输入： “ 2 “ - “ 2 “ - “ 6 “ 改为kcp协议 接着开放udp和tcp端口 输入： 其中port&#x3D;后面的数字为你的端口号 最后重启防火墙 到此V2Ray已经配置完成 接下来是V2Ray配置补充内容(可跳过)： 作用为可能能加速网络 方法一:输入v2ray -&gt; 11.其他 -&gt; 1.安装BBR -&gt; 按照提示下一步到底就行 方法二:分别输入以下指令： .&#x2F;tcp.sh 为脚本菜单，4、5、6、7、8加速方法可自行体验 - 第三步、V2Ray客户端 Windows：下载安装带V2Ray-Core的V2RayN 官方网站 安卓：下载V2RayN IOS：使用外区账号下载Shadowrocket（下载付费），无账号或支付途径可走tb使用Sideloadly自签没成功过，也没研究，感兴趣可以试试 服务器 - 添加[VMess]服务器 复制进地址、端口号、用户ID、传输协议改为kcp - 确定 这样你的客户端就配好了 常用快捷键：Ctrl+P 、 Ctrl+T 使用时在右下角任务栏里选择代理方式和服务器 一般只用到全局模式和PAC模式 可批量导出配置给别的设备上配置使用 - 第四步、维护 当你在使用梯子时，突然连接不上了，这时该怎么办；首先检查是否Ping得通IP地址，若Ping不通，重新搭建服务器；若能Ping通，修改端口号，开放对应的tcp、udp端口，重启防火墙，修改客户端配置即可 至此，教程结束，感谢观看！"},{"title":"Hello World And My First Blog","date":"2022-03-16T06:31:54.000Z","url":"/2022/03/16/my-first-blog/","categories":[["undefined",""]],"content":"第一章内容 第二章test参考test Welcome to Hexo! This is your very first post. Check documentation for more info. Quick StartCreate a new post Run server Generate static files Deploy to remote sites testtesttesttest"},{"title":"Kratos-Rebirth食用说明","date":"2020-04-07T07:27:05.000Z","url":"/2020/04/07/Kratos-Rebirth-Manual/","tags":[["文档","/tags/%E6%96%87%E6%A1%A3/"]],"categories":[["教程文档","/categories/%E6%95%99%E7%A8%8B%E6%96%87%E6%A1%A3/"]],"content":"没错这是一个文档！（被打死 安装提示由于本模板使用了和默认模板landscape一样的ejs引擎，因此当您完成Hexo站点的安装后，您应该能够直接运行本主题。 在运行之前，请您将_config.yml.example文件复制一份，并重命名为_config.yml； 主题配置配置文件地址：./kratos-rebirth/_config.yml - Global 全局配置 site_analytics : 站点统计代码，这一行代码会被插入到后页脚。 hoster : 网站托管服务提供者，这个是出于感恩性的可选添加内容，这一个链接会被插入到后页脚。 site_logo : 网站的LOGO图片文件，请注意与后面核心JS的设置保持一致。 snow : (true&#x2F;false)站点下雪特效开关，控制是否在载入下雪相关的代码。 click_animate_js : (filename&#x2F;false) 点击事件使用的动画 js 文件，默认为 candy 即主题自带的 candy.js 文件，您可以设置成 false 表示禁用，或是引入其他您喜欢的动画 js 文件。 enable_dark : (true&#x2F;false)站点是否启用暗色模式适配。请注意，即使启用了暗色模式，在亮色的环境下主题仍然会渲染为亮色模式；同时用户可以手动选择使用的颜色（右下角菜单栏按钮处）。 highlight_theme : 代码高亮主题，五选一（light | night | night-eighties | night-blue | night-bright），控制代码高亮时候使用的配色。会根据用户的选择自动加载对应的高亮主题文件。 cdn (jsdelivr&#x2F;unpkg&#x2F;false)为静态资源开启CDN加速（使用jsDelivr或是unpkg，如果开启则默认使用jsdelivr，有其他什么好建议可以随时提出issue）。请注意，如果您修改了任何静态资源，那么请保持此项为false（同时也是默认状态） check_update (true&#x2F;false)版本更新检查，无需检查的话就记得关闭哦。 - Custom Styles 自定义样式这部分配置的内容可以覆盖 CSS 文件中指定的部分。 images 图片 banner 站点横幅 background 站点背景 - Index 首页配置相关 post_type (true&#x2F;false)站点首页是否使用文章主题的显示模式（即一开始可见一部分，点击阅读更多可以加载全文，Hexo许多主题都默认的显示模式（而不是默认的这种卡片式的陈列方式） read_count (true&#x2F;false)在首页显示每篇文章的阅读量统计（目前仅支持 valine&#x2F;waline 评论系统的内置统计功能） comment_count (true&#x2F;false)在首页显示每篇文章的评论量统计（目前仅支持 waline 评论系统的内置统计功能） - Top Menu 顶部导航栏相关 分为menu和label两个模块，控制页首的顶部导航栏内容。menu模块提供导航到的页面位置，label模块提供导航选项卡的显示内容。请注意menu项与label项需要一一对应，否则可能会出现无法正常显示的情况。配置样例随主题附带，可以参考使用。 现已加入二级菜单支持，配置格式为： 请注意关键词submenu不可被改变，其他内容在保证一一对应的情况下可以自定义。具体可以参照主题自带的样例配置。 额外提示：二级菜单功能可能会和旧版本的部分函数发生冲突，如果出现意外报错的话可以考虑检查一下是否存在更新的Hexo版本，或者去Github提一个Issue。目前开发使用的环境(package.json文件)可以参见🎁 使用环境小贴士 - Footer 页脚显示相关 group_link : 控制是否在页面右下角显示群聊的加入按钮。如果显示的话，这里可以指定加群的链接。无需显示的话请留空（而不是删除这个设置项），相关的代码会自行处理结构生成关系。 contact : 联系方式相关，控制是否在页脚(.&#x2F;kratos-rebirth&#x2F;layout&#x2F;_partial&#x2F;footer.ejs)显示各种联系方式的按钮如果要启用的话，请输入相关联系方式的代码，直接输入用户名即可（fediverse的实例需要输入实例地址，邮箱请使用&#109;&#97;&#105;&#x6c;&#x40;&#x65;&#x78;&#97;&#x6d;&#112;&#108;&#x65;&#46;&#x63;&#x6f;&#x6d;这样的格式）；无需显示的内容请留空。 timenotice : 本站运行时间前的提示文本。 icp : ICP备案号，便于生成快捷链接，如萌ICP备22010101号 psr : 公安备案号，便于生成快捷链接，如371402000001 - Post Page 文章页面相关 show_cc : (true&#x2F;false)控制文章页面(.&#x2F;kratos-rebirth&#x2F;layout&#x2F;post.ejs)是否显示CreativeCommon知识共享协议相关的提示内容w donate : (true&#x2F;false)控制文章页面是否显示捐助的二维码按钮，二维码链接可以在站点的 JavaScript 相关的配置 里进行修改（详见下文） share : (true&#x2F;false)控制文章页面是否显示分享链接的按钮 comments : (disqus&#x2F;disqusjs&#x2F;valine&#x2F;twikoo&#x2F;waline&#x2F;gitalk&#x2F;gitment&#x2F;false)会从layout/_comments文件夹中加载指定的评论系统，您也可以自定义其他的解决方案。如果不想开启评论的话，那就还是设置为false吧~ - Disqus 评论相关 shortname : 站点短代号，需与 Disqus Admin - Settings - General - Shortname 的保持一致 - DisqusJS 评论相关这里使用了DisqusJS这个项目，具体的参数配置相关的可以参考原始文档，这里提供的说明仅供参考w shortname : 站点短代号，需与 Disqus Admin - Settings - General - Shortname 的保持一致 sitename : 站点名，建议与 Disqus Admin - Settings - General - Website Name 的保持一致 api : API服务器地址，官方有提供一个反向代理地址，也可以使用其他的API代理服务，或是自建相关的代理，如本站使用自建的代理() apikey : DisqusJS发起请求时使用的公钥，本主题目前只考虑了一个的情况，如果有多请求需求的话可以考虑直接修改./kratos-rebirth/layout/_comments/disqusjs.ejs的代码 admin : 站点评论区管理员的Disqus用户名，可以在 Disqus - Settings - Account - Username 获取或进行修改 adminlabel : 站点管理员的提示标签，可以在 Disqus Admin - Settings - Community - Moderator Badge Text 获取或进行修改 - Valine 评论相关这里使用了Valine这个项目，具体的参数配置相关的可以参考原始文档，这里提供的说明仅供参考；如果您有自定义功能的需要，您可以考虑手动修改layout/_comments/valine.ejs文件中相关的配置内容。 app_id : 您LeanCloud的APP ID app_key : 您LeanCloud的APP Key visitor : (true&#x2F;false)是否开启Valine的阅读统计功能 enableQQ : (true&#x2F;false)是否开启昵称框自动获取QQ昵称和QQ头像 - twikoo评论相关 env_id : 您twikoo的Env ID - Waline 评论相关这里使用了Waline这个项目，具体的参数配置相关的可以参考Waline文档的前端配置段，自行调整相关前后端的配置。在该配置段下的内容都会被自动引入至评论模块中。el 和 path 会在页面自动生成，不必加入。 - Gitalk 评论相关这里使用了Gitalk这个项目，具体的参数配置相关的可以参考Gitalk 文档，自行调整相关前后端的配置。在该配置段下的内容都会被自动引入至评论模块中。id 会在页面自动生成，不必加入。 - APlayer 音乐播放器相关（页面左下角） enabled : (true&#x2F;false)用音乐来点缀全新的体验吧！这里可以选择是否开启aplayer播放器哦~ playlist : APlayer播放使用的歌单地址，可以使用公开的API服务，或是搭建自己使用的后端。我提供了一个后端API的样例，目前本站点使用的就是这个，可以去Github获取。不过这个项目已经过时，我们推荐使用下一种加载方式，即使用MetingJS（默认使用api.i-meto.com/meting/api解析）的方式来加载。 meting : 使用MetingJS时请保留该选项 server : 使用的音乐服务来源：netease, tencent, kugou, xiami, baidu type : 加载的播放列表类型：song, playlist, album, search, artist id : 请求的ID，如曲目ID、播放列表ID、专辑ID、搜索关键词等 order : (list&#x2F;random)音乐播放的顺序，我个人比较喜欢的是random模式，这样就能避免每次访问博客时，都是从第一首音乐开始播放的尴尬清情况。 - Widgets 侧边栏与挂件 sidebar : (left&#x2F;right&#x2F;none)是否启用侧边栏与小工具，若设置为left则会显示在页面左侧，若设置为right则会显示在页面右侧。 widgets : 启用的小部件，默认全部启用，不喜欢的就删掉吧 请注意splitter是分隔符，用于分割活动区域和固定区域（例如默认配置下文章页向下滚动时，About区块会顺势上浮，toc区块会固定在最顶，您可以手动调整各小挂件的位置，删除splitter表示禁用该功能（即所有小挂件均固定显示） avatarUri : 头像的图片地址链接 mobile_toc : 移动端文章目录显示相关配置 hide : (true&#x2F;false)是否隐藏移动端目录 hide_id : (true&#x2F;false)移动端目录前是否自动补充的标号 - FancyBox 图片放大显示 fancybox : (true&#x2F;false)启用图片放大显示工具，点击文章内的图片可以进行全屏放大操作 - Search 搜索 enable : (true&#x2F;false)是否启用站点搜索功能 path : 搜索数据库的文件名，一般保持默认search.json即可 field : 搜索的区域，可以是页面，或是文章，或是所有内容。默认情况下是仅搜索文章内容。 content : (true&#x2F;false)搜索内容是否包含文章或是页面的详细内容 - JavaScript 相关的配置 main : 主JavaScript配置 pic : 无图片文章使用的随机图片相关设置 CDN : (jsdelivr&#x2F;unpkg&#x2F;false)图片是否使用CDN来载入（如果有本地替换过图片，请设置为 false 以避免图片失效） random_amount : 表示图片的编号为 1 ~ 您设定的值，默认是 20 filename : 图片的文件名格式 createTime 站点建立的时间，请改成您站点建立的时间。该项与页脚的运行时间有直接关联，建议按照样例格式进行书写，以免出现莫名其妙的报错。 donateBtn 捐助按钮上显示的文字，建议不要太长以免溢出，如果不显示捐助按钮的话就不用去管它啦~ kr.scanNotice 二维码小窗口上的小标题，如果不显示捐助按钮的话也不用去管它啦~ qr_alipay 支付宝二维码的文件地址 qr_wechat 微信支付二维码的文件地址 siteLeaveEvent (true&#x2F;false)是否启用站点失焦事件（只是为了卖萌，有可能会影响到历史记录，请谨慎开启） leaveTitle 离开时候站点标题的追加内容 returnTitle 返回时候站点标题的追加内容 expire_day 文章过期提示：距离最后更新时间多少天时，打开文件会给出提示信息 topNavScrollToggle (true&#x2F;false)顶部导航栏在页面向下滚动时隐藏 - Site verify related 站点所有权验证相关 site_verify : google : Google Search，只填写中间那一串随机码即可 baidu : 百毒搜索，同样只需填写中间的一串随机码 bing : 必应搜索，同样只需填写中间的一串随机码 - Friends page related 友链页面相关 工作模式 我们提供两种配置友链的方式： 一种是自动生成单独的页面，您只需要指定页面的路径（href配置内容）即可自动生成 另一种则是Tag工作模式（href项留空或删除），主题会生成一个方便您使用的小标签，在任何一个页面或是文章内插入{% friends %}即可自动生成友链块。 friends : 友链页面全局字段，删除此字段以禁止自动生成友链页面 href : 友链页面的路径，如friends表示yoursite.ltd/friends/的路径，留空此字段会使用Tag模式 page : 页面相关的参数，您可以配置任意多您需要的页面参数，提供的样例可供您参考 list : 友链列表，您可以参照提供的样例进行对应的复制修改，每一项可以提供显示的名字(name)、简介(bio)、头像链接(avatar)和目标站点链接(link)，无用项建议留空（而不是直接删除） verify : 是否在每次启动时验证友联的可访问性 文章页面配置路径：顶部，文章信息区 (Front-Matter) pic : 可以指定这篇文章是否使用自定义的缩略图名称（在文章资源文件夹内），而不是使用随机化的图标 sticky : (number)重要的文章，把它们置顶吧！数字越大优先级越高哦~ comments : (true&#x2F;false)是否为单篇文章指定开启或关闭评论区 toc： (true&#x2F;false)该文章是否需要生成目录 only： 指定文章显示的位置，有以下关键词： home: 在首页显示 category: 在分类页显示 tag: 在标签页显示留空或是不配置此项，则文章在所有该出现的位置都会显示。层级之间相互平等，没有覆盖关系。特别地，如果配置了此项，但是使用的并不是以上的关键词（例如只留了一个- none，那么文章就被隐藏起来了） 一个完整的 Front-Matter 区样式如下（可自行删去不必要的内容）： 模板与特定页面项目Kratos-Rebirth-Specified-Pages已经废弃，所有功能均已内置，无需使用额外的模块。 此处给出我使用的scaffolds/post.md文件内容： 模板特有标签组件提示信息喵呼呼o(&#x3D;•ェ•&#x3D;)m 成功啦o(￣▽￣)ブ 有危险Σ(っ °Д °;)っ 有消息(・∀・(・∀・(・∀・*) 当心哦≧ ﹏ ≦ 折叠内容 这是一条折叠内容 这是一条预先展开的折叠内容 提示面板 这是一个提示面板框 TYPE是面板框的类型，可以是： success danger info warning 模糊字符这里有一些被模糊的字符 关于MathJax对公式进行的处理功能已废弃，建议使用类似hexo-math类似功能的插件，相关的代码注入部分已经修复。 关于Hexo书写的小技巧Hexo使用了MarkDown，但是在一些细节的处理上有很棒的技巧哦~ 文章概要可以将文章开头的一段作为概要显示在首页主题部分，方法就是在需要分割的地方加入&lt;!-- more --&gt;即可；或者可以在文章头指定excerpt 图片资源Hexo有为每篇文章生成一个资源文件夹，可以将图片资源以{% asset_img 文件名 备注 %}的格式插入文章，本主题引入的fancybox会自动实现对文章内图片的放大功能。 "}]